[
["index.html", "Applied Longitudinal Data Analysis", " Applied Longitudinal Data Analysis Josh Jackson Fall 2017 Applied Longitudinal Data Analysis "],
["01-Syllabus.html", "Chapter 1 Syllabus", " Chapter 1 Syllabus Instructor: Joshua Jackson Office: 315B Office hours: 10-11 Wednesday and by appointment Course Descrition This course covers modern methods of handling longitudinal, repeated measures. The class will introduce the rationale of measuring change and stability over time to study phenomena, as well as how within-person designs can increase statistical power and precision compared to more traditional designs. Most the course will use multi-level models and latent (growth) curve models to specify patterns of change across time. Additional topics include: visualization, measurement invariance, time-to- event models and power. PREREQ: Use of R will be required, Familiarity with MLM and/or Structural Equation Models. Class textbook Readings will be provided Structure of class Each class will cover a specific type of longitudinal model. During that class, I (josh) will provide an overview of the important considerations or motivation for this analysis. Then we will switch to walking through code and results. For each topic I will select (in advance) someone who will meet with me outside of class time to go over analyses for that topic using their own dataset. That person will be in charge of providing background information on the dataset and discussing the progress of their data analytic plan. Final code will be shared to the class via Github. If you are not presenting you will need to run the analyses using your own dataset or one that is appropriate for the techinique. These are due before the start of the next class. Grading Grading consists of 3 aspects: 1. Weekly projects uploaded to github (60% of grade) 2. Class presentation based on your data (20%) 3. Final paper covering the method and results of your main longitudinal hypothesis(es) (20%) Schedule Week Date Topic Readings 1 8/31 Motivation, terms, concepts and graphing 2 9/7 Growth curves; MLM in R: packages and procedures 3 9/14 Conditional (Leve 1 and 2 predictors) MLM models 4 9/21 Class canceled 5 9/28 Polynomial, piecewise and spline models 6 10/05 Intensive data anlysis/within person fluctuations p1 7 10/12 Intensive data anlysis/within person fluctuations p2 8 10/19 SEM and lavaan intro 9 10/26 Latent Grown (curve) Models 10 11/2 MI and Second order Model 11 11/9 Multiple group models 12 11/16 Biometric Models 13 11/23 Tofurkey day 14 11/30 Flexible SEM models (LCM, STATE-TRAIT; ALT-SR) 15 12/7 Mixture Models Other topics: Longitudinal mediation (and multilevel mediation), two wave data, experimental approaches "],
["02-LDA-basics.html", "Chapter 2 LDA basics 2.1 Motivation, terms, concepts 2.2 Data analysis and data structures 2.3 Putting it together example 2.4 What does this look like? 2.5 Design considerations 2.6 Threats to validity 2.7 Why not RM ANOVA? 2.8 Now you try", " Chapter 2 LDA basics 2.1 Motivation, terms, concepts 2.1.1 Why longtiduinal? At least 6 reasons: Identification of intraindiviaul change (and stability). Do you increase or decrease with time or age. Is this pattern monotonic? Should this best be conceptualized as a stable process or something that is more dynamic? On average how do people change? Inter-individual differences in intraindividual change. Does everyone change the same? Do some people start higher but change less? Do some increase while some decrease? Examine joint relationship among intraindividual change for two or more constructs. If variable X goes up does variable Y also go up across time? Does this always happen or only during certain times? Is this association due to a third variable or does it mean that change occurs for similar reasons? Determinants of intraindividual change. What are the repeated experiences that can push construct X around. Do these have similar effects at all times? Determinants of interindividual differences in intraindividual change. Do events, background characteristics, interventions or other between person characteristic shape why certain people change while others don’t? Inter-individual differences in intraindividual fluctuation and determinants of intraindividual fluctuation. Does everyone vary the same? Why are some more variable than others? 2.1.2 Types of change (most common) There are many ways to think of change and stability. We will only have time to go into a few of these types, but it is helpful to think about what type you are interested in when you plan a project or sit down to analyze data. Differential / rank order consistency/ rank order stability. Goes by many names but in the end it is just a correlation. This is a group/sample/population level variable and indexes the relative standing of a person with regard to the rest o f the members in the sample. Does not take into account mean structure. Best used with heterotypic continuity where the construct may be the same but the measurement of the construct changes e.g., childhood IQ or acting out in school versus when you are an adult. A specialized case of this is ipsative change, which looks at the rank order of constructs within a person. This is not done on a single variable (depression) but on a broad number of them (all PD symptoms). Mean level/ absolute change. Takes into account mean structure and indexes absolute levels of a construct. A strong assumption is that the construct means (not a pun) the same thing across time. That is, my measure of depression is interpreted the same for a 40 year old and a 90 year old if I want to look at absolute differences between the two ages. Mean level change is not dependent at all on rank order consistency. Can have no mean level change and high rank order consistency and vice versa. Individual differences in change. Rank order and mean level provide an index of change and or stability for the sample. Here this provides an assessment of change for an individual. For example, if it is typical to decline in cognitive ability do some people buck the trend and stay at their past level? Individual differences in change get at both mean level changes as well as the tendency of the sample to show stability. It is the type of change that we will focus on the most. 2.1.3 Between person versus within person Or in other words these are the shortened version of interindividaul differences in change versus intraindividaul differences in change. Refers to across people versus within a particular person. Often we are interested in both simultaneously. Related to Level 1 and Level 2 (for those of you familiar with this terminology). We may be interested in understanding only between person variability, within person variability or both. When trying to understand within person variability it is typically the case that predictors of between person effects are constant (between person) variables (e.g., gender) that does not change from assessment to assessment. In contrast, within person variability is best understood by time varying predictors (within person variables e.g., daily mood). We will incorporate both time invariant (between person) and time varying (within person) predictors into our eventual model. 2.1.4 Trajectories, curves, change, growth… oh my How do we refer to ‘change’? Usually it is easier to refer to pictorially or in terms of an equation. Putting a word onto it usually causes some confusion, which is why there are a lot of redundant terms in the literature. All of these might refer to the same thing when used within a model. However, the names of some models use these terms differently and thus can refer to different models or conditions that you are working with. In this class I will try to point out the important differences but you will be fine if you supplement your terms with graphs or equations. 2.2 Data analysis and data structures 2.2.1 Modeling frameworks: MLM &amp; SEM In this class (and in the field) two primary techniques are used with longitudinal models: MLM and SEM. At some levels they are completely equivalent. At others, one is better than the other and vice versa. MLM/HLM is a simple extension of regression. As a result it is easy to interpret and implement. In terms of longitudinal data it is easier to run models when the time of measurement differs from person to person. For this class we will use lme4 as our MLM program but there are many others we could use e.g., nlme. SEM is related to regression in that regression is a subset of SEM techniques. In other words, an SEM program could run a simple regression analysis. The primary advantage of MLM is that you may have assessment waves that vary in length between participants. An assumption of SEM models is that everyone has the same amount of time between assessment waves (though this can be somewhat relaxed). MLM is also better suited for complex error structures and complex nesting above and beyond assessments within person. It is also easier to model interactions. SEM primary advantage is the ability to account for measurement error via latent assessment of the repeated measures. Other advantages include the ability to model multiple DVs at once, and do so in a flexible manner to look at, for example, the associations between change in one construct and change in the another. Another major advantage is the ability to look at latent groups via latent class or mixture models. Bottom line: MLM is probably best suited for “basic” growth models. More complex analyses of change would benefit from an SEM approach. 2.2.2 Wide and Long form Depending on what type of analysis you want to perform you may need to restructure your data. I recommend the combination of tidyr and dplyr (among others) to restructure and manage your dataframes. The first decision you need to make is whether you want your data structured in a long or a wide format. There are multiple names to refer to these two types: multivariate vs univariate, person-level vs person-period, etc but they all refer to the same idea. How to structure your data depends on both what level of analysis (individual, dyad, household) and what type of analyses (MLM/SEM). Typically our focus is on individuals. Wide form is common among non-longitudinal data. It has one line per individual with all of their repeated measures in the same row, each with some name to distinguish which assessment wave the data came from. In general, this format is used for SEM. ## # A tibble: 3 x 4 ## ID ext_1 ext_2 ext_3 ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 4 4 4 ## 2 2 6 5 4 ## 3 3 4 5 6 In contrast, long format has a row per observation. Thus, participants likely have many rows, each one referring to a different assessment wave. There are fewer variables in this format which makes organization somewhat easier. Thus this has been referred to as “Tidy” data. Graphing with ggplot is facilitated when using tidy data such as being in the long format. ## # A tibble: 9 x 3 ## ID time ext ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 1 4 ## 2 1 2 4 ## 3 1 3 4 ## 4 2 1 6 ## 5 2 2 5 ## 6 2 3 4 ## 7 3 1 4 ## 8 3 2 5 ## 9 3 3 6 How do you go back and forth? To do so use the gather and spread functions of tidyr package. Gather goes from wide to long. library(tidyr) wide_to_long &lt;- wide %&gt;% gather(ext_1:ext_3,key = &quot;time&quot;, value = &quot;ext&quot;) wide_to_long ## # A tibble: 9 x 3 ## ID time ext ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 1 ext_1 4 ## 2 2 ext_1 6 ## 3 3 ext_1 4 ## 4 1 ext_2 4 ## 5 2 ext_2 5 ## 6 3 ext_2 5 ## 7 1 ext_3 4 ## 8 2 ext_3 4 ## 9 3 ext_3 6 This is equivalent code wide_to_long &lt;- wide %&gt;% gather(-ID,key = &quot;time&quot;, value = &quot;ext&quot;) %&gt;% arrange(ID) The separate function could be used to get only the assessment wave number. This might be useful when combining data together or for creating a common time metric for everyone. wide_to_long2 &lt;- wide_to_long %&gt;% separate(time, into = c(&quot;omit&quot;, &quot;wave&quot;), sep = &quot;_&quot;, convert = TRUE) %&gt;% select(-omit) %&gt;% arrange(ID) wide_to_long2 ## # A tibble: 9 x 3 ## ID wave ext ## &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 1 1 4 ## 2 1 2 4 ## 3 1 3 4 ## 4 2 1 6 ## 5 2 2 5 ## 6 2 3 4 ## 7 3 1 4 ## 8 3 2 5 ## 9 3 3 6 # Note that the seperate function will identify non numeric characters and use that to seperate the values. You can omit the sep = function to check yourself. One issue that comes up here is that we have differing dates for each assessment. Ideally we would like to utilize that extra information. ## # A tibble: 3 x 7 ## ID ext_1 ext_2 ext_3 date_1 date_2 date_3 ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1 4 4 4 1/1/10 5/1/10 8/1/10 ## 2 2 6 5 4 1/6/10 4/10/10 9/1/10 ## 3 3 4 5 6 1/8/10 4/25/10 9/13/10 How do we fix it? The same way we would with multiple variables we want to convert. Wave, along with ID helps us keep track of what variables go with which person at which time. Together, the two serve as a unique identifier. To better understand the code go through each line to see what the intervening data frame looks like. long.date &lt;- wide.date %&gt;% gather(-ID, key = &quot;time&quot;, value = &quot;value&quot;) %&gt;% separate(time, into = c(&quot;variable&quot;, &quot;wave&quot;)) %&gt;% spread(variable,value) long.date ## # A tibble: 9 x 4 ## ID wave date ext ## * &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1 1 1/1/10 4 ## 2 1 2 5/1/10 4 ## 3 1 3 8/1/10 4 ## 4 2 1 1/6/10 6 ## 5 2 2 4/10/10 5 ## 6 2 3 9/1/10 4 ## 7 3 1 1/8/10 4 ## 8 3 2 4/25/10 5 ## 9 3 3 9/13/10 6 One difficulty of creating a wave variable is whether or not the variables are named in a manner such that 1) assessment wave is easily identifiable (e.g. does _a always refer to the first wave whereas _b always refer to the second?) and 2) if that is consistent across variables. Having a wave identifier for your variables is important/necessary. Having an easily selected one (ie at the end of the variable name, hopefully separated by an underscore or a period). If assessment wave separators are embedded within the variable name it will be harder to covert your data. Often, variable data is attached at the end of a name such as SWB_4 to refer to the fourth item in a scale. This may obscure wave identification as in SWB_A_4. A similar naming problem can occur with multiple reports e.g,. SWB_4_parent. I recommend putting wave identification last. The difficulties become partly moot when working in long format as opposed to wide. In the above code we used spread to go from long to wide as a means of creating a long dataset where there were multiple variables. Technically this is not a tidy dataset in that it comprises of both long and wide information, but it is the typical format used for MLM analyses. Going from long to wide uses spread function as seen above, which we will utilize when converting our MLM models to SEM models. long_to_wide &lt;- long %&gt;% spread(time, ext) long_to_wide ## # A tibble: 3 x 4 ## ID `1` `2` `3` ## * &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 4 4 4 ## 2 2 6 5 4 ## 3 3 4 5 6 Note that this is technically the dataframe format that we want. The problem is that our variable names are numeric. This often causes problems. When working with tibbles use backticks ‘to refer to the column e.g., select(’1’) 2.2.2.1 meaningful time metric Time is the most important part of longitudinal analyses. Without some sort of explicit operationalization of time or thought into how you handle time in your analyses you are not conducting longitudinal analyses. The key to interpretting your output is to know how you handled your time variable. What units is it in? Does everyone have the same differences between assessments? Is time something you are explicitly interested in or merely there as a means to collect repeated measures? We will discuss more of these as the semester progresses. Right now however an important distinction is what should the scale of our x-axis variable, time, be in? At one level, the distinction is relevent to what is the process that is changing someone? Is it a naturally occuring devlopmental process? Then maybe age is the best metric. What about tracking childs cognitive ability, something that might be influenced by level of schooling? Here grade may be more important than age. Another common metric is time in study. This may be usefull if you are running an intervention or if you want to put everyone on the same starting metric and then control for nuisance variables like age or schooling level. Similarly, year of study as a prime time candidate may be useful if you are working from panel studies and interested in historical events and or cohort effects. As seen above,a wave variable (ie study measurement occastion) may be good enough to use as a time metric (though this makes some assumptions about the regularity of assessments both within and across people). Depending on your choice of time metric you may see different rates of change and variability in change. For psychological applications the most common would be age and time in study (followed by grades for assessments of kids). Age is nice because it captures a number of developmental processes thought to drive change (maturation, history, time-in-study) but does not identify a single reason. Time in study is the opposite in that it does not index any other type of change but that simplicity aides in testing different reasons for change (e.g, age moderation). 2.2.3 Graphing library(ggplot2) 2.3 Putting it together example Using some resting state imaging data gg1 &lt;- ggplot(example, aes(x = week, y = SMN7, group = ID)) + geom_point() print(gg1) ## Warning: Removed 9 rows containing missing values (geom_point). 2.3.1 a person level gg2 &lt;- ggplot(example, aes(x = week, y = SMN7, group = ID)) + geom_line() gg2 faceting gg3 &lt;- ggplot(example, aes(x = week, y = SMN7, group = ID)) + geom_line() + geom_point() + facet_wrap( ~ ID) gg3 ## Warning: Removed 9 rows containing missing values (geom_point). gg4 &lt;- ggplot(example, aes(x = week, y = SMN7, group = ID)) + geom_line() + facet_grid(. ~ group) gg4 gg5 &lt;- gg2 + aes(colour = factor(ID)) + guides(colour=FALSE) gg5 set.seed(11) ex.random &lt;- example %&gt;% select(ID) %&gt;% distinct %&gt;% sample_n(10) example2 &lt;- left_join(ex.random, example) ## Joining, by = &quot;ID&quot; gg6 &lt;- ggplot(example2, aes(x = week, y = SMN7, group = ID)) + geom_point() + stat_smooth(method=&quot;lm&quot;) + facet_wrap( ~ID) gg6 ## Warning in qt((1 - level)/2, df): NaNs produced ## Warning in qt((1 - level)/2, df): NaNs produced ## Warning in qt((1 - level)/2, df): NaNs produced ## Warning in qt((1 - level)/2, df): NaNs produced ## Warning in qt((1 - level)/2, df): NaNs produced lets look at individual level regressions library(tidyverse) library(broom) regressions &lt;- example2 %&gt;% group_by(ID) %&gt;% do(tidy(lm(SMN7 ~ week, data=.))) regressions ## # A tibble: 20 x 6 ## # Groups: ID [10] ## ID term estimate std.error statistic p.value ## &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 6 (Intercept) 0.043751626 0.019715849 2.2191095 0.26953127 ## 2 6 week -0.011495133 0.016432601 -0.6995322 0.61139970 ## 3 29 (Intercept) 0.110400000 NaN NaN NaN ## 4 29 week -0.033032982 NaN NaN NaN ## 5 48 (Intercept) 0.113337786 0.006560796 17.2750049 0.03681099 ## 6 48 week 0.030970692 0.003240913 9.5561620 0.06637719 ## 7 54 (Intercept) 0.129501865 0.014599949 8.8700220 0.07147028 ## 8 54 week -0.015721671 0.005719476 -2.7487959 0.22212408 ## 9 66 (Intercept) 0.069222338 0.034173465 2.0256166 0.29193874 ## 10 66 week 0.007679576 0.009070045 0.8466966 0.55272806 ## 11 87 (Intercept) 0.078700000 NaN NaN NaN ## 12 87 week -0.022742308 NaN NaN NaN ## 13 89 (Intercept) 0.079337057 0.020886636 3.7984602 0.16388088 ## 14 89 week 0.001695623 0.015490902 0.1094593 0.93059237 ## 15 120 (Intercept) 0.127500000 NaN NaN NaN ## 16 120 week 0.040389344 NaN NaN NaN ## 17 174 (Intercept) 0.158100000 NaN NaN NaN ## 18 174 week -0.010711592 NaN NaN NaN ## 19 205 (Intercept) 0.195400000 NaN NaN NaN ## 20 205 week -0.026256661 NaN NaN NaN regressions %&gt;% group_by(term) %&gt;% summarise(avg.reg = mean(estimate)) ## # A tibble: 2 x 2 ## term avg.reg ## &lt;chr&gt; &lt;dbl&gt; ## 1 (Intercept) 0.110525067 ## 2 week -0.003922511 average trend gg7 &lt;- gg1 &lt;- ggplot(example, aes(x = week, y = SMN7)) + geom_point() + stat_smooth() gg7 ## `geom_smooth()` using method = &#39;loess&#39; ## Warning: Removed 9 rows containing non-finite values (stat_smooth). ## Warning: Removed 9 rows containing missing values (geom_point). gg8 &lt;- ggplot(example, aes(x = week, y = SMN7)) + geom_point() + stat_smooth(method = &quot;lm&quot;) + facet_grid(. ~ group) gg8 ## Warning: Removed 9 rows containing non-finite values (stat_smooth). ## Warning: Removed 9 rows containing missing values (geom_point). gg9 &lt;- ggplot(example, aes(x = week, y = SMN7, group = ID)) + geom_point(alpha = 0.05) + stat_smooth(method = &quot;lm&quot;, se = FALSE) gg10 &lt;- gg9 + stat_smooth(data = example, aes(x = week, y = SMN7, group=1, color = &quot;black&quot;), method = &quot;lm&quot;, size = 2) + guides(fill=FALSE) gg11 &lt;- gg10 + facet_grid(.~ group) + theme(legend.position=&quot;none&quot;) gg11 ## Warning: Removed 9 rows containing non-finite values (stat_smooth). ## Warning: Removed 9 rows containing non-finite values (stat_smooth). ## Warning: Removed 9 rows containing missing values (geom_point). 2.4 What does this look like? A fancy regression equation. That is it. Seriously. What is different? Extra error terms, mostly. For regression, we think of error as existing in one big bucket. For MLMs (and other longitudinal models) we will be breaking up unexplained variance (error) into multiple buckets. This is where fixed effects and random effects come into play. We will discuss this more next class, but the just is that fixed effects are the regression coefficients you are used to. Fixed effects index group level change. Random effects vary among individuals (in the longitudinal models we are talking about) and index variation from the group. For our purposes this is most easily seen thinking about an average group trajectory (fixed effect) and the random effect indexes how much variability there is around that group level effect. 2.5 Design considerations 2.5.1 number of assessment waves Remember high school algebra: two points define a line. But, that assumes we can measure without error. Three assessment points will better define changes in psychological variables. 2.5.2 measuremnt 2.5.2.1 scale of measurement What does it mean for categorical variables to change over time? Can ranks, such as in preference for school subjects, How would dichotomous responses impact ability to measure change? Can I analyze childhood and adult variables simultaneously if assess the same construct, even though they may be measured differently? 2.5.2.2 standardizing Why would z-scoring your variables be problematic? 2.5.2.3 reliability The goal of longitudinal analyses is to understand why some construct changes or stays the same across time. A major difficulty in addressing this goal is whether you are able to accurately assess the construct of interest. One of the key characteristics (but not the only characteristic) is whether or not your assessment would be consistent if you gave an alternative measure or if you retook it immediately after your first assessment. This is known as reliability of measurement. To the extent that your measure is reliable it assesses true score variance as opposed to error variance. The amount of error score variance assessed is important given that error variance will masquerade as change across time given that error can correlate with anything else. The more error in your measurement the more change you will find. Of course this is unreliable change – change that is not true change, just stochastic noise. To ensure that your rate of change is reliable assessed, a few thoughts must go into measurement of your variable of interest as well as the number of assessment waves. 2.6 Threats to validity 2.6.1 Missing data 2.6.1.1 types of missing data On a scale from 1 to you’re completely screwed, how confident are you that the missingness is not related to your study variables? Missing completely at random (MCAR) means that the missingness pattern is due entirely to randomness Missing at random (MAR) means that there is conditional randomness. Missingness may be due to other variables in the dateset. Pretty standard for longitudinal data. Not missing at random (NMAR) means that the missingness is systematic based on the missing values and not associated with measures variables. For example, in a study of reading ability, kids with low reading ability drop out, due to not liking to take tests on reading ability. However, if reading ability is assocaited with other variables in the model, then this missingness becomes closer in kind of MAR, and thus somewhat less problematic. Typically, we make the assumption we are working under MAR and thus we will have unbiased estimates when predictors of missingness are incorporated into the model. 2.6.1.2 how to handle missing data Listwise? Nah Full information maximum likelihood and other ML approaches? Sure. Multiple imputation? Cannot hurt. 2.6.2 Attrition/Mortality Major contributor to missing data 2.6.3 History/cohort Know that the processes driving change can be due to a specific event or cohort 2.6.4 Maturation Change may occur because of natural processes. Thus if you just follow someone across time they will likely change irregardless of say, if they are in the control group 2.6.5 Testing Having people take the same survey, test or interview multiple times may lead them to respond differently. Does that change result from development or does it result from them being familiar with the test? 2.6.6 Selection If you are looking at life events, know that life events are not distributed randomly. Moreover, people who stay in studies and even sign up for studies are different from those that do not. As a result, it is often hard to make internally valid inferences with longitudinal data. 2.7 Why not RM ANOVA? Cannot handle missing data Assumes rate of change is the same for all individuals. Time is usally done with orthogonal polynomials, making it difficult to interpret or to model non-linear. In other words, you have flexibility on how you want to model time. Accounting for correlation across time uses up many paramters, MLM is more efficient. Can accomidate differences in time between assessment waves across participants Handles arious types of predictors - continuous vs nominal &amp; static vs dynamic 2.8 Now you try Move your data into a long format and a wide format. Did you have any specific challenges that you encountered? If so, discuss them. Create a wave variable and date variable (if applicable). What is your sample size for each wave of assessment? Take the date variable and convert it to a different date format such as time in study or age (if appropriate). What scale is most suitable for your analyses? (weeks/months/years?) Graph your data using the different time metrics, fitting individual curves for each person. Create an overall average trend of your data (split up into groups if appropriate). Attempt to color your individual data points and/or shade different lines (highlight some particiapnts, highlight the average trend line but not the individual level lines) Look at the correlations of your DV across time "],
["03-Growth-curves.html", "Chapter 3 Growth curves 3.1 Between person models and cross sectional data 3.2 Within person models e.g., 2-level models 3.3 Adding time 3.4 Individaul level random effects 3.5 working with models in R 3.6 Exploring beyond the summary 3.7 Adding time to the MLM 3.8 Random effects 3.9 comparing to a standard linear model 3.10 Other types of models 3.11 Matrix notation (as a way to help understand what is going on) 3.12 Estimation 3.13 Testing significance (adapted from Ben Bolker) 3.14 Predictions and prediction intervals 3.15 Coefficient of determination equivalents 3.16 Now you try:", " Chapter 3 Growth curves 3.1 Between person models and cross sectional data You already know this, but it gives us a chance to review regression \\[ {Y}_{i} = b_{0} + b_{1}X_{1} + b_{2}X_{2} + b_{3}X_{3}+... +\\epsilon_{i} \\] \\[ \\hat{Y}_{i} = b_{0} + b_{1}X_{1} + b_{2}X_{2} + b_{3}X_{3}+... \\] Parameters are considered fixed where one regression value corresponds to everyone. I.e., that association between X1 and Y is the same for everyone. Each person has a Y, denoted by the subscript i, and each has a residual associated with them, also designated by i. library(readr,) example &lt;- read_csv(&quot;~/Box Sync/5165 Applied Longitudinal Data Analysis/Longitudinal/example.csv&quot;) example$ID &lt;- as.factor(example$ID) Lets look at some data library(tidyverse) library(ggplot2) gg1 &lt;- ggplot(example, aes(x = week, y = SMN7)) + geom_point() + stat_smooth(method = &quot;lm&quot;) print(gg1) What happens if we run a regression? regression &lt;- lm(SMN7 ~ week, data = example) summary(regression) ## ## Call: ## lm(formula = SMN7 ~ week, data = example) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.099294 -0.039929 -0.005938 0.032715 0.169885 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.100161 0.005261 19.039 &lt;2e-16 *** ## week 0.004087 0.002563 1.595 0.112 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.05562 on 214 degrees of freedom ## (9 observations deleted due to missingness) ## Multiple R-squared: 0.01174, Adjusted R-squared: 0.007124 ## F-statistic: 2.543 on 1 and 214 DF, p-value: 0.1123 3.2 Within person models e.g., 2-level models library(tidyverse) gg2 &lt;- ggplot(example, aes(x = week, y = SMN7, group = ID)) + geom_point() + stat_smooth(method = &quot;lm&quot;, se = FALSE) gg3 &lt;- gg2 + stat_smooth(data = example, aes(x = week, y = SMN7, group=1, colour=&quot;#990000&quot;), method = &quot;lm&quot;, size = 3, se=FALSE) print(gg3) Each person has multiple assessments, so we now need to distinguish between people and their assessments. Failing to distinguish would lead to violation of independence, an important assumption of the standard regression model. As seen in the graph above, what we have now is both individual level slopes as well as an average level slope. The average level slope is going to be the average of the individual level slopes, which will look like our average slope ignoring all dependencies. Same for the intercept. ## Joining, by = &quot;ID&quot; regressions &lt;- example2 %&gt;% group_by(ID) %&gt;% do(tidy(lm(SMN7 ~ week, data = .))) head(regressions) ## # A tibble: 6 x 6 ## # Groups: ID [3] ## ID term estimate std.error statistic p.value ## &lt;fctr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 6 (Intercept) 0.04375163 0.019715849 2.2191095 0.26953127 ## 2 6 week -0.01149513 0.016432601 -0.6995322 0.61139970 ## 3 29 (Intercept) 0.11040000 NaN NaN NaN ## 4 29 week -0.03303298 NaN NaN NaN ## 5 48 (Intercept) 0.11333779 0.006560796 17.2750049 0.03681099 ## 6 48 week 0.03097069 0.003240913 9.5561620 0.06637719 We also have variation around that mean. This variation is lost when we have a between subjects only model that ignores the individual level. This variation will be called Random Effects Note, there is another source of error, the within-subjects error that can be seen in the below graph. This error is assumed to be random. We will discuss this error more in depth later. example3 &lt;- example2 %&gt;% filter(ID == &quot;66&quot;) gg4 &lt;- ggplot(example3, aes(x = week, y = SMN7, group = ID)) + geom_point() + stat_smooth(method = &quot;lm&quot;) gg4 3.2.1 thinking about random effects 3.2.2 random effects Within subjects variability in either staring value or slope is referenced in terms of random effects. How do we represent this in our equation? Easy, we just say that the typical regression parameters we have are not the same for everyone – that they are random (in contrast to fixed). In general, when would we want to use random effects? If there is some sort of selection (random or not) of many possible values of the predictor (e.g., stimuli are 3 random depression drugs, three semi random chosen levels of a drug). With longitudinal data this is people. What situations are necessary for random effects? For longitudinal models, there needs to be multiple assessments per your grouping category (people, schools, neighborhoods). Random as in they are sampled from some population and thus can vary. This means that your parameters (traditional regression parameters) are estimates and thus have error associated with them. This error is not like like a standard residual, which represents error for your overall model. Nor is it like the standard error for a point estimate. Random effects can best be thought of as deviation of individual regression lines from the group regression line (though it technically is not this). To facilitate the multiple assessments per person we will now use both i and j subscripts. We will see that the random effects are part of the overall error term in the model. Counterintutitively, the main focus of these types of models will be the fixed effects, with less attention paid to the random effects. That said, the random effects are necessary to account for dependency in the data. One can think about these models as normal fixed effects regressions, with the random effects there to account for the longitudinal nature of the data. They are made up of a number of standard regression equations, each for a single individual. Doing so side steps the trouble of having correlated errors, and thus allows us to interpret our findings without concern. 3.2.3 Empty model equation Level 1 \\[ {Y}_{ij} = \\beta_{0j} +\\varepsilon_{ij} \\] Note that we have multiple responses per individual j, noted with an i to refer to specific times. Level 1 is considered the within person model. Also note that the intercept has a subscript. In typical regression it does not. This suggests that not everyone has the same intercept. The residuals at this level are thought of as measurment error OR as something that can be explained by time varying predictors. Level 2 \\[ {\\beta}_{0j} = \\gamma_{00} + U_{0j} \\] Level 2 takes the intercept (or other parameter) at level 1 and breaks it down into an equation for each individual, j. An overall group average (the gamma) and a residual term specific to deviation around the intercept (see below). And two variance components: 1. a random effect of the intercept \\[ {U}_{0j} \\sim \\mathcal{N}(0, \\tau_{00}^{2}) \\] The subscript of the \\(U_{0j}\\) refers to the number of the parameter where 0 is the intercept, 1 is the first regression coefficient, and so on. The second refers to the individual, j. This random effect is normally distributed with a mean of zero and a variance of \\(\\tau\\) the residual error term \\[ {R}_{ij} \\sim \\mathcal{N}(0, \\sigma^{2}) \\] Much like in normal regression there is an error term for all of the variation we cannot account for. What is unique here is that we took that normal variation and split it into two components. One that is attributable to variation around the intercept \\({U}_{0j}\\) and a catch all residual. Technically this is not a growth model, nor one that is inherently longitudinal. However, it does serve as a nice starting point to identify random effects. 3.2.4 Putting it together \\[ {Y}_{ij} = \\gamma_{00} + U_{0j} + \\varepsilon_{ij} \\] Random as in they are sampled from some population and thus can vary. This means that your parameters (traditional regression parameters) are estimates and thus have error associated with them. This error is not like like a standard residual, which represents error for your overall model. Nor is it like the standard error for a point estimate. Random effects can best be thought of as deviation of individual regression lines from the group regression line. To facilitate the multiple assessments per person we will now use both i and j subscripts. We will see that the random effects are part of the overall error term in the model. Counterintutitively, the main focus of these types of models will be the fixed effects, with less attention paid to the random effects. That said, the random effects are necessary to account for dependency in the data. One can think about these models as normal fixed effects regressions, with the random effects there to account for the longitudinal nature of the data. They are made up of a number of standard regression equations, each for a single individual. Doing so side steps the trouble of having correlated errors, and thus allows us to interpret our findings without concern. 3.2.5 Empty model Level 1 \\[ {Y}_{ij} = \\beta_{0j} +\\varepsilon_{ij} \\] Note that we have multiple responses per individual j, noted with an i to refer to specific times. Level 1 is considered the within person model. Also note that the intercept has a subscript. In typical regression it does not. This suggests that not everyone has the same intercept. Level 2 \\[ {\\beta}_{0j} = \\gamma_{00} + U_{0j} \\] Level 2 takes the intercept (or other parameter) at level 1 and breaks it down into an equation for each individual, j. An overall group average (the gamma) and a residual term specific to deviation around the intercept (see below). And two variance components: 1. a random effect of the intercept \\[ {U}_{0j} \\sim \\mathcal{N}(0, \\tau_{00}^{2}) \\] The subscript of the \\(U_{0j}\\) refers to the number of the parameter where 0 is the intercept, 1 is the first regression coefficient, and so on. The second refers to the individual, j. This random effect is normally distributed with a mean of zero and a variance of \\(\\tau\\) the residual error term \\[ {R}_{ij} \\sim \\mathcal{N}(0, \\sigma^{2}) \\] Much like in normal regression there is an error term for all of the variation we cannot account for. What is unique here is that we took that normal variation and split it into two components. One that is attributable to variation around the intercept \\({U}_{0j}\\) and a catch all residual. Technically this is not a growth model, nor one that is inherently longitudinal. However, it does serve as a nice starting point to identify random effects. 3.2.6 Putting it together \\[ {Y}_{ij} = \\gamma_{00} + U_{0j} + \\varepsilon_{ij} \\] 3.2.7 ICC ICC: \\[\\frac{U_{0j}}{U_{0j}+ \\varepsilon_{ij}}\\] % variation between vs within person variance 3.3 Adding time Level 1: \\[ {Y}_{ij} = \\beta_{0j} + \\beta_{1j}X_{ij} + \\varepsilon_{ij} \\] Note how similar this looks like to a normal regression equation. Again, the differences are due to those pesky subscripts. Like before, think of this as a normal regression equation at the level of a person. Each person would have one of these equations with, in addition to a unique Y, X and residual, a unique \\(\\beta_{0}\\) and \\(\\beta_{1}\\). Level 2: \\[ {\\beta}_{0j} = \\gamma_{00} + U_{0j}\\] Level 2 takes the parameters at level 1 and decomposes them into a fixed component that reflects that average and then the individual deviations around that fixed effect. \\[ {\\beta}_{1j} = \\gamma_{10} \\] The new level 2 term refers to the first predictor in the level 1 regression equation ie the slope. This slope is fixed in that the level 2 equation only has a gamma term and no U residual term. Putting it together: \\[ {Y}_{ij} = \\gamma_{00} + \\gamma_{10} (X_{1j})+ U_{0j} + \\varepsilon_{ij} \\] Note that in computing a single individuals Y, it depends on the two fixed effects, the Xj, and the random effect for the intercept. 3.3.1 What does this look like graphically? And how does this differ from the random intercept model? What does this look like graphically? Can you draw out the sources of error? The random effects for each participant? The fixed effects? 3.3.2 Adding a random slope? What happens when we add a random slope? Level 1: \\[ {Y}_{ij} = \\beta_{0j} + \\beta_{1j}X_{1j} + \\varepsilon_{ij} \\] Level 2: \\[ {\\beta}_{0j} = \\gamma_{00} + U_{0j}\\] \\[ {\\beta}_{1j} = \\gamma_{10} + U_{1j} \\] \\[ {Y}_{ij} = \\gamma_{00} + \\gamma_{10}(X_{ij})+ U_{0j} + U_{1j}(X_{ij}) + \\varepsilon_{ij} \\] Can think of a persons score divided up into a fixed component as well as the random component. These random effects are likely related to one another. For example, if someone starts high on a construct they are then less likely to increase across time. This negative correlation can be seen in the residual structure, where the random effects are again normally distributed with a mean of zero, but this time one must also consider covariance in addition to variance. \\[ \\begin{pmatrix} {U}_{0j} \\\\ {U}_{1j} \\end{pmatrix} \\sim \\mathcal{N} \\begin{pmatrix} 0, &amp; \\tau_{00}^{2} &amp; \\tau_{01}\\\\ 0, &amp; \\tau_{01} &amp; \\tau_{10}^{2} \\end{pmatrix} \\] Note that it is possible to have a different error structure, one where there is no relationship between the intercept and the slope. We will discuss this more later in the semester. Right now just know that the default is to have correlated random effects. We also have the within subject variance term that accounts for deviations that are not accounted for by time variable and other level 1 predictors. \\[ {R}_{ij} \\sim \\mathcal{N}(0, \\sigma^{2}) \\] Note that it is possible to model these level 1 residuals with different structures. This specification implies that there is no correlation across an individuals residuals, once you account for level 1 predictors (ie growth trajectories). Having a specific level 1 autoregressive or other type of pattern is common in other treatments of longitudinal models (panel models) but is not necessary with growth models (but possible). This is the basic format of the growth model. It will be expanded later on by adding variables to the level 1 model and to the level 2 model. Adding to the level 1 model is only possible with repeated variables. Level 1 regression coefficients are added to the level 2 model. These coefficients are decomposed into a fixed effect, a random effect (possibly), and between person predictors. As with any regression model, each of these only have a single error term. 3.4 Individaul level random effects 3.4.1 Calculation of individaul level random effects Random effects are often thought in terms of variance components. We can see this if we think of individual level regressions for each person where we then have a mean and a variance for both the intercept or the slope. The greater the variance around the intercept and the slope means that not everyone starts at the same position and not everyone changes at the same rate. If you want to look at a specific person’s random effect you can think of it as a deviation from the fixed effect where subject 6’s intercept can be thought of as \\[ {\\beta}_{06} = \\gamma_{00} \\pm U_{06}\\] e.g 2.2 = 3 - .8 3.4.2 How are these random effects calculated? It isn’t as straightforward as calculating a slope for each person and then using the difference between that slope and the average slope. Instead, the estimates are partially pooled towards the overall mean of the sample, the fixed effect. We do this to get a better estimate of the parameters, the same way that using regression to predict y-hat given an X is better than binning X and calculating y-hat. More information = better. Why not full pooling? Because it ignores individaul differences in change. The result is that the variance of the change trajectories (using MLM) will be smaller than the variance of the fitted linear models. 3.4.3 random effects and residual (standard) assumptions Joint normal distribution of random effects Normally distributed residual Constant variance over time Random effects and residual are uncorrelated Both have a mean of zero Random effects and residual size will depend on predictors in the model. 3.4.4 Random effect decomposition Think of the original total variance in a scatter plot of our DVs. Adding random effects takes that variance and trims it down. The intercept only MLM seperates it into a level 1 variance (which at this stage is treated as error) and a level 2 random intercept variance. Creating a random slopes model takes the Level 1 residual variance and creates a new “pile” of explained variance. 3.5 working with models in R 3.5.1 basic lmer code The basic function we will work with is lmer from the lme4 package library(lme4) ## Loading required package: Matrix ## ## Attaching package: &#39;Matrix&#39; ## The following object is masked from &#39;package:tidyr&#39;: ## ## expand The package was developed to be similar to the lm function. The code will be similar to the formula for the combined model Code for empty model lmer(Y ~ 1 + (1 | subjects), data=example) Level 1 \\[ {Y}_{ij} = \\beta_{0j} +\\varepsilon_{ij} \\] Level 2 \\[ {\\beta}_{0j} = \\gamma_{00} + U_{0j} \\] Combined \\[ {Y}_{ij} = \\gamma_{00} + U_{0j} + \\varepsilon_{ij} \\] 1 is the way to reference the intercept. All additional fixed effects go outside the parentheses. Inside the parentheses are the random effects and residual terms. To the right of the vertical line is our level 1 residual term, which references the grouping variable. In this case, as with almost all longitudinal work, is the subject ID. To the left of the vertical line is the random effects we want to estimate. Right now this estimates only one random effect, one for the intercept. It is possible to suppress a random intercept by putting a zero instead of a 1. If you do not put anything there the 1 is implied. lmer(y ~ 1 + time + (1 + time | subjects), data=data) lmer(y ~ time + (time | subjects), data=data) # both are equivalent 3.5.2 Example mod.1 &lt;- lmer(SMN7 ~ 1 + (1 | ID), data=example) summary(mod.1) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: SMN7 ~ 1 + (1 | ID) ## Data: example ## ## REML criterion at convergence: -714.1 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.1575 -0.4728 -0.0232 0.4512 3.2750 ## ## Random effects: ## Groups Name Variance Std.Dev. ## ID (Intercept) 0.001823 0.04270 ## Residual 0.001302 0.03608 ## Number of obs: 225, groups: ID, 91 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 0.106972 0.005106 20.95 3.5.3 How to calculate ICC? 0.001823/(0.001823 + 0.001302) ## [1] 0.58336 3.6 Exploring beyond the summary class(mod.1) ## [1] &quot;lmerMod&quot; ## attr(,&quot;package&quot;) ## [1] &quot;lme4&quot; 3.6.1 what do the random effects look like? library(sjPlot) ## Warning in checkMatrixPackageVersion(): Package version inconsistency detected. ## TMB was built with Matrix version 1.2.10 ## Current Matrix version is 1.2.11 ## Please re-install &#39;TMB&#39; from source or restore original &#39;Matrix&#39; package sjp.lmer(mod.1, facet.grid = FALSE, sort = &quot;sort.all&quot;) Best Linear Unbiased Predictor = BLUP. More on this later. head(ranef(mod.1)) ## $ID ## (Intercept) ## 6 -0.0597240676 ## 29 -0.0101119687 ## 34 -0.0103698893 ## 36 -0.0035902640 ## 37 -0.0082433828 ## 48 0.0455797808 ## 53 -0.0222710793 ## 54 -0.0066548052 ## 58 -0.0060624543 ## 61 -0.0271347235 ## 66 -0.0123359896 ## 67 -0.0026491341 ## 69 0.0348398944 ## 71 -0.0486040243 ## 74 0.0484338355 ## 75 0.0224228634 ## 76 -0.0021583228 ## 78 0.0224780927 ## 79 -0.0054325535 ## 80 -0.0194707993 ## 81 0.0712662731 ## 82 0.0053695094 ## 85 -0.0532215424 ## 86 -0.0388885303 ## 87 -0.0387411472 ## 89 -0.0208712286 ## 91 0.0123812011 ## 92 -0.0078125821 ## 93 0.0430219016 ## 94 -0.0543390587 ## 96 0.0233440081 ## 97 -0.0497003276 ## 98 -0.0432302582 ## 99 0.0104394983 ## 101 0.0508032394 ## 102 -0.0104344307 ## 103 -0.0206130188 ## 104 -0.0482473609 ## 105 -0.0478231980 ## 106 -0.0028045239 ## 110 0.0418641246 ## 112 -0.0109089622 ## 114 -0.0549314097 ## 115 -0.0013505715 ## 116 0.0062422910 ## 120 0.0300499418 ## 122 0.0793976364 ## 125 0.0532803434 ## 127 -0.0105050866 ## 129 -0.0448207024 ## 135 0.0406255726 ## 136 -0.0364069792 ## 137 -0.0444890903 ## 140 -0.0153440709 ## 141 0.0770651692 ## 142 0.0817077386 ## 143 0.0072423981 ## 144 0.0001680065 ## 146 -0.0551006777 ## 149 -0.0137965477 ## 150 0.0091583791 ## 152 -0.0187707293 ## 153 0.0490992149 ## 155 -0.0233396072 ## 156 -0.0218943803 ## 159 -0.0488368935 ## 160 0.0024524455 ## 162 0.0911638808 ## 163 0.0155327007 ## 165 0.0320764602 ## 167 -0.0025217361 ## 169 0.0647586755 ## 171 -0.0397728293 ## 174 0.0259232134 ## 182 -0.0154177624 ## 187 -0.0581588782 ## 189 0.0348767402 ## 190 -0.0030744230 ## 193 0.0636533018 ## 194 0.0099321407 ## 201 0.0104848276 ## 204 0.0414352907 ## 205 0.0353188897 ## 208 0.0033367444 ## 209 -0.0346144188 ## 211 0.0168223034 ## 214 -0.0374146988 ## 219 0.0564683728 ## 222 -0.0262135788 ## 223 -0.0228606119 ## 229 -0.0484315898 head(coef(mod.1)) ## $ID ## (Intercept) ## 6 0.04724795 ## 29 0.09686005 ## 34 0.09660212 ## 36 0.10338175 ## 37 0.09872863 ## 48 0.15255179 ## 53 0.08470093 ## 54 0.10031721 ## 58 0.10090956 ## 61 0.07983729 ## 66 0.09463602 ## 67 0.10432288 ## 69 0.14181191 ## 71 0.05836799 ## 74 0.15540585 ## 75 0.12939488 ## 76 0.10481369 ## 78 0.12945011 ## 79 0.10153946 ## 80 0.08750121 ## 81 0.17823829 ## 82 0.11234152 ## 85 0.05375047 ## 86 0.06808348 ## 87 0.06823087 ## 89 0.08610079 ## 91 0.11935322 ## 92 0.09915943 ## 93 0.14999392 ## 94 0.05263296 ## 96 0.13031602 ## 97 0.05727169 ## 98 0.06374176 ## 99 0.11741151 ## 101 0.15777525 ## 102 0.09653758 ## 103 0.08635900 ## 104 0.05872465 ## 105 0.05914882 ## 106 0.10416749 ## 110 0.14883614 ## 112 0.09606305 ## 114 0.05204060 ## 115 0.10562144 ## 116 0.11321430 ## 120 0.13702196 ## 122 0.18636965 ## 125 0.16025236 ## 127 0.09646693 ## 129 0.06215131 ## 135 0.14759759 ## 136 0.07056503 ## 137 0.06248292 ## 140 0.09162794 ## 141 0.18403718 ## 142 0.18867975 ## 143 0.11421441 ## 144 0.10714002 ## 146 0.05187134 ## 149 0.09317547 ## 150 0.11613039 ## 152 0.08820128 ## 153 0.15607123 ## 155 0.08363241 ## 156 0.08507763 ## 159 0.05813512 ## 160 0.10942446 ## 162 0.19813589 ## 163 0.12250471 ## 165 0.13904847 ## 167 0.10445028 ## 169 0.17173069 ## 171 0.06719918 ## 174 0.13289523 ## 182 0.09155425 ## 187 0.04881314 ## 189 0.14184875 ## 190 0.10389759 ## 193 0.17062532 ## 194 0.11690415 ## 201 0.11745684 ## 204 0.14840730 ## 205 0.14229090 ## 208 0.11030876 ## 209 0.07235760 ## 211 0.12379432 ## 214 0.06955732 ## 219 0.16344039 ## 222 0.08075844 ## 223 0.08411140 ## 229 0.05854042 fixef(mod.1) ## (Intercept) ## 0.106972 How do these relate? Lets calculate ID 6 intercept random effect #coef = fixef + raneff # coef for ID = 6 is 0.04724795 0.106972 -0.0597240676 ## [1] 0.04724793 To get residuals and fitted scores library(broom) example.aug&lt;- augment(mod.1, data = example) ## Warning: Deprecated: please use `purrr::possibly()` instead ## Warning: Deprecated: please use `purrr::possibly()` instead ## Warning: Deprecated: please use `purrr::possibly()` instead ## Warning: Deprecated: please use `purrr::possibly()` instead ## Warning: Deprecated: please use `purrr::possibly()` instead # .fitted = predicted values # .resid = residuals/errors # .fixed = predicted values with no random effects 3.7 Adding time to the MLM 3.7.1 fixed slope mod.2f &lt;- lmer(SMN7 ~ 1 + week + (1 | ID), data=example) summary(mod.2f) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: SMN7 ~ 1 + week + (1 | ID) ## Data: example ## ## REML criterion at convergence: -675.4 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.2308 -0.4868 -0.0377 0.4542 3.2337 ## ## Random effects: ## Groups Name Variance Std.Dev. ## ID (Intercept) 0.001815 0.04261 ## Residual 0.001300 0.03606 ## Number of obs: 216, groups: ID, 88 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 0.104041 0.005733 18.147 ## week 0.001331 0.001755 0.758 ## ## Correlation of Fixed Effects: ## (Intr) ## week -0.426 What does this look like graphically? 3.7.2 Random slope mod.2 &lt;- lmer(SMN7 ~ 1 + week + (week | ID), data=example) summary(mod.2) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: SMN7 ~ 1 + week + (week | ID) ## Data: example ## ## REML criterion at convergence: -678.1 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -1.9333 -0.4702 -0.0040 0.4699 2.6797 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## ID (Intercept) 1.688e-03 0.041081 ## week 5.998e-05 0.007745 0.11 ## Residual 1.114e-03 0.033380 ## Number of obs: 216, groups: ID, 88 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 0.1047192 0.0054662 19.158 ## week 0.0004891 0.0019133 0.256 ## ## Correlation of Fixed Effects: ## (Intr) ## week -0.339 How does the intercept change from the random intercpet only model? It may change because the intercept is now conditional on time ie after accounting for time. It is not the predicted outcome when time = 0. You can think of the previous intercept as the grand mean of person means. If our week variable here changed across time then there would be a larger change in the intercept. How do you interpret week? How did the random effects change? 3.7.2.1 Why treating time is so important Time with a different scale. How do we interpret? And what changes? example$week.n &lt;- (example$week - 30) mod.2n &lt;- lmer(SMN7 ~ 1 + week.n + (week.n | ID), data=example) summary(mod.2n) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: SMN7 ~ 1 + week.n + (week.n | ID) ## Data: example ## ## REML criterion at convergence: -678.1 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -1.9333 -0.4702 -0.0040 0.4699 2.6797 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## ID (Intercept) 5.770e-02 0.240217 ## week.n 5.998e-05 0.007745 0.99 ## Residual 1.114e-03 0.033380 ## Number of obs: 216, groups: ID, 88 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 0.1193933 0.0557850 2.140 ## week.n 0.0004891 0.0019133 0.256 ## ## Correlation of Fixed Effects: ## (Intr) ## week.n 0.996 3.8 Random effects 3.8.1 Calcualtion of random effect confidence interval Conveys the predicted range around each fixed effect in which 95% of the sample individauls are predicted to fall. 95% random effect = fixed effect plus minus 1.96 * random standard deviation How to calcualte? 1. Intercept \\[ \\gamma_{00} \\pm 1.96 * \\tau_{U_{0j}} \\] 0.1193933 + (1.96 * 0.240217) ## [1] 0.5902186 0.1193933 - (1.96 * 0.240217) ## [1] -0.351432 Slope \\[ \\gamma_{10} \\pm 1.96 * \\tau_{U_{1j}} \\] 0.0004891 + (1.96 * 0.007745) ## [1] 0.0156693 0.0004891 - (1.96 * 0.007745) ## [1] -0.0146911 3.8.2 Individaul level random effects Are the intercept random effects the same as the model with only the intercept? Why or why not? head(ranef(mod.1)) ## $ID ## (Intercept) ## 6 -0.0597240676 ## 29 -0.0101119687 ## 34 -0.0103698893 ## 36 -0.0035902640 ## 37 -0.0082433828 ## 48 0.0455797808 ## 53 -0.0222710793 ## 54 -0.0066548052 ## 58 -0.0060624543 ## 61 -0.0271347235 ## 66 -0.0123359896 ## 67 -0.0026491341 ## 69 0.0348398944 ## 71 -0.0486040243 ## 74 0.0484338355 ## 75 0.0224228634 ## 76 -0.0021583228 ## 78 0.0224780927 ## 79 -0.0054325535 ## 80 -0.0194707993 ## 81 0.0712662731 ## 82 0.0053695094 ## 85 -0.0532215424 ## 86 -0.0388885303 ## 87 -0.0387411472 ## 89 -0.0208712286 ## 91 0.0123812011 ## 92 -0.0078125821 ## 93 0.0430219016 ## 94 -0.0543390587 ## 96 0.0233440081 ## 97 -0.0497003276 ## 98 -0.0432302582 ## 99 0.0104394983 ## 101 0.0508032394 ## 102 -0.0104344307 ## 103 -0.0206130188 ## 104 -0.0482473609 ## 105 -0.0478231980 ## 106 -0.0028045239 ## 110 0.0418641246 ## 112 -0.0109089622 ## 114 -0.0549314097 ## 115 -0.0013505715 ## 116 0.0062422910 ## 120 0.0300499418 ## 122 0.0793976364 ## 125 0.0532803434 ## 127 -0.0105050866 ## 129 -0.0448207024 ## 135 0.0406255726 ## 136 -0.0364069792 ## 137 -0.0444890903 ## 140 -0.0153440709 ## 141 0.0770651692 ## 142 0.0817077386 ## 143 0.0072423981 ## 144 0.0001680065 ## 146 -0.0551006777 ## 149 -0.0137965477 ## 150 0.0091583791 ## 152 -0.0187707293 ## 153 0.0490992149 ## 155 -0.0233396072 ## 156 -0.0218943803 ## 159 -0.0488368935 ## 160 0.0024524455 ## 162 0.0911638808 ## 163 0.0155327007 ## 165 0.0320764602 ## 167 -0.0025217361 ## 169 0.0647586755 ## 171 -0.0397728293 ## 174 0.0259232134 ## 182 -0.0154177624 ## 187 -0.0581588782 ## 189 0.0348767402 ## 190 -0.0030744230 ## 193 0.0636533018 ## 194 0.0099321407 ## 201 0.0104848276 ## 204 0.0414352907 ## 205 0.0353188897 ## 208 0.0033367444 ## 209 -0.0346144188 ## 211 0.0168223034 ## 214 -0.0374146988 ## 219 0.0564683728 ## 222 -0.0262135788 ## 223 -0.0228606119 ## 229 -0.0484315898 head(coef(mod.1)) ## $ID ## (Intercept) ## 6 0.04724795 ## 29 0.09686005 ## 34 0.09660212 ## 36 0.10338175 ## 37 0.09872863 ## 48 0.15255179 ## 53 0.08470093 ## 54 0.10031721 ## 58 0.10090956 ## 61 0.07983729 ## 66 0.09463602 ## 67 0.10432288 ## 69 0.14181191 ## 71 0.05836799 ## 74 0.15540585 ## 75 0.12939488 ## 76 0.10481369 ## 78 0.12945011 ## 79 0.10153946 ## 80 0.08750121 ## 81 0.17823829 ## 82 0.11234152 ## 85 0.05375047 ## 86 0.06808348 ## 87 0.06823087 ## 89 0.08610079 ## 91 0.11935322 ## 92 0.09915943 ## 93 0.14999392 ## 94 0.05263296 ## 96 0.13031602 ## 97 0.05727169 ## 98 0.06374176 ## 99 0.11741151 ## 101 0.15777525 ## 102 0.09653758 ## 103 0.08635900 ## 104 0.05872465 ## 105 0.05914882 ## 106 0.10416749 ## 110 0.14883614 ## 112 0.09606305 ## 114 0.05204060 ## 115 0.10562144 ## 116 0.11321430 ## 120 0.13702196 ## 122 0.18636965 ## 125 0.16025236 ## 127 0.09646693 ## 129 0.06215131 ## 135 0.14759759 ## 136 0.07056503 ## 137 0.06248292 ## 140 0.09162794 ## 141 0.18403718 ## 142 0.18867975 ## 143 0.11421441 ## 144 0.10714002 ## 146 0.05187134 ## 149 0.09317547 ## 150 0.11613039 ## 152 0.08820128 ## 153 0.15607123 ## 155 0.08363241 ## 156 0.08507763 ## 159 0.05813512 ## 160 0.10942446 ## 162 0.19813589 ## 163 0.12250471 ## 165 0.13904847 ## 167 0.10445028 ## 169 0.17173069 ## 171 0.06719918 ## 174 0.13289523 ## 182 0.09155425 ## 187 0.04881314 ## 189 0.14184875 ## 190 0.10389759 ## 193 0.17062532 ## 194 0.11690415 ## 201 0.11745684 ## 204 0.14840730 ## 205 0.14229090 ## 208 0.11030876 ## 209 0.07235760 ## 211 0.12379432 ## 214 0.06955732 ## 219 0.16344039 ## 222 0.08075844 ## 223 0.08411140 ## 229 0.05854042 fixef(mod.1) ## (Intercept) ## 0.106972 How do these relate? Lets calculate ID 6 intercept random effect #coef = fixef + raneff # 0.04724795 0.106972 -0.0597240676 ## [1] 0.04724793 To get residuals and fitted scores library(broom) example.aug&lt;- augment(mod.1, data = example) ## Warning: Deprecated: please use `purrr::possibly()` instead ## Warning: Deprecated: please use `purrr::possibly()` instead ## Warning: Deprecated: please use `purrr::possibly()` instead ## Warning: Deprecated: please use `purrr::possibly()` instead ## Warning: Deprecated: please use `purrr::possibly()` instead # .fitted = predicted values # .resid = residuals/errors # .fixed = predicted values with no random effects 3.8.3 adding time mod.2 &lt;- lmer(SMN7 ~ 1 + week + (week | ID), data=example) summary(mod.2) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: SMN7 ~ 1 + week + (week | ID) ## Data: example ## ## REML criterion at convergence: -678.1 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -1.9333 -0.4702 -0.0040 0.4699 2.6797 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## ID (Intercept) 1.688e-03 0.041081 ## week 5.998e-05 0.007745 0.11 ## Residual 1.114e-03 0.033380 ## Number of obs: 216, groups: ID, 88 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 0.1047192 0.0054662 19.158 ## week 0.0004891 0.0019133 0.256 ## ## Correlation of Fixed Effects: ## (Intr) ## week -0.339 Random effects another way re2 &lt;- ranef(mod.2) head(re2) ## $ID ## (Intercept) week ## 6 -0.0565693876 -0.0036946488 ## 29 -0.0084812502 -0.0012399695 ## 34 -0.0065599139 -0.0036267334 ## 36 -0.0071058058 0.0047521215 ## 37 -0.0075835906 0.0003777806 ## 48 0.0376074895 0.0079898155 ## 53 -0.0198932735 -0.0015608785 ## 54 0.0012968175 -0.0046566304 ## 58 0.0003752814 -0.0054295218 ## 61 -0.0252286991 -0.0013741827 ## 66 -0.0169264910 0.0022286289 ## 67 -0.0044351198 0.0020522124 ## 71 -0.0479007926 0.0002822149 ## 75 0.0214734474 0.0025669329 ## 76 -0.0011779173 0.0005878693 ## 78 0.0159038244 0.0031438858 ## 79 -0.0045545372 0.0005645243 ## 80 -0.0178969517 -0.0007156657 ## 81 0.0531021721 0.0082153576 ## 82 0.0041632658 0.0008113125 ## 85 -0.0522903314 -0.0013886487 ## 86 -0.0374677321 -0.0020088964 ## 87 -0.0353031581 -0.0042626635 ## 89 -0.0190640130 -0.0008531461 ## 91 0.0154744432 -0.0021927932 ## 92 -0.0051270484 -0.0012824204 ## 93 0.0377896360 0.0055463318 ## 94 -0.0531789999 -0.0005574516 ## 96 0.0253571389 -0.0004375991 ## 97 -0.0465464370 -0.0019519248 ## 98 -0.0387554767 -0.0027543679 ## 99 0.0097850196 0.0016153839 ## 101 0.0407311481 0.0116027111 ## 103 -0.0191071264 -0.0013253683 ## 104 -0.0465610719 -0.0034348580 ## 105 -0.0453195741 -0.0021916503 ## 106 0.0000399538 -0.0015452066 ## 110 0.0526597916 -0.0065614779 ## 112 -0.0054830896 -0.0041408032 ## 114 -0.0518752910 -0.0023741320 ## 115 -0.0006017030 0.0004675098 ## 116 0.0079162240 -0.0002937992 ## 120 0.0315638227 0.0021827362 ## 122 0.0784520272 0.0030226010 ## 125 0.0556521820 -0.0004022564 ## 127 -0.0103573035 0.0009944533 ## 129 -0.0438343313 -0.0011904028 ## 135 0.0451700269 -0.0027840979 ## 136 -0.0325726528 -0.0027537699 ## 137 -0.0430719716 -0.0026649436 ## 140 -0.0138988286 -0.0009470076 ## 141 0.0782760199 0.0011254590 ## 142 0.0765600112 0.0071699889 ## 143 0.0088016978 0.0001783473 ## 144 0.0005025170 0.0007246050 ## 146 -0.0519054115 -0.0030655524 ## 149 -0.0131560770 0.0001910980 ## 150 0.0132910150 -0.0028905846 ## 152 -0.0171937714 -0.0013668613 ## 153 0.0486487108 0.0022931844 ## 155 -0.0221220162 -0.0004933714 ## 156 -0.0204142314 -0.0004524692 ## 159 -0.0478271856 -0.0015437565 ## 160 0.0034589214 0.0001562946 ## 162 0.0877114808 0.0058969641 ## 163 0.0157575910 0.0011486111 ## 165 0.0324401589 0.0013198877 ## 167 -0.0005438261 -0.0009082554 ## 169 0.0657639666 0.0011933574 ## 171 -0.0347569068 -0.0047509419 ## 174 0.0279792237 -0.0004754973 ## 182 -0.0052334591 -0.0081368313 ## 187 -0.0560957612 -0.0019685294 ## 189 0.0345643054 0.0020406710 ## 190 -0.0016206743 -0.0003743260 ## 193 0.0585379718 0.0071783218 ## 194 0.0042424182 0.0066149744 ## 201 0.0118765581 -0.0001338794 ## 204 0.0379964146 0.0055305720 ## 205 0.0400395330 -0.0029403941 ## 208 0.0003049287 0.0043102513 ## 209 -0.0336676597 -0.0004229467 ## 211 0.0185609056 -0.0003189818 ## 214 -0.0367595828 -0.0001671127 ## 219 0.0454155727 0.0143718855 ## 222 -0.0194792229 -0.0063357893 ## 223 -0.0171899695 -0.0051032913 ## 229 -0.0425480075 -0.0060015683 random_params &lt;- tidy(mod.2, effect = &quot;ran_modes&quot;) head(random_params) ## level group term estimate std.error ## 1 101 ID (Intercept) 0.1454503656 0.018681947 ## 2 101 ID week 0.0120918470 0.006503031 ## 3 103 ID (Intercept) 0.0856120912 0.020552512 ## 4 103 ID week -0.0008362324 0.007484226 ## 5 104 ID (Intercept) 0.0581581457 0.020564594 ## 6 104 ID week -0.0029457221 0.007470732 Using simulations to get better estimates of confidence around our estimates library(merTools) ## Loading required package: arm ## Loading required package: MASS ## ## Attaching package: &#39;MASS&#39; ## The following object is masked from &#39;package:dplyr&#39;: ## ## select ## ## arm (Version 1.9-3, built: 2016-11-21) ## Working directory is /Users/jackson/Box Sync/5165 Applied Longitudinal Data Analysis/Longitudinal FEsim(mod.2) ## term mean median sd ## 1 (Intercept) 0.1049237738 0.104749324 0.005445517 ## 2 week 0.0003563293 0.000391386 0.001891124 re.sim &lt;- REsim(mod.2) head(re.sim) ## groupFctr groupID term mean median sd ## 1 ID 6 (Intercept) -0.056524049 -0.056520728 0.01853646 ## 2 ID 29 (Intercept) -0.009123963 -0.008834185 0.02100222 ## 3 ID 34 (Intercept) -0.008829130 -0.006406428 0.01971477 ## 4 ID 36 (Intercept) -0.007868465 -0.006664865 0.02263075 ## 5 ID 37 (Intercept) -0.008726581 -0.008822561 0.01890025 ## 6 ID 48 (Intercept) 0.039487076 0.040242828 0.02003486 This can be used to create CIs for each individaul random effect (and fixed effect). What is the confidence interval around person 6’s intercept estimate compared to person 2000 who has 25 repeated measurements? 3.8.4 caterpillar plots Look through these different methods of getting random effects. Note that they are not all exactly the same. caterpillar plots p1 &lt;- plotREsim(re.sim) p1 3.8.5 Density of individaul random effects p1.gg1 &lt;- re.sim %&gt;% filter(term == &quot;(Intercept)&quot;) ggplot(p1.gg1, aes(mean)) + geom_density() p1.gg2 &lt;- re.sim %&gt;% filter(term == &quot;week&quot;) ggplot(p1.gg2, aes(mean)) + geom_density() 3.9 comparing to a standard linear model lm.1 &lt;- lm(SMN7 ~ 1 + week, data=example) summary(lm.1) ## ## Call: ## lm(formula = SMN7 ~ 1 + week, data = example) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.099294 -0.039929 -0.005938 0.032715 0.169885 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.100161 0.005261 19.039 &lt;2e-16 *** ## week 0.004087 0.002563 1.595 0.112 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.05562 on 214 degrees of freedom ## (9 observations deleted due to missingness) ## Multiple R-squared: 0.01174, Adjusted R-squared: 0.007124 ## F-statistic: 2.543 on 1 and 214 DF, p-value: 0.1123 3.10 Other types of models Depending on your DV, you might not want to have a Gaussian sampling distribution. Instead you may want something like a Poisson or a negative binomial if you are using some sort of count data. You can do this somewhat with lme4. However, the BRMS package – which uses Bayesian estimation – has many more possibilities: geometric, log normal, weibull, exponential, gamma, Beta, hurdle Poisson/gamma/negative binomial, zero inflated beta/Poisson/negative binomial, cumulative. Maybe we will fit some of these later in the semester. 3.11 Matrix notation (as a way to help understand what is going on) \\[ y_{i} = X_{i}\\beta + Z_{i}b_{i} + \\varepsilon_{i} \\] Lets assume we have four time points. This formula is equivalent to: $$ \\[\\begin{bmatrix} y_{1j} \\\\ y_{2j} \\\\ y_{3j} \\\\ y_{4j} \\end{bmatrix}\\] \\[\\begin{bmatrix} 1 &amp; time_{1j} \\\\ 1 &amp; time_{2j} \\\\ 1 &amp; time_{3j} \\\\ 1 &amp; time_{4j} \\end{bmatrix}\\] \\[\\begin{bmatrix} \\beta_{0} \\\\ \\beta_{1} \\\\ \\beta_{2} \\\\ \\beta_{3} \\end{bmatrix}\\] \\[\\begin{bmatrix} 1 &amp; time_{1j} \\\\ 1 &amp; time_{2j} \\\\ 1 &amp; time_{3j} \\\\ 1 &amp; time_{4j} \\end{bmatrix}\\begin{bmatrix} b_{0j} \\\\ b_{1j} \\\\ \\end{bmatrix}\\] \\[\\begin{bmatrix} \\varepsilon_{1j} \\\\ \\varepsilon_{2j} \\\\ \\varepsilon_{3j} \\\\ \\varepsilon_{4j} \\end{bmatrix}\\] $$ X is the design matrix for fixed effects Z is the design matrix for random effects. \\(/beta\\) is a vector of fixed effects b is a vector of random effects \\(\\varepsilon\\) is a vector of residual error Note that all are subject specific (j) besides the vector of fixed effects The design matrix can be increased with the inclusion of other predictors (See next week) model.matrix(mod.2) ## (Intercept) week ## 1 1 0.0000000 ## 2 1 0.9479452 ## 3 1 1.8493151 ## 4 1 0.0000000 ## 5 1 1.0383562 ## 6 1 0.0000000 ## 7 1 2.3917808 ## 8 1 0.0000000 ## 9 1 2.9589041 ## 10 1 0.0000000 ## 11 1 1.9369863 ## 12 1 2.7917808 ## 13 1 0.0000000 ## 14 1 1.9068493 ## 15 1 2.9424658 ## 16 1 0.0000000 ## 17 1 3.2246575 ## 18 1 0.0000000 ## 19 1 1.8602740 ## 20 1 4.0109589 ## 21 1 0.0000000 ## 22 1 1.4082192 ## 23 1 2.4739726 ## 24 1 0.0000000 ## 25 1 2.6575342 ## 26 1 0.0000000 ## 27 1 2.9698630 ## 28 1 5.8109589 ## 29 1 0.0000000 ## 30 1 0.8931507 ## 31 1 1.6657534 ## 32 1 4.5232877 ## 35 1 0.0000000 ## 36 1 0.8657534 ## 37 1 1.7753425 ## 41 1 0.0000000 ## 42 1 2.9589041 ## 43 1 0.0000000 ## 44 1 1.0164384 ## 45 1 2.0328767 ## 46 1 0.0000000 ## 47 1 3.1232877 ## 48 1 5.9863014 ## 49 1 0.0000000 ## 50 1 2.0164384 ## 51 1 0.0000000 ## 52 1 3.8109589 ## 53 1 0.0000000 ## 54 1 3.1150685 ## 55 1 6.0493151 ## 56 1 0.0000000 ## 57 1 2.1369863 ## 58 1 3.2301370 ## 59 1 6.3178082 ## 60 1 0.0000000 ## 61 1 1.0712329 ## 62 1 0.0000000 ## 63 1 1.2109589 ## 64 1 0.0000000 ## 65 1 2.1369863 ## 66 1 0.0000000 ## 67 1 1.1397260 ## 68 1 2.0383562 ## 69 1 0.0000000 ## 70 1 0.9753425 ## 71 1 1.8657534 ## 72 1 0.0000000 ## 73 1 1.9260274 ## 74 1 3.0356164 ## 75 1 0.0000000 ## 76 1 1.9315068 ## 77 1 3.0438356 ## 78 1 0.0000000 ## 79 1 1.0054795 ## 80 1 2.2136986 ## 81 1 0.0000000 ## 82 1 0.9698630 ## 83 1 0.0000000 ## 84 1 1.0054795 ## 85 1 2.0575342 ## 86 1 2.9150685 ## 87 1 0.0000000 ## 88 1 0.9616438 ## 89 1 2.2986301 ## 90 1 3.3232877 ## 91 1 0.0000000 ## 92 1 1.0520548 ## 93 1 2.1835616 ## 94 1 3.0164384 ## 95 1 0.0000000 ## 96 1 0.9041096 ## 97 1 3.2657534 ## 102 1 0.0000000 ## 103 1 1.1534247 ## 104 1 0.0000000 ## 105 1 1.1945205 ## 106 1 0.0000000 ## 107 1 0.9671233 ## 108 1 2.2410959 ## 109 1 0.0000000 ## 110 1 1.0410959 ## 111 1 3.1123288 ## 112 1 0.0000000 ## 113 1 1.6164384 ## 114 1 3.8794521 ## 115 1 0.0000000 ## 116 1 0.9369863 ## 117 1 3.2273973 ## 118 1 0.0000000 ## 119 1 1.0602740 ## 120 1 3.1232877 ## 121 1 0.0000000 ## 122 1 1.0136986 ## 123 1 3.2986301 ## 124 1 0.0000000 ## 125 1 0.9178082 ## 126 1 3.1616438 ## 127 1 0.0000000 ## 128 1 1.0027397 ## 129 1 0.0000000 ## 130 1 0.9780822 ## 131 1 3.3041096 ## 132 1 0.0000000 ## 133 1 1.2054795 ## 134 1 3.0767123 ## 135 1 0.0000000 ## 136 1 1.0410959 ## 137 1 3.0739726 ## 138 1 0.0000000 ## 139 1 0.9232877 ## 140 1 0.0000000 ## 141 1 0.9589041 ## 142 1 2.9972603 ## 143 1 0.0000000 ## 144 1 1.0383562 ## 145 1 3.3890411 ## 146 1 0.0000000 ## 147 1 1.0739726 ## 148 1 0.0000000 ## 149 1 0.9095890 ## 150 1 0.0000000 ## 151 1 3.2602740 ## 152 1 0.0000000 ## 153 1 3.2273973 ## 154 1 0.0000000 ## 155 1 1.1205479 ## 156 1 0.0000000 ## 157 1 3.2082192 ## 158 1 0.0000000 ## 159 1 2.9972603 ## 160 1 0.0000000 ## 161 1 3.2794521 ## 162 1 0.0000000 ## 163 1 2.9917808 ## 164 1 0.0000000 ## 165 1 1.2356164 ## 166 1 0.0000000 ## 167 1 3.1780822 ## 168 1 0.0000000 ## 169 1 1.9123288 ## 170 1 0.0000000 ## 171 1 1.0520548 ## 172 1 2.9397260 ## 173 1 0.0000000 ## 174 1 0.9753425 ## 175 1 0.0000000 ## 176 1 3.0876712 ## 177 1 0.0000000 ## 178 1 1.0383562 ## 179 1 3.0109589 ## 180 1 0.0000000 ## 181 1 3.0876712 ## 182 1 0.0000000 ## 183 1 3.0493151 ## 184 1 0.0000000 ## 185 1 2.9342466 ## 186 1 0.0000000 ## 187 1 3.1315068 ## 188 1 0.0000000 ## 189 1 2.9342466 ## 190 1 0.0000000 ## 191 1 2.9780822 ## 192 1 0.0000000 ## 193 1 3.4575342 ## 194 1 0.0000000 ## 195 1 2.9945205 ## 196 1 0.0000000 ## 197 1 3.0520548 ## 198 1 0.0000000 ## 199 1 2.9972603 ## 200 1 0.0000000 ## 201 1 3.1041096 ## 202 1 0.0000000 ## 203 1 3.1863014 ## 204 1 0.0000000 ## 205 1 3.4547945 ## 206 1 0.0000000 ## 207 1 2.9369863 ## 208 1 0.0000000 ## 209 1 3.0849315 ## 210 1 0.0000000 ## 211 1 2.9945205 ## 212 1 0.0000000 ## 213 1 3.3150685 ## 214 1 0.0000000 ## 215 1 3.0876712 ## 216 1 0.0000000 ## 217 1 2.9945205 ## 218 1 0.0000000 ## 219 1 2.8273973 ## 220 1 0.0000000 ## 221 1 2.9178082 ## 222 1 0.0000000 ## 223 1 2.9479452 ## 224 1 0.0000000 ## 225 1 2.8465753 ## attr(,&quot;assign&quot;) ## [1] 0 1 ## attr(,&quot;msgScaleX&quot;) ## character(0) 3.12 Estimation Maximum likelihood estimation. Uses a likelihood function that describes the probability of observing the sample data as a function of the parameters. Attempts to maximize the function. REML vs ML Differences account for the fact that fixed effects are being estimated simultaously with th variance parameters. REML accounts for uncertainty in the fixed effects before estimating residual variance. REML attempts to maximize the likelihood of the residuals whereas ML the sample data. If you use REML you should be careful in testing fixed effects against eachother (more down below) 3.13 Testing significance (adapted from Ben Bolker) Methods for testing single parameters From worst to best: Wald Z-tests. Easy to compute. However, they are asymptotic approximations, assuming both that (1) the sampling distributions of the parameters are multivariate normal and that (2) the sampling distribution of the log-likelihood is (proportional to) χ2. Wald t-tests Likelihood ratio test. Markov chain Monte Carlo (MCMC) or parametric bootstrap confidence intervals 3.13.1 P values are not included Authors are not convinced of the utility of the general approach of testing with reference to an approximate null distribution. In general, it is not clear that the null distribution of the computed ratio of sums of squares is really an F distribution, for any choice of denominator degrees of freedom. While this is true for special cases that correspond to classical experimental designs (nested, split-plot, randomized block, etc.), it is apparently not true for more complex designs (unbalanced, GLMMs, temporal or spatial correlation, etc.). tl;dr: it gets messy with more complex models If you really want p values # library(lmerTest) 3.13.2 Likelhiood ratio test How much more likely the data is under a more complex model than under the simpler model (these models need to be nested to compare this). Log Likelihood (LL) is derived from ML estimation. Larger the LL the better the fit. Deviance compares two LLs. Current model and a saturated model (that fits data perfectly). Deviance = -2[LL current - LL saturated] LL saturated = 1 for MLMs (probability it will perfectly recapture data). log of 1 is 0. So this term drops out. Deviance = -2LL current model. Comparing 2 models is called a likelihood ration test. Need to have: 1. same data 2. nested models (think of constraining a parameter to zero) Distributed as chi-square with df equal to constraint differences between models. mod.2r &lt;- lmer(SMN7 ~ 1 + week + ( 1 | ID), data=example) summary(mod.2r) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: SMN7 ~ 1 + week + (1 | ID) ## Data: example ## ## REML criterion at convergence: -675.4 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.2308 -0.4868 -0.0377 0.4542 3.2337 ## ## Random effects: ## Groups Name Variance Std.Dev. ## ID (Intercept) 0.001815 0.04261 ## Residual 0.001300 0.03606 ## Number of obs: 216, groups: ID, 88 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 0.104041 0.005733 18.147 ## week 0.001331 0.001755 0.758 ## ## Correlation of Fixed Effects: ## (Intr) ## week -0.426 anova(mod.2, mod.2r) ## refitting model(s) with ML (instead of REML) ## Data: example ## Models: ## mod.2r: SMN7 ~ 1 + week + (1 | ID) ## mod.2: SMN7 ~ 1 + week + (week | ID) ## Df AIC BIC logLik deviance Chisq Chi Df Pr(&gt;Chisq) ## mod.2r 4 -686.93 -673.43 347.46 -694.93 ## mod.2 6 -685.45 -665.20 348.73 -697.45 2.5248 2 0.283 3.13.3 Likelihood tests for random effects Not listed in the output because it is hard to do this with variances. Remember variances do not have values below zero and thus the distributions get a wonky quickly. Needs mixture distributions (Cannot be easily done with chi square, for example) Can Do anova comparisons, though that falls to many similar problems as trying to do a Wald test. The sampling distribution of variance estimates is in general strongly asymmetric: the standard error may be a poor characterization of the uncertainty. Thus the best way to handle is to do bootstrapped estimates. 3.13.4 AIC and BIC AIC (Akaike’s Information Criterion) and the BIC (Bayesian Information Criterion) where “smaller is better.” This is the opposite of LL/Deviance As with the other types, these may give you wonky findings depending on some factors as they are related to LLs. AIC = 2(number of parameters) + (−2LL) BIC = ln(n)(number of parameters) + (−2LL) BIC penalizes models with more parameters more than AIC does. 3.13.5 MCMC More on this later. library(rstanarm) library(brms) library(mcmcsamp) #library(mcmcsamp) 3.13.6 Bootstraps Parametric bootstrap: confint(mod.1, method=&quot;boot&quot;, nsim=1000) ## Computing bootstrap confidence intervals ... ## 2.5 % 97.5 % ## .sig01 0.03437900 0.05119232 ## .sigma 0.03201764 0.04051648 ## (Intercept) 0.09665969 0.11679542 summary(mod.1) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: SMN7 ~ 1 + (1 | ID) ## Data: example ## ## REML criterion at convergence: -714.1 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.1575 -0.4728 -0.0232 0.4512 3.2750 ## ## Random effects: ## Groups Name Variance Std.Dev. ## ID (Intercept) 0.001823 0.04270 ## Residual 0.001302 0.03608 ## Number of obs: 225, groups: ID, 91 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 0.106972 0.005106 20.95 # uses SDs of random effects # sigma = residual standard error Comparing two models. fit the reduced model, then repeatedly simulate from it and compute the differences between the deviance of the reduced and the full model for each simulated data set. Compare this null distribution to the observed deviance difference. This procedure is implemented in the pbkrtest package. library(pbkrtest) #pb &lt;- PBmodcomp(mod.2,mod.2r) 3.14 Predictions and prediction intervals Predict function is deterministic and uses only the fixed effects (i.e. does not include random effects in the predictions). It does not do prediction in the typical sense where you are predicting new individual’s scores. Simulate is non-deterministic because it samples random effect values for all subjects and then samples from the conditional distribution. Simulation is needed to create true predictions. 3.14.1 Predictions and prediction intervals Predict function is deterministic and uses only the fixed effects (i.e. does not include random effects in the predictions). It does not do prediction in the typical sense where you are predicting new individuals’s scores. Simulate is non-deterministic because it samples random effect values for all subjects and then samples from the conditional distribution. Simulation is needed to create true preditions. Short of a fully Bayesian analysis, bootstrapping is the gold-standard for deriving prediction intervals/bands (ie where would a new person score given X), but the time required is typically high. In order to generate a proper prediction (for either a new person or a new observation within a person), a prediction must account for three sources of uncertainty in mixed models: the residual (observation-level) variance, the uncertainty in the fixed coefficients, and the uncertainty in the variance parameters for the random effects Does so by: 1. extracting the fixed and random coefficients 2. takes n draws from the multivariate normal distribution of the fixed and random coefficients (separately) 3. calculates the linear predictor for each row in newdata based on these draws, and 4. incorporates the residual variation then: 5. returns newdata with the lower and upper limits of the prediction interval and the mean or median of the simulated predictions library(merTools) # see also their shiny app: shinyMer(mod.1) PI &lt;- predictInterval(merMod = mod.2, newdata = example, level = 0.9, n.sims = 100, stat = &quot;median&quot;, include.resid.var = TRUE) head(PI) ## fit upr lwr ## 1 0.05308425 0.1183595 -0.00207539 ## 2 0.03924973 0.1016941 -0.02471092 ## 3 0.04589482 0.1067277 -0.02701423 ## 4 0.09898698 0.1629537 0.02230258 ## 5 0.09481121 0.1548031 0.02872763 ## 6 0.09965338 0.1668796 0.04177601 Nice for bringing in confidence bands around your prediction (And we might use this later) Broom offers the fitted (predicted) values already if you just want to plot your trajectory. But note that these are not typical prediction intervals (what happens if you get a new participant with a certain value of X). The bands fit in ggplot are for predicted \\(\\mu\\)|X Broom offers the fitted (predicted) values already if you just want to plot your trajectory. But note that these are not typical prediction intervals (what happens if you get a new particpant with a certain value of X). The bands fit in ggplot are for predicted \\(\\mu\\)|X P.gg &lt;- ggplot(example.aug, aes(x= week, y = .fitted)) + geom_point() + stat_smooth(method = &quot;lm&quot;) P.gg ## Warning: Removed 9 rows containing non-finite values (stat_smooth). ## Warning: Removed 9 rows containing missing values (geom_point). Can also explicitly simulate new data (rather than rely on another function to do so), which will be useful for power calculations later. In the simulated data, the subject means are different from the means in the original data because simulate samples by-subject random effect values using the variance components in the fitted model. sim.1&lt;- simulate(mod.2) head(sim.1) 3.15 Coefficient of determination equivalents Issue is: should you include or exclude variation of different random-effects terms? Can do a more Psuedo R2 by taking the difference in variance between model 1 and model 2 and deviding it by model 1. E.g,. residual variance in varying intercept model subtracted from growth model devided by intercept only model. (sigma(mod.1) - sigma(mod.2)) / sigma(mod.1) ## [1] 0.07480908 Proportion of variance explained by time. 3.15.1 batch analyses Can easily do a lot of models simulataniously. You do not need to use for loops. Check out dplyr::do as well as purrr::map. 3.16 Now you try: 1.Run linear models on all of your subjects (a basic regression). What is the average intercept, the average slope? Now run a mlm/lmer model with only a random intercept. What is the ICC? What does residual variance look like compared to linear model? Create a graph to show this effect. Introduce a fixed slope term. What is the difference in terms of the fixed effects estimates between this estimate and the previous? Of the residual standard error? Create a graph to show both fixed effects estimates and the CIs around them. Run an additional model with a random slope. How does this change compare to the previous model? Should you keep the random slope or not? Interpret the correlation between the slope and the intercept. Create a density plot of the random effects from your final model. Create a catepilar plot of the random effects. Is there any person that seems odd in terms of a large standard errors around intercept and slope estimates? Create a plot of the trajectory, along with a spaghetti plot of each person’s individual slope. Set the alpha level (transparency) on the individual slopes to make them easier to see. Create a plot of the trajectory, along with a spagehtti plot of each person’s individual slope. Set the alpha level (transperancy) on the individual slopes to make them easier to see. "],
["04-conditional.html", "Chapter 4 Conditional Predictors in growth models 4.1 Intercept effects 4.2 Slope and Intercept effects 4.3 Need for thinking about scaling your predictors 4.4 Time-varying covariates (TVCs) 4.5 Now you try", " Chapter 4 Conditional Predictors in growth models 4.1 Intercept effects level 1: \\[ {Y}_{ij} = \\beta_{0j} + \\beta_{1j}Time_{ij} + \\varepsilon_{ij} \\] Level 2: \\[ {\\beta}_{0j} = \\gamma_{00} + \\gamma_{01}G_{j} + U_{0j}\\] \\[ {\\beta}_{1j} = \\gamma_{10} + U_{1j} \\] Combined \\[ {Y}_{ij} = \\gamma_{00} + \\gamma_{01}G_{j}+ \\gamma_{10} (Time_{ij}) + U_{0j} + U_{1j}(Time_{ij}) + \\varepsilon_{ij} \\] \\[ \\begin{pmatrix} {U}_{0j} \\\\ {U}_{1j} \\end{pmatrix} \\sim \\mathcal{N} \\begin{pmatrix} 0, &amp; \\tau_{00}^{2} &amp; \\tau_{01}\\\\ 0, &amp; \\tau_{01} &amp; \\tau_{10}^{2} \\end{pmatrix} \\] \\[ {R}_{ij} \\sim \\mathcal{N}(0, \\sigma^{2}) \\] 4.1.1 Seperatinng these into intercept and slope \\[ {Y}_{ij} = [\\gamma_{00} + \\gamma_{01}G_{j}+ U_{0j}] + [(\\gamma_{10} + U_{1j})(Time_{ij})] + \\varepsilon_{ij} \\] Understanding how to re-write the equation will help for calculating estimated scores for your predictors in addition to being able to interpret the coefficients. For example, what would differ between the two equations for group coded = 0 versus a group = 1? 4.2 Slope and Intercept effects level 1: \\[ {Y}_{ij} = \\beta_{0j} + \\beta_{1j}Time_{ij} + \\varepsilon_{ij} \\] Level 2: \\[ {\\beta}_{0j} = \\gamma_{00} + \\gamma_{01}G_{j} + U_{0j}\\] \\[ {\\beta}_{1j} = \\gamma_{10} + \\gamma_{11}G_{j} + U_{1j} \\] Notice that when we combine Level 1 and Level 2, the intercept effects predictor becomes an interaction with time. This is called “cross level” interactions. Anytime you have a slope predictor that will be an interaction with time. I.e. we are asking does group status differ in their trajectory across time. One of these is a level 2 predictor and one is a level 1 predictor, thus a “cross level” interaction. Combined \\[ {Y}_{ij} = \\gamma_{00} + \\gamma_{01}G_{j}+ \\gamma_{10} (Time_{ij}) + \\gamma_{11}(G_{j}*Time_{ij}) + U_{0j} + U_{1j}(Time_{ij}) + \\varepsilon_{ij} \\] \\[ \\begin{pmatrix} {U}_{0j} \\\\ {U}_{1j} \\end{pmatrix} \\sim \\mathcal{N} \\begin{pmatrix} 0, &amp; \\tau_{00}^{2} &amp; \\tau_{01}\\\\ 0, &amp; \\tau_{01} &amp; \\tau_{10}^{2} \\end{pmatrix} \\] \\[ {R}_{ij} \\sim \\mathcal{N}(0, \\sigma^{2}) \\] Alternative combined \\[ {Y}_{ij} = [\\gamma_{00} + U_{0j} +\\gamma_{01}G_{j}] + [(\\gamma_{10} + \\gamma_{11}G_{j}+ U_{1j})(Time_{ij})] + \\varepsilon_{ij} \\] 4.2.1 Equations necessary for plotting The above equation can be simplified to get rid of the random effects to focus only on fixed effects portion. This is what you would use to get an estimated trajectory. \\[ \\hat{Y}_{ij} = [\\gamma_{00} +\\gamma_{01}G_{j}] + [(\\gamma_{10} + \\gamma_{11}G_{j})(Time_{ij})] \\] 4.3 Need for thinking about scaling your predictors Redux of how to interpret lower order terms in an interaction regression model. Changing the scale of your predictors changes the interpretation of your model. We already saw this with the intercept and how we scaled time. Things will be the same here but more so as you can see in the alternative combined equation. The intercept is always interpretted when the predictors are at zero. How can we interpret \\(\\beta_{0j}\\) if there is a level 1 predictor? The same logic applies for \\(\\beta_{1j}\\) in that one would want the fixed parameters to represent the average effect. How to center? You dont want to necessarily overweight people with more time points, so you should do centering in the wide format unless people have the same number of assessment points. 4.4 Time-varying covariates (TVCs) These are predictors that are assessed at level 1, which repeate. Note that there are some variables that are inherently level 2 (e.g. handedness), some that make sense more as a level 1 (e.g., mood) and some that could be considered either depending on your research question and/or your data (e.g. income). The latter type could concievably change across time (And thus be appropriate for a level 1 variable; tvc) but may not change at the rate of your construct or not be important. We will go into these in more depth in further weeks. The two points I want to discuss now are: These can be treated as another predictor with the effect of “controlling” for some TVC. Thus the regression coefficents in the model are conditional on this covariate. For example, if you had group status (yes, no) as your TVC the fixed effect for this would indicate the difference in slope for the two conditions. The slope coefficient would be that average slope (depending on how the covariate is scaled) The level 1 and level 2 models are not that different from previous forms. Here is an example model with a TVC. level 1: \\[ {Y}_{ij} = \\beta_{0j} + \\beta_{1j}Time_{ij} + \\beta_{2j}Job_{ij} +\\varepsilon_{ij} \\] Level 2: \\[ {\\beta}_{0j} = \\gamma_{00} + U_{0j}\\] \\[ {\\beta}_{1j} = \\gamma_{10} + U_{1j} \\] \\[ {\\beta}_{2j} = \\gamma_{20} \\] It is not necessary to specify a random effect for the TVC. Doing so would suggest that the differences in group membership within a person is not the same across people. For example, the effect of jobloss may effect some peoples development but not others. The key question is whether or not we think the variability across people in their TVC effects are systematic or not. If they are systematic, then maybe it is important to predict them by another variable. Can we go further and also fit a random effects term? This is a tricky issue in that this adds an additional parameter to the random effects and thus increases the number of covariances estimated. Often our data are not large enough to estimate the increased number of parameters and results in non-convergence. The introduction of the TVC can reduce \\(\\tau^2_{U_{0j}}\\), \\(\\tau^2_{U_{1j}}\\) and \\(\\varepsilon_{ij}\\). Normal time-invariant covariates only reduce the between person variance in intercept and slope and cannot account for the within person variance. But, but, because you are adding a new variable that changes the interpretation of the gamma terms, you may actually get increases in your variance components. As a result, it is difficult to directly compare models that have TVCs and those that do not. You may need to seperate between person and within person effects for TVC. This is done through various centering techniques. 4.5 Now you try Run a series of models using a time-invariant nominal covariate. a) where the covariate only predicts the intercept b) predicts both intercept and slope c) is rescaled eg centering. For all models, how does your model change from model to model. What is your final model? Introduce a time-invariant continuous covariate and run models a-c from #1. Graph both of your final models for the continuous and nominal models above. Calculate confidence intervals around your estimates for your final models Include both types of covariates in a single model. How does your interpretation of parameters change? If you have one available, introduce a time-varying covariate. "],
["05-poly-splines.html", "Chapter 5 Polynomial and Splines 5.1 Polynomaials 5.2 polynomial example 5.3 Splines aka piecewise 5.4 splines + polynomail = polynomial piecewise", " Chapter 5 Polynomial and Splines 5.1 Polynomaials level 1: \\[ {Y}_{ij} = \\beta_{0j} + \\beta_{1j}(Time_{ij} - \\bar{X)} + \\beta_{2j}(Time_{ij} - \\bar{X)}^2 + \\varepsilon_{ij} \\] Level 2: \\[ {\\beta}_{0j} = \\gamma_{00} + U_{0j}\\] \\[ {\\beta}_{1j} = \\gamma_{10} + U_{1j} \\] \\[ {\\beta}_{2j} = \\gamma_{20} + U_{2j} \\] 5.2 polynomial example rm(list = ls()) library(readr) cdrs &lt;- read_csv(&quot;~/Box Sync/5165 Applied Longitudinal Data Analysis/Longitudinal/cdrs.csv&quot;) ## Parsed with column specification: ## cols( ## mapid = col_integer(), ## exclude = col_character(), ## cdr = col_double(), ## testdate = col_integer() ## ) personality &lt;- read_csv(&quot;~/Box Sync/5165 Applied Longitudinal Data Analysis/Longitudinal/Subject_personality.csv&quot;) ## Parsed with column specification: ## cols( ## mapid = col_integer(), ## age = col_integer(), ## neodate = col_integer(), ## neuroticism = col_integer(), ## extraversion = col_integer(), ## openness = col_integer(), ## agreeablness = col_integer(), ## conscientiousness = col_integer(), ## gender = col_character() ## ) library(ggplot2) gg1 &lt;- ggplot(personality, aes(x = neodate, y = neuroticism, group = mapid)) + geom_line() gg1 ## Warning: Removed 1 rows containing missing values (geom_path). library(tidyverse) personality&lt;- personality %&gt;% group_by(mapid) %&gt;% arrange(neodate) %&gt;% mutate(wave = seq_len(n())) gg2 &lt;- ggplot(personality, aes(x = wave, y = neuroticism, group = mapid)) + geom_line() gg2 personality$neodate &lt;- as.Date(personality$neodate, origin = &quot;1900-01-01&quot;) ## Warning in strptime(xx, f &lt;- &quot;%Y-%m-%d&quot;, tz = &quot;GMT&quot;): unknown timezone ## &#39;default/America/Chicago&#39; gg3 &lt;- ggplot(personality, aes(x = neodate, y = neuroticism, group = mapid)) + geom_line() gg3 ## Warning: Removed 1 rows containing missing values (geom_path). ## convert to days from first assessment personality.wide &lt;- personality %&gt;% dplyr::select(mapid, wave, neodate) %&gt;% spread(wave, neodate) personality.wide$wave_1 &lt;- personality.wide$&#39;1&#39; personality.wide$wave_2 &lt;- personality.wide$&#39;2&#39; personality.wide$wave_3 &lt;- personality.wide$&#39;3&#39; personality.wide$wave_4 &lt;- personality.wide$&#39;4&#39; personality.wide$wave_5 &lt;- personality.wide$&#39;5&#39; personality.wide &lt;- personality.wide %&gt;% mutate (w_1 = (wave_1 - wave_1)/365, w_2 = (wave_2 - wave_1)/365, w_3 = (wave_3 - wave_1)/365, w_4 = (wave_4 - wave_1)/365, w_5 = (wave_5 - wave_1)/365) personality.long &lt;- personality.wide %&gt;% dplyr::select(mapid, w_1:w_5) %&gt;% gather(wave, year, -mapid) %&gt;% separate(wave, c(&#39;weeks&#39;, &#39;wave&#39; ), sep=&quot;_&quot;) %&gt;% dplyr::select(-weeks) personality.long$wave &lt;- as.numeric(personality.long$wave) personality &lt;- personality %&gt;% left_join(personality.long, by = c(&#39;mapid&#39;, &#39;wave&#39; )) gg4 &lt;- ggplot(personality, aes(x = year, y = neuroticism, group = mapid)) + geom_line() gg4 ## Don&#39;t know how to automatically pick scale for object of type difftime. Defaulting to continuous. ## Warning: Removed 1 rows containing missing values (geom_path). library(lme4) p1 &lt;- lmer(neuroticism ~ year + (1 | mapid), data=personality) summary(p1) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: neuroticism ~ year + (1 | mapid) ## Data: personality ## ## REML criterion at convergence: 13657.4 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.7877 -0.4675 -0.0227 0.4289 3.3166 ## ## Random effects: ## Groups Name Variance Std.Dev. ## mapid (Intercept) 42.16 6.493 ## Residual 15.65 3.956 ## Number of obs: 2105, groups: mapid, 1090 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 16.05632 0.22577 71.12 ## year -0.13204 0.03247 -4.07 ## ## Correlation of Fixed Effects: ## (Intr) ## year -0.247 library(lme4) personality.s &lt;- personality %&gt;% group_by(mapid) %&gt;% tally() %&gt;% filter(n &gt;=2) personality &lt;- personality %&gt;% filter(mapid %in% personality.s$mapid) p2 &lt;- lmer(neuroticism ~ year + (1 | mapid), data=personality) summary(p2) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: neuroticism ~ year + (1 | mapid) ## Data: personality ## ## REML criterion at convergence: 10396.9 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.7542 -0.5122 -0.0282 0.4698 3.3369 ## ## Random effects: ## Groups Name Variance Std.Dev. ## mapid (Intercept) 40.92 6.397 ## Residual 15.61 3.950 ## Number of obs: 1635, groups: mapid, 620 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 15.3797 0.2915 52.76 ## year -0.1083 0.0331 -3.27 ## ## Correlation of Fixed Effects: ## (Intr) ## year -0.320 p3 &lt;- lmer(neuroticism ~ year + (year | mapid), data=personality) summary(p3) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: neuroticism ~ year + (year | mapid) ## Data: personality ## ## REML criterion at convergence: 10389.2 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.7438 -0.4825 -0.0305 0.4443 3.3453 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## mapid (Intercept) 41.68558 6.4564 ## year 0.09824 0.3134 -0.10 ## Residual 14.25791 3.7760 ## Number of obs: 1635, groups: mapid, 620 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 15.37238 0.29135 52.76 ## year -0.10272 0.03602 -2.85 ## ## Correlation of Fixed Effects: ## (Intr) ## year -0.317 5.2.1 importance of centering personality$year &lt;- as.numeric(personality$year) p4 &lt;- lmer(neuroticism ~ year + I(year^2) + (year | mapid), data=personality) summary(p4) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: neuroticism ~ year + I(year^2) + (year | mapid) ## Data: personality ## ## REML criterion at convergence: 10395.8 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.7663 -0.4836 -0.0251 0.4422 3.3258 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## mapid (Intercept) 41.72924 6.4598 ## year 0.09815 0.3133 -0.10 ## Residual 14.26218 3.7765 ## Number of obs: 1635, groups: mapid, 620 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 15.324317 0.297094 51.58 ## year -0.031791 0.092091 -0.35 ## I(year^2) -0.008789 0.010490 -0.84 ## ## Correlation of Fixed Effects: ## (Intr) year ## year -0.300 ## I(year^2) 0.194 -0.920 # woah, how do I interpret this? WHy all of a sudden non-sig? # what would happen if I changed my time metric? library(psych) ## ## Attaching package: &#39;psych&#39; ## The following object is masked from &#39;package:merTools&#39;: ## ## ICC ## The following objects are masked from &#39;package:arm&#39;: ## ## logit, rescale, sim ## The following objects are masked from &#39;package:ggplot2&#39;: ## ## %+%, alpha describe(personality$year) ## vars n mean sd median trimmed mad min max range skew kurtosis ## X1 1 1635 3.1 3.29 2.45 2.66 3.63 0 12.78 12.78 0.8 -0.41 ## se ## X1 0.08 personality$year.c &lt;- personality$year - 3.1 p5 &lt;- lmer(neuroticism ~ year.c + I(year.c^2) + (year.c | mapid), data=personality) summary(p5) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: neuroticism ~ year.c + I(year.c^2) + (year.c | mapid) ## Data: personality ## ## REML criterion at convergence: 10395.8 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.7663 -0.4836 -0.0251 0.4422 3.3258 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## mapid (Intercept) 41.43047 6.4367 ## year.c 0.09815 0.3133 0.05 ## Residual 14.26218 3.7765 ## Number of obs: 1635, groups: mapid, 620 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 15.141299 0.296073 51.14 ## year.c -0.086285 0.041061 -2.10 ## I(year.c^2) -0.008789 0.010490 -0.84 ## ## Correlation of Fixed Effects: ## (Intr) year.c ## year.c 0.226 ## I(year.c^2) -0.353 -0.480 5.2.2 random terms fitting a random slope plus a random quadratic leads to difficulties ie non-congergence. What does this model say? p6 &lt;- lmer(neuroticism ~ year + I(year^2) + ( I(year^2) | mapid), data=personality) ## Warning in checkConv(attr(opt, &quot;derivs&quot;), opt$par, ctrl = control$checkConv, : Model is nearly unidentifiable: very large eigenvalue ## - Rescale variables? summary(p6) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: neuroticism ~ year + I(year^2) + (I(year^2) | mapid) ## Data: personality ## ## REML criterion at convergence: 10398.9 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.7737 -0.4938 -0.0201 0.4526 3.3479 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## mapid (Intercept) 4.078e+01 6.38611 ## I(year^2) 4.854e-04 0.02203 0.02 ## Residual 1.506e+01 3.88052 ## Number of obs: 1635, groups: mapid, 620 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 15.321512 0.296443 51.68 ## year -0.026969 0.093406 -0.29 ## I(year^2) -0.009489 0.010731 -0.88 ## ## Correlation of Fixed Effects: ## (Intr) year ## year -0.300 ## I(year^2) 0.202 -0.928 ## convergence code: 0 ## Model is nearly unidentifiable: very large eigenvalue ## - Rescale variables? 5.3 Splines aka piecewise Fit more than 1 trajectory. Best to use when we have a reason for a qualitative difference at some identified time point. For example, before your health event you may have a different trajectory than after it and thus you would want to model two seperate trajectories. Splines allow you to do this in a single model. You can do this in simple regression and the logic follows for growth models. We simply replace time with dummy variables that represent different segments we wish to model. The point of separation is called a knot. You can have as many as you want and these can be pre-specified (usually for our case) or in more advanced treatments have the data specify it for you. 5.3.1 seperate curves The most common is to create different trajectories that change across knots. The easiest example is to take your time variable and transform it into a Time1 and time2, that represent the different time periods. This is easiest to see if we choose our wave variable as our time metric, though you do not have to necessarily do it this way. t1 &lt;- tribble( ~time, ~t0, ~t1,~t2,~t3,~t4,~t5, &quot;time 1&quot;, 0, 1,2,2,2,2, &quot;time 2&quot;, 0, 0,0,1,2,3 ) t1 ## # A tibble: 2 x 7 ## time t0 t1 t2 t3 t4 t5 ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 time 1 0 1 2 2 2 2 ## 2 time 2 0 0 0 1 2 3 The idea is that once you hit the knot your value stays the same. Same logic for the second knot, until you get to that knot you dont have a trajectory. 5.3.2 incremental curves This can be contrasted with a different type of coding, called incremental. Here the first trajectory keeps going, whereas the second trajectory starts at the position of the knot. t2 &lt;- tribble( ~time, ~t0, ~t1,~t2,~t3,~t4,~t5, &quot;time 1&quot;, 0, 1,2,3,4,5, &quot;time 2&quot;, 0, 0,0,1,2,3 ) t2 ## # A tibble: 2 x 7 ## time t0 t1 t2 t3 t4 t5 ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 time 1 0 1 2 3 4 5 ## 2 time 2 0 0 0 1 2 3 The two coding schemes propose the same type of trajectoy, the only thing that differes is the interpretation of the coefficients. In the first, the two slope coefficients represent the actual slope in the respective time period. In the second, the coefficient for time 2 represents the deviation from the slope in period 1. The positive of this second method is you can easily test whether these two slopes are different from one another. level 1: \\[ {Y}_{ij} = \\beta_{0j} + \\beta_{1j}Time1_{ij} + \\beta_{2j}Time2_{ij} + \\varepsilon_{ij} \\] Level 2: \\[ {\\beta}_{0j} = \\gamma_{00} + U_{0j} \\] \\[ {\\beta}_{1j} = \\gamma_{10} + U_{1j} \\] \\[ {\\beta}_{2j} = \\gamma_{20} + U_{2j} \\] 5.3.3 splines example personality$time1 &lt;- recode(personality$wave, &#39;1&#39; = 0 , &#39;2&#39; = 1, &#39;3&#39; = 1, &#39;4&#39; = 1,&#39;5&#39; = 1) personality$time2 &lt;- recode(personality$wave, &#39;1&#39; = 0 , &#39;2&#39; = 0, &#39;3&#39; = 1, &#39;4&#39; = 2,&#39;5&#39; = 3) p7 &lt;- lmer(conscientiousness ~ time1 + time2 + (time1 | mapid) , data=personality) summary(p7) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: conscientiousness ~ time1 + time2 + (time1 | mapid) ## Data: personality ## ## REML criterion at convergence: 10003.8 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -5.2557 -0.4068 0.0272 0.4304 4.5853 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## mapid (Intercept) 32.98 5.743 ## time1 4.73 2.175 -0.13 ## Residual 10.70 3.271 ## Number of obs: 1635, groups: mapid, 620 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 34.1871 0.2654 128.80 ## time1 -0.5365 0.2018 -2.66 ## time2 0.2184 0.1561 1.40 ## ## Correlation of Fixed Effects: ## (Intr) time1 ## time1 -0.370 ## time2 0.000 -0.301 gg5 &lt;- ggplot(personality, aes(x = wave, y = conscientiousness, group = mapid)) + stat_smooth(method = &#39;lm&#39;, formula = y ~ poly(x,2, raw = TRUE),data = personality, aes(x = wave, y = conscientiousness, group=1)) + scale_y_continuous(limits = c(30, 40)) gg5 ## Warning: Removed 609 rows containing non-finite values (stat_smooth). 5.4 splines + polynomail = polynomial piecewise \\[ {Y}_{ij} = \\beta_{0j} + \\beta_{1j}Time1_{ij} + \\beta_{2j}Time1_{ij}^2 + \\beta_{3j}Time2_{ij} + \\varepsilon_{ij} \\] Level 2: \\[ {\\beta}_{0j} = \\gamma_{00} + U_{0j} \\] \\[ {\\beta}_{1j} = \\gamma_{10} + U_{1j} \\] \\[ {\\beta}_{2j} = \\gamma_{20} + U_{2j} \\] \\[ {\\beta}_{3j} = \\gamma_{30} + U_{3j}\\] "],
["06-intensive-longitudinal.html", "Chapter 6 Intensive Longitudinal Designs 6.1 within versus between person processes 6.2 Centering", " Chapter 6 Intensive Longitudinal Designs Often we are not interested in looking at trajectories across time. Instead we are interested in using time as a means to look at fluctuations in our DV. Fluctuations are especially helpful to understand within person processes versus between person processes. Typically, the focus of these sorts of analyses are with level 1 (time varying) covariates ie variables you have assessed more than once. The questions that can be answered with this design are: Are there associations between 6.1 within versus between person processes 6.2 Centering 6.2.1 within person Useful for level 1, necessary for seperating within person and between person effects. 6.2.2 Grand mean Useful for level 2, but is not necessary. If you grand mean center at level 2, then the interpretation is more closely related to regression. Here the slope would then be calculated as the average of the population whereas the intercept would be calcualted as the average (ie 0) for predictors. Can also grand mean center level 1. "],
["07-SEM.html", "Chapter 7 SEM 7.1 Structural Equation Modeling 7.2 Latent variables 7.3 goal of SEM 7.4 Setting the scale and defining variables 7.5 lavaan 7.6 additional SEM details 7.7 Types of longitudinal models other than growth models (brief intro) 7.8 SEM Growth models 7.9 Measurement Invariance (MI) 7.10 second order growth model 7.11 Multple groups 7.12 Missing data 7.13 Power 7.14 Now you try", " Chapter 7 SEM 7.1 Structural Equation Modeling SEM is the broader umbrella from the GLM. With it we are able to do two interesting this: Fit a latent measurement model (e.g., CFA) Fit a structural model (e.g,. path analysis) 7.2 Latent variables A latent variable is assumes to exist but we cannot directly measure (see) it. Sounds like psychological variables! The reason why items/indicators/measures correlate is assumed to be due to this latent variable. For example, why does Sally like to go to parties, likes to talk a lot, and always tends to be a in a good mood? Maybe it is because her high levels of extraversion ( a latent variable that we cannot directly measure) is causing these tendencies. Key point: the variable/construct itself is not measurable, but the manifestations caused by the variable are measurable/observable. Interesting point: because variables are assumed to be causing indicators of the variable, SEM is sometimes referred to as causal modeling. (Also because in path models a directional relationship is hypothesized) Note that we cannot get any closer to causality than we can with regression. 7.2.1 More pretty pictures Circles = latent variables Boxes = observed indicator variables two headed arrows = correlations/covariances/variances single head arrows = regressions triangle = means 7.2.2 Classical test theory interpretation How can we think of a latent construct: Latent construct = what the indicators share in common The indicators represent the sum of True Score variance + Item specific variance + Random error The variance of the latent variable represents the amount of common information in the latent variable The residual errors (sometimes referred to as disturbances) represent the amount of information unique to each indicator. A combination of error and item-specific variance. 7.2.3 Generizability interpretation of latent variables Same as above, but… True score variance can be thought of as consisting as a combination of 1. Construct variance- this is the truest true score variance 2. Method variance- see Campbell and Fiske or sludge factor of Meehl. 3. Occasion- important for longitudinal, aging, and cohort analyses–and for this class. For longitudinal models, occasion specific variance can lead to biased estimates. We want to separate the time specific variance from the overall construct variance. Or, we want to make sure that the time specific variance doesn’t make it appear that a construct is changing when really it is not. 7.2.3.1 Formative indicators These pretty pictures imply that the latent variables “cause” the indicators. These are referred to as reflexive indicators and are the standard way of creating latent variables. However, there is another approach, formative indicators, were indicators “cause” the latent variable. Or, in other words, the latent variable doesn’t actually exist. It is not real, only a combination of variables. An example of this is SES. 7.2.4 measurement error A major advantage is that each latent variable does not contain measurement error. It is as is if we measured our variable with an alpha = 1. What does that do? Well, ideally that gets us closer to the population model, which could yield higher R2 and parameter estimates. How does this happen? It is a direct result of capturing what is shared among the indicators. The measurement error associated with each indicator is uncorrelated with the latent variable. Think about how this situation differs from creating a composite among variables. Think about how this differs from creating a factor score among variables within a simple factor analyses approach. How are all three different and similar? What does it mean if the error variances are correlated with one another? 7.2.5 regarding means SEM is also known as covariance structure analysis. You can do SEM using only variance-covariance matrices. These do not necessarily involve any direct information about their means. Means in SEM are optional. More later on how we define the mean of a latent variable if we do not assess the mean of the variable in the first place 7.3 goal of SEM Creation of a model that specifies a certain relationship among variables. This is done by creating a measurement or path model that we think is driven by the data generating process we are trying to study. In addition to setting the measurement model and paths we may want to put apriori constraining parameters (variances/covarainces/regressions) to reflect how we think variables are related. E.g., Should these two variables be correlated or not? Then we use or ML algorithm to get our model implied covariances/means as close as possible to the observed covariances/means. E.g., we specified no correlation between these two variables, does that then change how their indicators relate to their latent variable? 7.3.1 What questions can be asked? Too many to mention. This is a really flexible approach to your data. Might as well always think about problems in terms of SEM because is subsumes regression models. Specifically, however, SEM can handle any time of measured DV/IV or construct/indicators. If you have categorical indicators you can do SEM. However, it is hard to measure change using categorical indicators. But, categorical indicators are used for many latent variable models such as in measuring psychopathology. If you have a categorical construct you can also do SEM. Here it is called latent transition analysis (if you also had categorical indicators) or latent class / latent mixture modeling if you had continuous indicators (i am counting ordinal as continuous). 7.4 Setting the scale and defining variables We are trying to measure clouds. How can we do this given that they are always moving? Need to define a parameter a latent variable because there is no inherent scale of measurement. Largely irrelevant as to what scale is chosen. Serves to establish a point of reference in interpret other parameters. 3 options: Fixed factor. Here you fix the variance of the latent variable to 1 (standardized) Marker variable. Here you fix one factor loading to 1. All other loadings are relative to this loading. Effect coding. Here you constrain loading to average to 1. This will be helpful for us as we can then put the scale of measurement into our original metric. For longitudinal models this is helpful in terms of how to interpret the amount of change. 7.4.1 identification All of this works only if you have enough data to be able to create new constructs. As a rule of thumb you need at least three indicators for each latent variable. More specifically, you need to compare the number of knows (variances and covariances) to the unknowns (model parameters). Foe example, a three indicator latent variable has 7 unknowns. 3 Loadings, 3 error variances and the variance of the latent variable The covariance matrix has 6 data points. Thus we need to add in one more known, in this case a fixed factor or a marker variable. 7.4.2 types of identification just identified is where the number of knowns equal unknowns. also known as saturated model. over identified is when you have more knowns than unknowns (this is good) under identified is when you have problems and have more unknowns than knowns. this is because there is more than one solution available and the algorithm cannot decide e.g,. 2 + X = Y. If we add a constraint or a known value then it becomes manageable 2 + X = 12 7.4.2.1 degrees of freedom knowns - unknowns = df Note that df in this case will not directly relate to sample size 7.5 lavaan Easy to use SEM program in R library(lavaan) ## This is lavaan 0.5-23.1097 ## lavaan is BETA software! Please report any bugs. ## ## Attaching package: &#39;lavaan&#39; ## The following object is masked from &#39;package:psych&#39;: ## ## cor2cov Does most of what other sem packages do and just as well except for: Multilevel SEM Latent class models/mixture models Two useful add on packages are library(semTools) ## ## ############################################################################### ## This is semTools 0.4-14 ## All users of R (or SEM) are invited to submit functions or ideas for functions. ## ############################################################################### ## ## Attaching package: &#39;semTools&#39; ## The following object is masked from &#39;package:psych&#39;: ## ## skew library(semPlot) A related package that uses similar syntax for Bayesian models is library(blavaan) ## Loading required package: runjags ## ## Attaching package: &#39;runjags&#39; ## The following object is masked from &#39;package:tidyr&#39;: ## ## extract ## This is blavaan 0.2-4 ## blavaan is more BETA than lavaan! 7.5.1 lavaan language All you need to know (almost) is here: http://lavaan.ugent.be/tutorial/ A quick recap of that: Paths between variables is the same as our linear model syntax y ~ x1 + x2 + x3 ~ can be read as “is regressed on” defining latent variables y =~ x1 + x2 + x3 =~ can be read as “measured by” Y is measured by the variables x1 - x3. This will define the factor loadings. defining variances and covariances y ~~ x1 Y covaries with X1. The beautify of lavaan is that it will decide for you if you are interested in a variance or a covariance or a residual (co)variance. intercept y ~ 1 Much as we saw with our lmer models where 1 served an important role, 1 here also is special in that it references the mean (intercept) of the variable. This will come in handy when we want to constrain or make the means of variables similar to one another. constraints y =~ NA*x1 + 1*x2 + a*x3 + a*x4 NA serves to free a lavaan imposed constraint. Here, the default is to set the first factor loading to 1 to define the latent variable. NA* serves to say there is no constraint. 1* pre-multiples the loading by a particular number. In this case it is 1, to define the latent variable, but it could be any number. R doesn’t know if it makes sense or not. a* (or and other character strings) serves as an equality constraint by estimating the same parameter for each term with that label. In this case x3 and x4 will have the same factor loading, referred to as a. 7.5.2 How to run lavaan Specify your model Fit the model Display the summary output #1. Specify your model HS.model &lt;- &#39; visual =~ x1 + x2 + x3 textual =~ x4 + x5 + x6 speed =~ x7 + x8 + x9 &#39; #2. Fit the model fit &lt;- cfa(HS.model, data=HolzingerSwineford1939) # other functions include sem, growth, and lavaan. All have different defaults (See below). we will use growth a lot. #3. Display the summary output summary(fit, fit.measures=TRUE) 7.5.3 lavaan defaults First, by default, the factor loading of the first indicator of a latent variable is fixed to 1, thereby fixing the scale of the latent variable. Second, residual variances are added automatically. And third, all exogenous latent variables are correlated by default. lets work with a dataset from the lavaan package HolzingerSwineford1939 &lt;- HolzingerSwineford1939 mod.1 &lt;- &#39;visual =~ x1 + x2 + x3 textual =~ x4 + x5 + x6 speed =~ x7 + x8 + x9&#39; fit.1 &lt;- cfa(mod.1, data=HolzingerSwineford1939) summary(fit.1, fit.measures=TRUE, standardized=TRUE) ## lavaan (0.5-23.1097) converged normally after 35 iterations ## ## Number of observations 301 ## ## Estimator ML ## Minimum Function Test Statistic 85.306 ## Degrees of freedom 24 ## P-value (Chi-square) 0.000 ## ## Model test baseline model: ## ## Minimum Function Test Statistic 918.852 ## Degrees of freedom 36 ## P-value 0.000 ## ## User model versus baseline model: ## ## Comparative Fit Index (CFI) 0.931 ## Tucker-Lewis Index (TLI) 0.896 ## ## Loglikelihood and Information Criteria: ## ## Loglikelihood user model (H0) -3737.745 ## Loglikelihood unrestricted model (H1) -3695.092 ## ## Number of free parameters 21 ## Akaike (AIC) 7517.490 ## Bayesian (BIC) 7595.339 ## Sample-size adjusted Bayesian (BIC) 7528.739 ## ## Root Mean Square Error of Approximation: ## ## RMSEA 0.092 ## 90 Percent Confidence Interval 0.071 0.114 ## P-value RMSEA &lt;= 0.05 0.001 ## ## Standardized Root Mean Square Residual: ## ## SRMR 0.065 ## ## Parameter Estimates: ## ## Information Expected ## Standard Errors Standard ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## visual =~ ## x1 1.000 0.900 0.772 ## x2 0.554 0.100 5.554 0.000 0.498 0.424 ## x3 0.729 0.109 6.685 0.000 0.656 0.581 ## textual =~ ## x4 1.000 0.990 0.852 ## x5 1.113 0.065 17.014 0.000 1.102 0.855 ## x6 0.926 0.055 16.703 0.000 0.917 0.838 ## speed =~ ## x7 1.000 0.619 0.570 ## x8 1.180 0.165 7.152 0.000 0.731 0.723 ## x9 1.082 0.151 7.155 0.000 0.670 0.665 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## visual ~~ ## textual 0.408 0.074 5.552 0.000 0.459 0.459 ## speed 0.262 0.056 4.660 0.000 0.471 0.471 ## textual ~~ ## speed 0.173 0.049 3.518 0.000 0.283 0.283 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .x1 0.549 0.114 4.833 0.000 0.549 0.404 ## .x2 1.134 0.102 11.146 0.000 1.134 0.821 ## .x3 0.844 0.091 9.317 0.000 0.844 0.662 ## .x4 0.371 0.048 7.779 0.000 0.371 0.275 ## .x5 0.446 0.058 7.642 0.000 0.446 0.269 ## .x6 0.356 0.043 8.277 0.000 0.356 0.298 ## .x7 0.799 0.081 9.823 0.000 0.799 0.676 ## .x8 0.488 0.074 6.573 0.000 0.488 0.477 ## .x9 0.566 0.071 8.003 0.000 0.566 0.558 ## visual 0.809 0.145 5.564 0.000 1.000 1.000 ## textual 0.979 0.112 8.737 0.000 1.000 1.000 ## speed 0.384 0.086 4.451 0.000 1.000 1.000 Lets use a fixed factor approach rather than a marker variable approach mod.2 &lt;- &#39;visual =~ x1 + x2 + x3 textual =~ x4 + x5 + x6 speed =~ x7 + x8 + x9&#39; fit.2 &lt;- cfa(mod.2, std.lv=TRUE, data=HolzingerSwineford1939) summary(fit.2, fit.measures=TRUE, standardized=TRUE) ## lavaan (0.5-23.1097) converged normally after 22 iterations ## ## Number of observations 301 ## ## Estimator ML ## Minimum Function Test Statistic 85.306 ## Degrees of freedom 24 ## P-value (Chi-square) 0.000 ## ## Model test baseline model: ## ## Minimum Function Test Statistic 918.852 ## Degrees of freedom 36 ## P-value 0.000 ## ## User model versus baseline model: ## ## Comparative Fit Index (CFI) 0.931 ## Tucker-Lewis Index (TLI) 0.896 ## ## Loglikelihood and Information Criteria: ## ## Loglikelihood user model (H0) -3737.745 ## Loglikelihood unrestricted model (H1) -3695.092 ## ## Number of free parameters 21 ## Akaike (AIC) 7517.490 ## Bayesian (BIC) 7595.339 ## Sample-size adjusted Bayesian (BIC) 7528.739 ## ## Root Mean Square Error of Approximation: ## ## RMSEA 0.092 ## 90 Percent Confidence Interval 0.071 0.114 ## P-value RMSEA &lt;= 0.05 0.001 ## ## Standardized Root Mean Square Residual: ## ## SRMR 0.065 ## ## Parameter Estimates: ## ## Information Expected ## Standard Errors Standard ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## visual =~ ## x1 0.900 0.081 11.127 0.000 0.900 0.772 ## x2 0.498 0.077 6.429 0.000 0.498 0.424 ## x3 0.656 0.074 8.817 0.000 0.656 0.581 ## textual =~ ## x4 0.990 0.057 17.474 0.000 0.990 0.852 ## x5 1.102 0.063 17.576 0.000 1.102 0.855 ## x6 0.917 0.054 17.082 0.000 0.917 0.838 ## speed =~ ## x7 0.619 0.070 8.903 0.000 0.619 0.570 ## x8 0.731 0.066 11.090 0.000 0.731 0.723 ## x9 0.670 0.065 10.305 0.000 0.670 0.665 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## visual ~~ ## textual 0.459 0.064 7.189 0.000 0.459 0.459 ## speed 0.471 0.073 6.461 0.000 0.471 0.471 ## textual ~~ ## speed 0.283 0.069 4.117 0.000 0.283 0.283 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .x1 0.549 0.114 4.833 0.000 0.549 0.404 ## .x2 1.134 0.102 11.146 0.000 1.134 0.821 ## .x3 0.844 0.091 9.317 0.000 0.844 0.662 ## .x4 0.371 0.048 7.778 0.000 0.371 0.275 ## .x5 0.446 0.058 7.642 0.000 0.446 0.269 ## .x6 0.356 0.043 8.277 0.000 0.356 0.298 ## .x7 0.799 0.081 9.823 0.000 0.799 0.676 ## .x8 0.488 0.074 6.573 0.000 0.488 0.477 ## .x9 0.566 0.071 8.003 0.000 0.566 0.558 ## visual 1.000 1.000 1.000 ## textual 1.000 1.000 1.000 ## speed 1.000 1.000 1.000 7.6 additional SEM details 7.6.1 coding revisited Marker variable: if you are lazy; default. Residual variances can change, but the loadings do as does the variance of the latent factor. The latent factors variance is the reliable variance of the marker variable, and the mean of the marker variable. Fixed factor: standardized, unit-free estimates. Has some nice-ities. Does not arbitrarily give more weight to one indicator. If more than one latent factor is estimated, the estimates between the factors gives the correlation. If you square the loadings and add the residual it equals 1. Effects coding: if the original metric is meaningful, keeps the latent variable in the metric of your scale. Residual variance is the same. Loadings average to 1. mod.3 &lt;- &#39; visual =~ NA*x1 + v1*x1 + v2*x2 + v3*x3 textual =~ NA*x4 + t1*x4 + t2*x5 + t3*x6 speed =~ NA*x7 + s1*x7 + s2*x8 + s3*x9 v1 == 3 - v2 - v3 t1 == 3 - t2 - t3 s1 == 3 - s2 - s3 &#39; fit.3 &lt;- cfa(mod.3, data=HolzingerSwineford1939) summary(fit.3, fit.measures=TRUE, standardized=TRUE) ## lavaan (0.5-23.1097) converged normally after 32 iterations ## ## Number of observations 301 ## ## Estimator ML ## Minimum Function Test Statistic 85.306 ## Degrees of freedom 24 ## P-value (Chi-square) 0.000 ## ## Model test baseline model: ## ## Minimum Function Test Statistic 918.852 ## Degrees of freedom 36 ## P-value 0.000 ## ## User model versus baseline model: ## ## Comparative Fit Index (CFI) 0.931 ## Tucker-Lewis Index (TLI) 0.896 ## ## Loglikelihood and Information Criteria: ## ## Loglikelihood user model (H0) -3737.745 ## Loglikelihood unrestricted model (H1) -3695.092 ## ## Number of free parameters 21 ## Akaike (AIC) 7517.490 ## Bayesian (BIC) 7595.339 ## Sample-size adjusted Bayesian (BIC) 7528.739 ## ## Root Mean Square Error of Approximation: ## ## RMSEA 0.092 ## 90 Percent Confidence Interval 0.071 0.114 ## P-value RMSEA &lt;= 0.05 0.001 ## ## Standardized Root Mean Square Residual: ## ## SRMR 0.065 ## ## Parameter Estimates: ## ## Information Expected ## Standard Errors Standard ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## visual =~ ## x1 (v1) 1.314 0.101 13.037 0.000 0.900 0.772 ## x2 (v2) 0.727 0.091 8.006 0.000 0.498 0.424 ## x3 (v3) 0.958 0.089 10.744 0.000 0.656 0.581 ## textual =~ ## x4 (t1) 0.987 0.034 29.056 0.000 0.990 0.852 ## x5 (t2) 1.099 0.036 30.883 0.000 1.102 0.855 ## x6 (t3) 0.914 0.033 27.627 0.000 0.917 0.838 ## speed =~ ## x7 (s1) 0.920 0.078 11.725 0.000 0.619 0.570 ## x8 (s2) 1.085 0.081 13.381 0.000 0.731 0.723 ## x9 (s3) 0.995 0.078 12.789 0.000 0.670 0.665 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## visual ~~ ## textual 0.315 0.055 5.736 0.000 0.459 0.459 ## speed 0.217 0.041 5.295 0.000 0.471 0.471 ## textual ~~ ## speed 0.191 0.051 3.775 0.000 0.283 0.283 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .x1 0.549 0.114 4.833 0.000 0.549 0.404 ## .x2 1.134 0.102 11.146 0.000 1.134 0.821 ## .x3 0.844 0.091 9.317 0.000 0.844 0.662 ## .x4 0.371 0.048 7.779 0.000 0.371 0.275 ## .x5 0.446 0.058 7.642 0.000 0.446 0.269 ## .x6 0.356 0.043 8.277 0.000 0.356 0.298 ## .x7 0.799 0.081 9.823 0.000 0.799 0.676 ## .x8 0.488 0.074 6.573 0.000 0.488 0.477 ## .x9 0.566 0.071 8.003 0.000 0.566 0.558 ## visual 0.469 0.062 7.549 0.000 1.000 1.000 ## textual 1.005 0.093 10.823 0.000 1.000 1.000 ## speed 0.454 0.055 8.271 0.000 1.000 1.000 ## ## Constraints: ## |Slack| ## v1 - (3-v2-v3) 0.000 ## t1 - (3-t2-t3) 0.000 ## s1 - (3-s2-s3) 0.000 7.6.2 plotting library(semPlot) semPaths(fit.3) semPaths(fit.3, what= &quot;std&quot;) Fixed factor: standardized, unit-free estimates Effects coding: if the original metric is meaningful Marker variable: if you are lazy. Changes interpretation of some parameters. Will not change fit indices. 7.6.3 Fit Indices residuals. Good to check. modification indices. Check to see if missing parameters that residuals may suggest you didn’t include or should include. Can test with more advanced techniques. But eh… makes your models non-theoretical, could be over fitting, relying too much on sig tests… chi-square. (Statistical fit) Implied versus observed data, tests to see if model are exact fit with data. But eh…too impacted by sample size RMSEA or SRMR (Absolute fit). Does not compare to a null model. Judges distance from perfect fit. Above .10 poor fit Below .08 acceptable CFI, TFI (Relative fit models). Compares relative to a null model. Judges distance from the worse fit ie a null model. Null models have no covariance among observed and latent variables. range from 0-1. Indicate % of improvement from the null model to a saturated ie just identified model. Usually &gt;.9 is okay. Some care about &gt; .95 Minor changes to the model can improve fit. Check the model parameters. Are they wonky? Easy to get negative variances or correlations above 1. 7.6.4 Comparing models Can compare models as in mlm. anova(model1, model2) Use AIC and BIC, just as with MLM. Smaller values indicate a better fit. 7.6.5 Parcels It is often necessary to simplify your model. One option to do so is with parcels where you combine indicators into a composite. This simplifies the model in that you have fewer parameters to fit. In addition to being a way to get a model identified, it also has benefits in terms of the assumptions of the indicator variables. To do so, you can combine items however you want into 3 or 4 groups or parcels, averaging them together. You may balance highly loading with less highly loading items (item to construct technique) or you may pair pos and negatively keyed items together. It is up to you. Some dislike it because you are aggregating without taking into account the association between the indicators; it is a blind procedure based on theory/assumptions rather than maths. ¯_(ツ)_/¯ 7.6.6 Estimators Default in lavaan is the ML estimator, which we have seen before. There are many other options too, some of which require complete data (though see multiple imputation discussion next class). There are a number of “robust” estimates that are uniformly better. MLR is my personal choice if you go this route, but others are just as good and maybe better if you have complete data. To confuse things, there are other methods to get robust standard errors. When data are missing one can request standard errors via a number of different methods. To do so one needs to first specify that data are missing via missing = “ML” in the fitting function. Then use the se function to specify what you want. Bootstrapped estimates are also available with se = “bootstrap” 7.7 Types of longitudinal models other than growth models (brief intro) long &lt;- read_csv(&quot;~/Box Sync/5165 Applied Longitudinal Data Analysis/SEM_workshop/longitudinal.csv&quot;) ## Parsed with column specification: ## cols( ## PosAFF11 = col_double(), ## PosAFF21 = col_double(), ## PosAFF31 = col_double(), ## NegAFF11 = col_double(), ## NegAFF21 = col_double(), ## NegAFF31 = col_double(), ## PosAFF12 = col_double(), ## PosAFF22 = col_double(), ## PosAFF32 = col_double(), ## NegAFF12 = col_double(), ## NegAFF22 = col_double(), ## NegAFF32 = col_double(), ## PosAFF13 = col_double(), ## PosAFF23 = col_double(), ## PosAFF33 = col_double(), ## NegAFF13 = col_double(), ## NegAFF23 = col_double(), ## NegAFF33 = col_double() ## ) summary(long) ## PosAFF11 PosAFF21 PosAFF31 NegAFF11 ## Min. :1.365 Min. :0.4152 Min. :1.140 Min. :-0.8584 ## 1st Qu.:2.739 1st Qu.:2.6343 1st Qu.:2.797 1st Qu.: 1.1035 ## Median :3.209 Median :3.1143 Median :3.204 Median : 1.5075 ## Mean :3.212 Mean :3.1050 Mean :3.248 Mean : 1.5220 ## 3rd Qu.:3.688 3rd Qu.:3.6216 3rd Qu.:3.775 3rd Qu.: 1.9815 ## Max. :5.804 Max. :6.1970 Max. :6.048 Max. : 3.2403 ## NegAFF21 NegAFF31 PosAFF12 PosAFF22 ## Min. :-0.3991 Min. :-0.5606 Min. :1.528 Min. :0.6575 ## 1st Qu.: 1.0229 1st Qu.: 1.0100 1st Qu.:2.852 1st Qu.:2.6571 ## Median : 1.3718 Median : 1.4335 Median :3.215 Median :3.1206 ## Mean : 1.3971 Mean : 1.3981 Mean :3.253 Mean :3.1256 ## 3rd Qu.: 1.7566 3rd Qu.: 1.8101 3rd Qu.:3.637 3rd Qu.:3.5467 ## Max. : 2.9844 Max. : 2.7674 Max. :5.413 Max. :5.4420 ## PosAFF32 NegAFF12 NegAFF22 NegAFF32 ## Min. :0.7369 Min. :0.1797 Min. :0.1784 Min. :-0.03494 ## 1st Qu.:2.8484 1st Qu.:1.1464 1st Qu.:0.9963 1st Qu.: 1.02027 ## Median :3.2692 Median :1.3818 Median :1.3172 Median : 1.31692 ## Mean :3.2737 Mean :1.4115 Mean :1.3237 Mean : 1.30002 ## 3rd Qu.:3.7170 3rd Qu.:1.7251 3rd Qu.:1.6382 3rd Qu.: 1.56441 ## Max. :5.9676 Max. :2.5033 Max. :2.5587 Max. : 2.44236 ## PosAFF13 PosAFF23 PosAFF33 NegAFF13 ## Min. :1.307 Min. :0.8057 Min. :1.629 Min. :-0.01837 ## 1st Qu.:2.979 1st Qu.:2.7147 1st Qu.:2.858 1st Qu.: 1.15739 ## Median :3.299 Median :3.0832 Median :3.325 Median : 1.43937 ## Mean :3.302 Mean :3.0945 Mean :3.280 Mean : 1.43015 ## 3rd Qu.:3.683 3rd Qu.:3.5296 3rd Qu.:3.698 3rd Qu.: 1.73650 ## Max. :4.712 Max. :4.8007 Max. :5.014 Max. : 2.75085 ## NegAFF23 NegAFF33 ## Min. :0.147 Min. :0.3145 ## 1st Qu.:1.009 1st Qu.:1.0261 ## Median :1.294 Median :1.3154 ## Mean :1.281 Mean :1.2974 ## 3rd Qu.:1.560 3rd Qu.:1.5583 ## Max. :2.447 Max. :2.6385 7.7.1 Longitudinal CFA key concerns: 1. Should the correlations be the same across time? 2. Should the error variances be correlated? 3. Are the loadings the same across time? (more on this later) long.cfa &lt;- &#39; ## define latent variables Pos1 =~ PosAFF11 + PosAFF21 + PosAFF31 Pos2 =~ PosAFF12 + PosAFF22 + PosAFF32 Pos3 =~ PosAFF13 + PosAFF23 + PosAFF33 Neg1 =~ NegAFF11 + NegAFF21 + NegAFF31 Neg2 =~ NegAFF12 + NegAFF22 + NegAFF32 Neg3 =~ NegAFF13 + NegAFF23 + NegAFF33 ## correlated residuals across time PosAFF11 ~~ PosAFF12 + PosAFF13 PosAFF12 ~~ PosAFF13 PosAFF21 ~~ PosAFF22 + PosAFF23 PosAFF22 ~~ PosAFF23 PosAFF31 ~~ PosAFF32 + PosAFF33 PosAFF32 ~~ PosAFF33 NegAFF11 ~~ NegAFF12 + NegAFF13 NegAFF12 ~~ NegAFF13 NegAFF21 ~~ NegAFF22 + NegAFF23 NegAFF22 ~~ NegAFF23 NegAFF31 ~~ NegAFF32 + NegAFF33 NegAFF32 ~~ NegAFF33 &#39; fit.long.cfa &lt;- cfa(long.cfa, data=long, std.lv=TRUE) summary(fit.long.cfa, standardized=TRUE, fit.measures=TRUE) ## lavaan (0.5-23.1097) converged normally after 134 iterations ## ## Number of observations 368 ## ## Estimator ML ## Minimum Function Test Statistic 119.443 ## Degrees of freedom 102 ## P-value (Chi-square) 0.114 ## ## Model test baseline model: ## ## Minimum Function Test Statistic 5253.085 ## Degrees of freedom 153 ## P-value 0.000 ## ## User model versus baseline model: ## ## Comparative Fit Index (CFI) 0.997 ## Tucker-Lewis Index (TLI) 0.995 ## ## Loglikelihood and Information Criteria: ## ## Loglikelihood user model (H0) -3060.353 ## Loglikelihood unrestricted model (H1) -3000.632 ## ## Number of free parameters 69 ## Akaike (AIC) 6258.707 ## Bayesian (BIC) 6528.365 ## Sample-size adjusted Bayesian (BIC) 6309.453 ## ## Root Mean Square Error of Approximation: ## ## RMSEA 0.022 ## 90 Percent Confidence Interval 0.000 0.036 ## P-value RMSEA &lt;= 0.05 1.000 ## ## Standardized Root Mean Square Residual: ## ## SRMR 0.028 ## ## Parameter Estimates: ## ## Information Expected ## Standard Errors Standard ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## Pos1 =~ ## PosAFF11 0.654 0.030 21.936 0.000 0.654 0.903 ## PosAFF21 0.651 0.031 20.864 0.000 0.651 0.875 ## PosAFF31 0.685 0.031 22.361 0.000 0.685 0.912 ## Pos2 =~ ## PosAFF12 0.556 0.026 21.256 0.000 0.556 0.883 ## PosAFF22 0.638 0.030 21.448 0.000 0.638 0.887 ## PosAFF32 0.644 0.027 23.567 0.000 0.644 0.940 ## Pos3 =~ ## PosAFF13 0.508 0.024 21.028 0.000 0.508 0.887 ## PosAFF23 0.545 0.027 20.347 0.000 0.545 0.867 ## PosAFF33 0.538 0.026 20.827 0.000 0.538 0.879 ## Neg1 =~ ## NegAFF11 0.563 0.028 20.465 0.000 0.563 0.868 ## NegAFF21 0.479 0.024 19.856 0.000 0.479 0.847 ## NegAFF31 0.555 0.025 22.373 0.000 0.555 0.920 ## Neg2 =~ ## NegAFF12 0.365 0.019 18.989 0.000 0.365 0.826 ## NegAFF22 0.375 0.017 21.452 0.000 0.375 0.889 ## NegAFF32 0.368 0.017 21.383 0.000 0.368 0.896 ## Neg3 =~ ## NegAFF13 0.363 0.021 17.128 0.000 0.363 0.782 ## NegAFF23 0.341 0.017 19.493 0.000 0.341 0.855 ## NegAFF33 0.344 0.017 19.700 0.000 0.344 0.869 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .PosAFF11 ~~ ## .PosAFF12 0.004 0.007 0.578 0.563 0.004 0.043 ## .PosAFF13 0.000 0.007 0.037 0.971 0.000 0.003 ## .PosAFF12 ~~ ## .PosAFF13 0.004 0.006 0.674 0.500 0.004 0.050 ## .PosAFF21 ~~ ## .PosAFF22 0.008 0.008 1.020 0.308 0.008 0.071 ## .PosAFF23 0.008 0.008 0.991 0.322 0.008 0.070 ## .PosAFF22 ~~ ## .PosAFF23 0.011 0.007 1.470 0.142 0.011 0.104 ## .PosAFF31 ~~ ## .PosAFF32 0.004 0.007 0.616 0.538 0.004 0.057 ## .PosAFF33 0.016 0.007 2.182 0.029 0.016 0.177 ## .PosAFF32 ~~ ## .PosAFF33 0.004 0.006 0.690 0.490 0.004 0.061 ## .NegAFF11 ~~ ## .NegAFF12 0.005 0.005 0.966 0.334 0.005 0.065 ## .NegAFF13 0.006 0.006 1.036 0.300 0.006 0.070 ## .NegAFF12 ~~ ## .NegAFF13 0.007 0.005 1.528 0.126 0.007 0.099 ## .NegAFF21 ~~ ## .NegAFF22 0.015 0.004 3.605 0.000 0.015 0.267 ## .NegAFF23 0.011 0.005 2.387 0.017 0.011 0.173 ## .NegAFF22 ~~ ## .NegAFF23 0.010 0.003 3.145 0.002 0.010 0.253 ## .NegAFF31 ~~ ## .NegAFF32 -0.006 0.004 -1.607 0.108 -0.006 -0.147 ## .NegAFF33 -0.008 0.004 -1.778 0.075 -0.008 -0.163 ## .NegAFF32 ~~ ## .NegAFF33 -0.001 0.003 -0.481 0.630 -0.001 -0.041 ## Pos1 ~~ ## Pos2 0.473 0.044 10.663 0.000 0.473 0.473 ## Pos3 0.399 0.048 8.228 0.000 0.399 0.399 ## Neg1 -0.436 0.047 -9.358 0.000 -0.436 -0.436 ## Neg2 -0.297 0.052 -5.706 0.000 -0.297 -0.297 ## Neg3 -0.169 0.056 -3.003 0.003 -0.169 -0.169 ## Pos2 ~~ ## Pos3 0.449 0.046 9.777 0.000 0.449 0.449 ## Neg1 -0.179 0.054 -3.279 0.001 -0.179 -0.179 ## Neg2 -0.543 0.041 -13.203 0.000 -0.543 -0.543 ## Neg3 -0.198 0.055 -3.578 0.000 -0.198 -0.198 ## Pos3 ~~ ## Neg1 -0.074 0.057 -1.304 0.192 -0.074 -0.074 ## Neg2 -0.167 0.056 -2.989 0.003 -0.167 -0.167 ## Neg3 -0.292 0.054 -5.442 0.000 -0.292 -0.292 ## Neg1 ~~ ## Neg2 0.526 0.043 12.317 0.000 0.526 0.526 ## Neg3 0.351 0.052 6.778 0.000 0.351 0.351 ## Neg2 ~~ ## Neg3 0.435 0.048 9.006 0.000 0.435 0.435 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .PosAFF11 0.096 0.011 8.497 0.000 0.096 0.184 ## .PosAFF21 0.130 0.013 9.956 0.000 0.130 0.235 ## .PosAFF31 0.095 0.012 7.944 0.000 0.095 0.168 ## .PosAFF12 0.087 0.009 10.044 0.000 0.087 0.220 ## .PosAFF22 0.110 0.011 9.883 0.000 0.110 0.213 ## .PosAFF32 0.055 0.009 6.437 0.000 0.055 0.117 ## .PosAFF13 0.070 0.008 8.319 0.000 0.070 0.214 ## .PosAFF23 0.098 0.011 9.317 0.000 0.098 0.249 ## .PosAFF33 0.085 0.010 8.716 0.000 0.085 0.227 ## .NegAFF11 0.104 0.011 9.546 0.000 0.104 0.246 ## .NegAFF21 0.091 0.009 10.363 0.000 0.091 0.283 ## .NegAFF31 0.056 0.009 6.475 0.000 0.056 0.153 ## .NegAFF12 0.062 0.006 10.835 0.000 0.062 0.317 ## .NegAFF22 0.037 0.004 8.445 0.000 0.037 0.209 ## .NegAFF32 0.033 0.004 7.917 0.000 0.033 0.198 ## .NegAFF13 0.084 0.008 10.660 0.000 0.084 0.389 ## .NegAFF23 0.043 0.005 8.170 0.000 0.043 0.270 ## .NegAFF33 0.038 0.005 7.372 0.000 0.038 0.245 ## Pos1 1.000 1.000 1.000 ## Pos2 1.000 1.000 1.000 ## Pos3 1.000 1.000 1.000 ## Neg1 1.000 1.000 1.000 ## Neg2 1.000 1.000 1.000 ## Neg3 1.000 1.000 1.000 semPaths(fit.long.cfa) 7.7.2 Longitudinal Path Model key concerns: 1. Should the regressions be the same across time? 2. Should the error variances be correlated? 3. Are the loadings the same across time? (more on this later) long.path &lt;- &#39; ## define latent variables Pos1 =~ L1*PosAFF11 + L2*PosAFF21 + L3*PosAFF31 Pos2 =~ L1*PosAFF12 + L2*PosAFF22 + L3*PosAFF32 Pos3 =~ L1*PosAFF13 + L2*PosAFF23 + L3*PosAFF33 Neg1 =~ L4*NegAFF11 + L5*NegAFF21 + L6*NegAFF31 Neg2 =~ L4*NegAFF12 + L5*NegAFF22 + L6*NegAFF32 Neg3 =~ L4*NegAFF13 + L5*NegAFF23 + L6*NegAFF33 ## free latent variances at later times (only set the scale once) Pos2 ~~ NA*Pos2 Pos3 ~~ NA*Pos3 Neg2 ~~ NA*Neg2 Neg3 ~~ NA*Neg3 Pos1 ~~ Neg1 Pos2 ~~ Neg2 Pos3 ~~ Neg3 ## directional regression paths Pos2 ~ Pos1 Pos3 ~ Pos2 Neg2 ~ Neg1 Neg3 ~ Neg2 ## correlated residuals across time PosAFF11 ~~ PosAFF12 + PosAFF13 PosAFF12 ~~ PosAFF13 PosAFF21 ~~ PosAFF22 + PosAFF23 PosAFF22 ~~ PosAFF23 PosAFF31 ~~ PosAFF32 + PosAFF33 PosAFF32 ~~ PosAFF33 NegAFF11 ~~ NegAFF12 + NegAFF13 NegAFF12 ~~ NegAFF13 NegAFF21 ~~ NegAFF22 + NegAFF23 NegAFF22 ~~ NegAFF23 NegAFF31 ~~ NegAFF32 + NegAFF33 NegAFF32 ~~ NegAFF33 &#39; fit.long.path &lt;- sem(long.path, data=long, std.lv=TRUE) summary(fit.long.path, standardized=TRUE, fit.measures=TRUE) ## lavaan (0.5-23.1097) converged normally after 141 iterations ## ## Number of observations 368 ## ## Estimator ML ## Minimum Function Test Statistic 170.843 ## Degrees of freedom 118 ## P-value (Chi-square) 0.001 ## ## Model test baseline model: ## ## Minimum Function Test Statistic 5253.085 ## Degrees of freedom 153 ## P-value 0.000 ## ## User model versus baseline model: ## ## Comparative Fit Index (CFI) 0.990 ## Tucker-Lewis Index (TLI) 0.987 ## ## Loglikelihood and Information Criteria: ## ## Loglikelihood user model (H0) -3086.053 ## Loglikelihood unrestricted model (H1) -3000.632 ## ## Number of free parameters 53 ## Akaike (AIC) 6278.107 ## Bayesian (BIC) 6485.235 ## Sample-size adjusted Bayesian (BIC) 6317.086 ## ## Root Mean Square Error of Approximation: ## ## RMSEA 0.035 ## 90 Percent Confidence Interval 0.023 0.046 ## P-value RMSEA &lt;= 0.05 0.989 ## ## Standardized Root Mean Square Residual: ## ## SRMR 0.055 ## ## Parameter Estimates: ## ## Information Expected ## Standard Errors Standard ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## Pos1 =~ ## PosAFF11 (L1) 0.630 0.027 23.609 0.000 0.630 0.892 ## PosAFF21 (L2) 0.673 0.029 23.387 0.000 0.673 0.884 ## PosAFF31 (L3) 0.686 0.029 23.966 0.000 0.686 0.913 ## Pos2 =~ ## PosAFF12 (L1) 0.630 0.027 23.609 0.000 0.575 0.893 ## PosAFF22 (L2) 0.673 0.029 23.387 0.000 0.614 0.878 ## PosAFF32 (L3) 0.686 0.029 23.966 0.000 0.626 0.932 ## Pos3 =~ ## PosAFF13 (L1) 0.630 0.027 23.609 0.000 0.504 0.884 ## PosAFF23 (L2) 0.673 0.029 23.387 0.000 0.539 0.861 ## PosAFF33 (L3) 0.686 0.029 23.966 0.000 0.549 0.887 ## Neg1 =~ ## NegAFF11 (L4) 0.546 0.024 22.398 0.000 0.546 0.859 ## NegAFF21 (L5) 0.510 0.023 22.505 0.000 0.510 0.868 ## NegAFF31 (L6) 0.537 0.023 23.717 0.000 0.537 0.908 ## Neg2 =~ ## NegAFF12 (L4) 0.546 0.024 22.398 0.000 0.384 0.841 ## NegAFF22 (L5) 0.510 0.023 22.505 0.000 0.358 0.871 ## NegAFF32 (L6) 0.537 0.023 23.717 0.000 0.377 0.904 ## Neg3 =~ ## NegAFF13 (L4) 0.546 0.024 22.398 0.000 0.362 0.780 ## NegAFF23 (L5) 0.510 0.023 22.505 0.000 0.338 0.847 ## NegAFF33 (L6) 0.537 0.023 23.717 0.000 0.356 0.883 ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## Pos2 ~ ## Pos1 0.416 0.042 10.020 0.000 0.456 0.456 ## Pos3 ~ ## Pos2 0.404 0.044 9.207 0.000 0.460 0.460 ## Neg2 ~ ## Neg1 0.382 0.031 12.203 0.000 0.544 0.544 ## Neg3 ~ ## Neg2 0.432 0.049 8.867 0.000 0.457 0.457 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## Pos1 ~~ ## Neg1 -0.441 0.046 -9.502 0.000 -0.441 -0.441 ## .Pos2 ~~ ## .Neg2 -0.269 0.036 -7.544 0.000 -0.561 -0.561 ## .Pos3 ~~ ## .Neg3 -0.125 0.027 -4.596 0.000 -0.298 -0.298 ## .PosAFF11 ~~ ## .PosAFF12 0.004 0.007 0.536 0.592 0.004 0.039 ## .PosAFF13 0.003 0.007 0.386 0.699 0.003 0.030 ## .PosAFF12 ~~ ## .PosAFF13 0.003 0.006 0.585 0.559 0.003 0.044 ## .PosAFF21 ~~ ## .PosAFF22 0.007 0.008 0.865 0.387 0.007 0.061 ## .PosAFF23 0.008 0.008 1.030 0.303 0.008 0.074 ## .PosAFF22 ~~ ## .PosAFF23 0.011 0.007 1.516 0.130 0.011 0.106 ## .PosAFF31 ~~ ## .PosAFF32 0.005 0.007 0.705 0.481 0.005 0.064 ## .PosAFF33 0.016 0.007 2.173 0.030 0.016 0.180 ## .PosAFF32 ~~ ## .PosAFF33 0.004 0.006 0.580 0.562 0.004 0.051 ## .NegAFF11 ~~ ## .NegAFF12 0.005 0.005 0.947 0.344 0.005 0.064 ## .NegAFF13 0.007 0.006 1.107 0.268 0.007 0.073 ## .NegAFF12 ~~ ## .NegAFF13 0.007 0.005 1.539 0.124 0.007 0.100 ## .NegAFF21 ~~ ## .NegAFF22 0.015 0.004 3.399 0.001 0.015 0.249 ## .NegAFF23 0.010 0.005 2.217 0.027 0.010 0.163 ## .NegAFF22 ~~ ## .NegAFF23 0.011 0.003 3.430 0.001 0.011 0.259 ## .NegAFF31 ~~ ## .NegAFF32 -0.007 0.004 -1.724 0.085 -0.007 -0.155 ## .NegAFF33 -0.007 0.004 -1.587 0.113 -0.007 -0.143 ## .NegAFF32 ~~ ## .NegAFF33 -0.002 0.003 -0.734 0.463 -0.002 -0.066 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .Pos2 0.660 0.075 8.760 0.000 0.792 0.792 ## .Pos3 0.504 0.058 8.628 0.000 0.788 0.788 ## .Neg2 0.347 0.041 8.458 0.000 0.704 0.704 ## .Neg3 0.347 0.041 8.409 0.000 0.791 0.791 ## .PosAFF11 0.102 0.011 9.329 0.000 0.102 0.204 ## .PosAFF21 0.126 0.013 9.699 0.000 0.126 0.218 ## .PosAFF31 0.094 0.012 8.132 0.000 0.094 0.166 ## .PosAFF12 0.084 0.009 9.650 0.000 0.084 0.202 ## .PosAFF22 0.112 0.011 10.307 0.000 0.112 0.229 ## .PosAFF32 0.059 0.008 7.215 0.000 0.059 0.131 ## .PosAFF13 0.071 0.008 8.813 0.000 0.071 0.218 ## .PosAFF23 0.101 0.010 9.833 0.000 0.101 0.259 ## .PosAFF33 0.082 0.009 8.703 0.000 0.082 0.214 ## .NegAFF11 0.106 0.010 10.098 0.000 0.106 0.262 ## .NegAFF21 0.085 0.009 9.768 0.000 0.085 0.247 ## .NegAFF31 0.062 0.008 7.633 0.000 0.062 0.176 ## .NegAFF12 0.061 0.006 10.625 0.000 0.061 0.292 ## .NegAFF22 0.041 0.004 9.619 0.000 0.041 0.242 ## .NegAFF32 0.032 0.004 7.781 0.000 0.032 0.182 ## .NegAFF13 0.084 0.008 11.031 0.000 0.084 0.392 ## .NegAFF23 0.045 0.005 9.102 0.000 0.045 0.282 ## .NegAFF33 0.036 0.005 7.466 0.000 0.036 0.221 ## Pos1 1.000 1.000 1.000 ## Neg1 1.000 1.000 1.000 semPaths(fit.long.path, layout = &quot;tree3&quot;) ## layout can also be done manually to get publications worthy plots 7.7.3 Longitudinal Cross lagged model key concerns: 1. Should the regressions (both cross lagged and autoregressive) be the same across time? 2. Should the indicator error variances be correlated (within time or within construct)? 3. Are the loadings the same across time? (more on this later) 4. Are the latent error variances the same or different? 5. Are the latent error variances correlated the same or different across time? 6. Are there more lagged effects? long.cross &lt;- &#39; ## define latent variables Pos1 =~ L1*PosAFF11 + L2*PosAFF21 + L3*PosAFF31 Pos2 =~ L1*PosAFF12 + L2*PosAFF22 + L3*PosAFF32 Pos3 =~ L1*PosAFF13 + L2*PosAFF23 + L3*PosAFF33 Neg1 =~ L4*NegAFF11 + L5*NegAFF21 + L6*NegAFF31 Neg2 =~ L4*NegAFF12 + L5*NegAFF22 + L6*NegAFF32 Neg3 =~ L4*NegAFF13 + L5*NegAFF23 + L6*NegAFF33 ## free latent variances at later times (only set the scale once) Pos2 ~~ NA*Pos2 Pos3 ~~ NA*Pos3 Neg2 ~~ NA*Neg2 Neg3 ~~ NA*Neg3 Pos1 ~~ Neg1 Pos2 ~~ Neg2 Pos3 ~~ Neg3 ## directional regression paths Pos2 ~ Pos1 + Neg1 Neg2 ~ Pos1 + Neg1 Pos3 ~ Pos2 + Neg2 Neg3 ~ Pos2 + Neg2 ## correlated residuals across time PosAFF11 ~~ PosAFF12 + PosAFF13 PosAFF12 ~~ PosAFF13 PosAFF21 ~~ PosAFF22 + PosAFF23 PosAFF22 ~~ PosAFF23 PosAFF31 ~~ PosAFF32 + PosAFF33 PosAFF32 ~~ PosAFF33 NegAFF11 ~~ NegAFF12 + NegAFF13 NegAFF12 ~~ NegAFF13 NegAFF21 ~~ NegAFF22 + NegAFF23 NegAFF22 ~~ NegAFF23 NegAFF31 ~~ NegAFF32 + NegAFF33 NegAFF32 ~~ NegAFF33 &#39; fit.long.cross &lt;- sem(long.cross,data=long, std.lv=TRUE) summary(fit.long.cross, standardized=TRUE, fit.measures=TRUE) ## lavaan (0.5-23.1097) converged normally after 151 iterations ## ## Number of observations 368 ## ## Estimator ML ## Minimum Function Test Statistic 163.406 ## Degrees of freedom 114 ## P-value (Chi-square) 0.002 ## ## Model test baseline model: ## ## Minimum Function Test Statistic 5253.085 ## Degrees of freedom 153 ## P-value 0.000 ## ## User model versus baseline model: ## ## Comparative Fit Index (CFI) 0.990 ## Tucker-Lewis Index (TLI) 0.987 ## ## Loglikelihood and Information Criteria: ## ## Loglikelihood user model (H0) -3082.335 ## Loglikelihood unrestricted model (H1) -3000.632 ## ## Number of free parameters 57 ## Akaike (AIC) 6278.669 ## Bayesian (BIC) 6501.430 ## Sample-size adjusted Bayesian (BIC) 6320.590 ## ## Root Mean Square Error of Approximation: ## ## RMSEA 0.034 ## 90 Percent Confidence Interval 0.022 0.046 ## P-value RMSEA &lt;= 0.05 0.990 ## ## Standardized Root Mean Square Residual: ## ## SRMR 0.051 ## ## Parameter Estimates: ## ## Information Expected ## Standard Errors Standard ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## Pos1 =~ ## PosAFF11 (L1) 0.630 0.027 23.619 0.000 0.630 0.892 ## PosAFF21 (L2) 0.673 0.029 23.393 0.000 0.673 0.884 ## PosAFF31 (L3) 0.686 0.029 23.990 0.000 0.686 0.914 ## Pos2 =~ ## PosAFF12 (L1) 0.630 0.027 23.619 0.000 0.582 0.896 ## PosAFF22 (L2) 0.673 0.029 23.393 0.000 0.622 0.880 ## PosAFF32 (L3) 0.686 0.029 23.990 0.000 0.634 0.933 ## Pos3 =~ ## PosAFF13 (L1) 0.630 0.027 23.619 0.000 0.503 0.884 ## PosAFF23 (L2) 0.673 0.029 23.393 0.000 0.537 0.861 ## PosAFF33 (L3) 0.686 0.029 23.990 0.000 0.547 0.886 ## Neg1 =~ ## NegAFF11 (L4) 0.547 0.024 22.394 0.000 0.547 0.860 ## NegAFF21 (L5) 0.510 0.023 22.488 0.000 0.510 0.868 ## NegAFF31 (L6) 0.538 0.023 23.710 0.000 0.538 0.908 ## Neg2 =~ ## NegAFF12 (L4) 0.547 0.024 22.394 0.000 0.382 0.840 ## NegAFF22 (L5) 0.510 0.023 22.488 0.000 0.356 0.869 ## NegAFF32 (L6) 0.538 0.023 23.710 0.000 0.375 0.903 ## Neg3 =~ ## NegAFF13 (L4) 0.547 0.024 22.394 0.000 0.358 0.777 ## NegAFF23 (L5) 0.510 0.023 22.488 0.000 0.334 0.844 ## NegAFF33 (L6) 0.538 0.023 23.710 0.000 0.352 0.881 ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## Pos2 ~ ## Pos1 0.463 0.052 8.829 0.000 0.501 0.501 ## Neg1 0.039 0.053 0.746 0.456 0.042 0.042 ## Neg2 ~ ## Pos1 -0.057 0.039 -1.454 0.146 -0.081 -0.081 ## Neg1 0.347 0.039 8.812 0.000 0.498 0.498 ## Pos3 ~ ## Pos2 0.451 0.054 8.307 0.000 0.522 0.522 ## Neg2 0.134 0.073 1.843 0.065 0.117 0.117 ## Neg3 ~ ## Pos2 0.046 0.046 1.000 0.317 0.065 0.065 ## Neg2 0.446 0.062 7.239 0.000 0.475 0.475 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## Pos1 ~~ ## Neg1 -0.437 0.047 -9.375 0.000 -0.437 -0.437 ## .Pos2 ~~ ## .Neg2 -0.269 0.036 -7.567 0.000 -0.566 -0.566 ## .Pos3 ~~ ## .Neg3 -0.127 0.027 -4.710 0.000 -0.308 -0.308 ## .PosAFF11 ~~ ## .PosAFF12 0.004 0.007 0.529 0.597 0.004 0.039 ## .PosAFF13 0.002 0.007 0.371 0.711 0.002 0.028 ## .PosAFF12 ~~ ## .PosAFF13 0.003 0.006 0.569 0.569 0.003 0.043 ## .PosAFF21 ~~ ## .PosAFF22 0.007 0.008 0.869 0.385 0.007 0.061 ## .PosAFF23 0.008 0.008 0.964 0.335 0.008 0.069 ## .PosAFF22 ~~ ## .PosAFF23 0.011 0.007 1.416 0.157 0.011 0.099 ## .PosAFF31 ~~ ## .PosAFF32 0.004 0.007 0.649 0.516 0.004 0.059 ## .PosAFF33 0.016 0.007 2.257 0.024 0.016 0.187 ## .PosAFF32 ~~ ## .PosAFF33 0.004 0.006 0.580 0.562 0.004 0.050 ## .NegAFF11 ~~ ## .NegAFF12 0.005 0.005 0.986 0.324 0.005 0.067 ## .NegAFF13 0.007 0.006 1.088 0.277 0.007 0.072 ## .NegAFF12 ~~ ## .NegAFF13 0.007 0.005 1.537 0.124 0.007 0.100 ## .NegAFF21 ~~ ## .NegAFF22 0.015 0.004 3.440 0.001 0.015 0.252 ## .NegAFF23 0.010 0.005 2.238 0.025 0.010 0.165 ## .NegAFF22 ~~ ## .NegAFF23 0.011 0.003 3.397 0.001 0.011 0.256 ## .NegAFF31 ~~ ## .NegAFF32 -0.007 0.004 -1.748 0.080 -0.007 -0.157 ## .NegAFF33 -0.007 0.004 -1.602 0.109 -0.007 -0.145 ## .NegAFF32 ~~ ## .NegAFF33 -0.002 0.003 -0.751 0.453 -0.002 -0.068 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .Pos2 0.653 0.075 8.735 0.000 0.765 0.765 ## .Pos3 0.496 0.058 8.594 0.000 0.780 0.780 ## .Neg2 0.346 0.041 8.475 0.000 0.710 0.710 ## .Neg3 0.345 0.041 8.396 0.000 0.804 0.804 ## .PosAFF11 0.102 0.011 9.359 0.000 0.102 0.205 ## .PosAFF21 0.127 0.013 9.731 0.000 0.127 0.219 ## .PosAFF31 0.093 0.012 8.100 0.000 0.093 0.165 ## .PosAFF12 0.083 0.009 9.656 0.000 0.083 0.198 ## .PosAFF22 0.113 0.011 10.344 0.000 0.113 0.226 ## .PosAFF32 0.060 0.008 7.270 0.000 0.060 0.129 ## .PosAFF13 0.071 0.008 8.814 0.000 0.071 0.219 ## .PosAFF23 0.101 0.010 9.817 0.000 0.101 0.259 ## .PosAFF33 0.082 0.009 8.730 0.000 0.082 0.216 ## .NegAFF11 0.105 0.010 10.063 0.000 0.105 0.260 ## .NegAFF21 0.085 0.009 9.775 0.000 0.085 0.247 ## .NegAFF31 0.062 0.008 7.599 0.000 0.062 0.176 ## .NegAFF12 0.061 0.006 10.647 0.000 0.061 0.295 ## .NegAFF22 0.041 0.004 9.668 0.000 0.041 0.245 ## .NegAFF32 0.032 0.004 7.810 0.000 0.032 0.184 ## .NegAFF13 0.084 0.008 11.023 0.000 0.084 0.396 ## .NegAFF23 0.045 0.005 9.106 0.000 0.045 0.287 ## .NegAFF33 0.036 0.005 7.452 0.000 0.036 0.224 ## Pos1 1.000 1.000 1.000 ## Neg1 1.000 1.000 1.000 semPaths(fit.long.cross) semPaths(fit.long.cross, layout = &quot;tree3&quot;) 7.7.4 Longitudinal mediation model #Do Self-Reported Social Experiences Mediate the Effect of Extraversion on Life Satisfaction and Happiness? #number close friends library(readr) TSS_sub &lt;- read_csv(&quot;~/Box Sync/5165 Applied Longitudinal Data Analysis/Longitudinal/TSS_sub.csv&quot;) ## Warning: Missing column names filled in: &#39;X1&#39; [1] ## Parsed with column specification: ## cols( ## .default = col_integer(), ## a1bfie = col_double(), ## a1bfia = col_double(), ## a1bfic = col_double(), ## a1bfin = col_double(), ## a1bfio = col_double(), ## a1panpos = col_double(), ## a1panneg = col_double(), ## f1gpa = col_double(), ## f1sbcad = col_double(), ## f1gpaes = col_double(), ## f1acwkp = col_double(), ## f1acvol = col_double(), ## f1acode = col_character(), ## f1acohr = col_double(), ## f1mhpro = col_double(), ## h1gpaes = col_double(), ## h1gpafr = col_double(), ## h1acwkp = col_double(), ## h1acvol = col_double(), ## h1acspo = col_double() ## # ... with 114 more columns ## ) ## See spec(...) for full column specifications. scon.model6&lt;-&#39; # definine extraversion bfie =~ a1bfi01 + a1bfi06r + a1bfi11 + a1bfi16 + a1bfi21r + a1bfi26 + a1bfi31r + a1bfi36 # correlated residuals a1bfi11 ~~ a1bfi16 a1bfi06r ~~ a1bfi21r + a1bfi31r a1bfi21r ~~ a1bfi31r + a1bfi01 #define social connection at 4 waves hconnect=~h1clrel + h1satfr + h1sosat + h1ced05 jconnect=~j1clrel + j1satfr + j1sosat + j1ced05 kconnect=~k1clrel + k1satfr + k1sosat + k1ced05 mconnect=~m1clrel + m1satfr + m1sosat + m1ced05 #correlate residuals h1clrel ~~ j1clrel + k1clrel + m1clrel j1clrel ~~ k1clrel + m1clrel k1clrel ~~ m1clrel h1satfr ~~ j1satfr + k1satfr + m1satfr j1satfr ~~ k1satfr + m1satfr k1satfr ~~ m1satfr h1sosat ~~ j1sosat + k1sosat + m1sosat j1sosat ~~ k1sosat + m1sosat k1sosat ~~ m1sosat h1ced05 ~~ j1ced05 + k1ced05 + m1ced05 j1ced05 ~~ k1ced05 + m1ced05 k1ced05 ~~ m1ced05 # same time covariances between extraversion, connection, satisfaction bfie~~a1swls hconnect ~~ h1swls jconnect ~~ j1swls kconnect ~~ k1swls #regressions to calculate indiret effects hconnect ~ a1*bfie + d1*a1swls jconnect ~ a2*bfie + d2*h1swls + m1*hconnect kconnect ~ a3*bfie + d3*j1swls + m2*jconnect mconnect ~ a4*bfie + d4*k1swls + m3*kconnect h1swls ~ y1*a1swls + c1*bfie j1swls ~ y2*h1swls + c2*bfie + b1*hconnect k1swls ~ y3*j1swls + c3*bfie + b2*jconnect m1swls ~ y4*k1swls + c4*bfie + b3*kconnect #effects # extraversion -&gt; connect (a) # connect -&gt; swb (b) # extraversion -&gt; swb (c) # auto-regressive connection (m) # auto-regressive swb (y) ind:= a1*b1*y3*y4 + a1*m1*b2*y4 + a1*m1*m2*b3 + a2*b2*y4 + a2*m2*b3 + a3*b3 total:= ind + c4 + c3*y4 + c2*y3*y4 + c1*y2*y3*y4 &#39; scon62 &lt;- sem(scon.model6, data=TSS_sub, missing = &quot;ml&quot;, fixed.x = FALSE) summary(scon62, standardized=T, fit.measures=TRUE) ## lavaan (0.5-23.1097) converged normally after 113 iterations ## ## Number of observations 393 ## ## Number of missing patterns 30 ## ## Estimator ML ## Minimum Function Test Statistic 600.051 ## Degrees of freedom 326 ## P-value (Chi-square) 0.000 ## ## Model test baseline model: ## ## Minimum Function Test Statistic 4447.119 ## Degrees of freedom 406 ## P-value 0.000 ## ## User model versus baseline model: ## ## Comparative Fit Index (CFI) 0.932 ## Tucker-Lewis Index (TLI) 0.916 ## ## Loglikelihood and Information Criteria: ## ## Loglikelihood user model (H0) -13558.593 ## Loglikelihood unrestricted model (H1) -13258.568 ## ## Number of free parameters 138 ## Akaike (AIC) 27393.187 ## Bayesian (BIC) 27941.573 ## Sample-size adjusted Bayesian (BIC) 27503.702 ## ## Root Mean Square Error of Approximation: ## ## RMSEA 0.046 ## 90 Percent Confidence Interval 0.040 0.052 ## P-value RMSEA &lt;= 0.05 0.854 ## ## Standardized Root Mean Square Residual: ## ## SRMR 0.068 ## ## Parameter Estimates: ## ## Information Observed ## Standard Errors Standard ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## bfie =~ ## a1bfi01 1.000 0.905 0.728 ## a1bfi06r 0.813 0.072 11.336 0.000 0.735 0.601 ## a1bfi11 0.605 0.056 10.808 0.000 0.547 0.592 ## a1bfi16 0.603 0.054 11.084 0.000 0.545 0.604 ## a1bfi21r 0.951 0.063 15.013 0.000 0.860 0.700 ## a1bfi26 0.806 0.067 12.066 0.000 0.729 0.648 ## a1bfi31r 0.823 0.072 11.471 0.000 0.744 0.618 ## a1bfi36 1.064 0.068 15.561 0.000 0.962 0.871 ## hconnect =~ ## h1clrel 1.000 1.006 0.681 ## h1satfr 1.014 0.119 8.552 0.000 1.020 0.589 ## h1sosat 1.086 0.116 9.389 0.000 1.093 0.747 ## h1ced05 -0.562 0.066 -8.470 0.000 -0.565 -0.644 ## jconnect =~ ## j1clrel 1.000 0.876 0.661 ## j1satfr 1.226 0.126 9.754 0.000 1.074 0.645 ## j1sosat 1.145 0.114 10.055 0.000 1.003 0.754 ## j1ced05 -0.567 0.066 -8.548 0.000 -0.497 -0.597 ## kconnect =~ ## k1clrel 1.000 0.830 0.635 ## k1satfr 1.221 0.144 8.485 0.000 1.014 0.611 ## k1sosat 1.097 0.137 7.984 0.000 0.911 0.607 ## k1ced05 -0.612 0.076 -8.028 0.000 -0.508 -0.574 ## mconnect =~ ## m1clrel 1.000 0.755 0.662 ## m1satfr 1.172 0.109 10.797 0.000 0.885 0.622 ## m1sosat 1.261 0.120 10.492 0.000 0.952 0.693 ## m1ced05 -0.656 0.068 -9.580 0.000 -0.495 -0.598 ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## hconnect ~ ## bfie (a1) 0.224 0.082 2.728 0.006 0.202 0.202 ## a1swls (d1) 0.372 0.062 5.963 0.000 0.370 0.427 ## jconnect ~ ## bfie (a2) 0.099 0.071 1.403 0.161 0.102 0.102 ## h1swls (d2) 0.034 0.065 0.528 0.597 0.039 0.054 ## hconnect (m1) 0.385 0.113 3.417 0.001 0.443 0.443 ## kconnect ~ ## bfie (a3) 0.153 0.062 2.455 0.014 0.167 0.167 ## j1swls (d3) 0.142 0.060 2.380 0.017 0.172 0.209 ## jconnect (m2) 0.391 0.101 3.858 0.000 0.412 0.412 ## mconnect ~ ## bfie (a4) 0.170 0.051 3.302 0.001 0.204 0.204 ## k1swls (d4) -0.070 0.052 -1.352 0.177 -0.093 -0.120 ## kconnect (m3) 0.671 0.110 6.085 0.000 0.738 0.738 ## h1swls ~ ## a1swls (y1) 0.564 0.068 8.289 0.000 0.564 0.468 ## bfie (c1) 0.070 0.093 0.754 0.451 0.063 0.046 ## j1swls ~ ## h1swls (y2) 0.364 0.075 4.839 0.000 0.364 0.415 ## bfie (c2) 0.079 0.082 0.958 0.338 0.071 0.059 ## hconnect (b1) 0.097 0.129 0.746 0.455 0.097 0.080 ## k1swls ~ ## j1swls (y3) 0.538 0.076 7.091 0.000 0.538 0.507 ## bfie (c3) 0.271 0.079 3.446 0.001 0.245 0.190 ## jconnect (b2) 0.009 0.126 0.072 0.943 0.008 0.006 ## m1swls ~ ## k1swls (y4) 0.338 0.068 4.944 0.000 0.338 0.362 ## bfie (c4) 0.005 0.066 0.076 0.940 0.004 0.004 ## kconnect (b3) 0.562 0.137 4.112 0.000 0.466 0.387 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .a1bfi11 ~~ ## .a1bfi16 0.181 0.032 5.659 0.000 0.181 0.337 ## .a1bfi06r ~~ ## .a1bfi21r 0.355 0.052 6.900 0.000 0.355 0.414 ## .a1bfi31r 0.325 0.056 5.786 0.000 0.325 0.351 ## .a1bfi21r ~~ ## .a1bfi31r 0.342 0.050 6.837 0.000 0.342 0.411 ## .a1bfi01 ~~ ## .a1bfi21r 0.178 0.040 4.518 0.000 0.178 0.238 ## .h1clrel ~~ ## .j1clrel 0.225 0.090 2.494 0.013 0.225 0.210 ## .k1clrel 0.234 0.090 2.603 0.009 0.234 0.215 ## .m1clrel 0.358 0.073 4.883 0.000 0.358 0.386 ## .j1clrel ~~ ## .k1clrel 0.334 0.082 4.100 0.000 0.334 0.333 ## .m1clrel 0.257 0.061 4.189 0.000 0.257 0.302 ## .k1clrel ~~ ## .m1clrel 0.277 0.065 4.259 0.000 0.277 0.321 ## .h1satfr ~~ ## .j1satfr 0.238 0.136 1.753 0.080 0.238 0.134 ## .k1satfr 0.273 0.145 1.886 0.059 0.273 0.149 ## .m1satfr 0.274 0.108 2.539 0.011 0.274 0.176 ## .j1satfr ~~ ## .k1satfr 0.471 0.127 3.700 0.000 0.471 0.282 ## .m1satfr 0.417 0.099 4.231 0.000 0.417 0.294 ## .k1satfr ~~ ## .m1satfr 0.662 0.107 6.207 0.000 0.662 0.452 ## .h1sosat ~~ ## .j1sosat 0.010 0.078 0.129 0.897 0.010 0.012 ## .k1sosat 0.021 0.107 0.198 0.843 0.021 0.018 ## .m1sosat 0.003 0.077 0.039 0.969 0.003 0.003 ## .j1sosat ~~ ## .k1sosat 0.135 0.088 1.546 0.122 0.135 0.130 ## .m1sosat 0.070 0.069 1.005 0.315 0.070 0.080 ## .k1sosat ~~ ## .m1sosat 0.301 0.092 3.256 0.001 0.301 0.254 ## .h1ced05 ~~ ## .j1ced05 0.122 0.034 3.624 0.000 0.122 0.272 ## .k1ced05 0.094 0.037 2.562 0.010 0.094 0.194 ## .m1ced05 0.069 0.032 2.128 0.033 0.069 0.154 ## .j1ced05 ~~ ## .k1ced05 0.101 0.034 2.968 0.003 0.101 0.209 ## .m1ced05 0.101 0.029 3.466 0.001 0.101 0.229 ## .k1ced05 ~~ ## .m1ced05 0.171 0.035 4.898 0.000 0.171 0.355 ## bfie ~~ ## a1swls 0.379 0.062 6.098 0.000 0.418 0.363 ## .hconnect ~~ ## .h1swls 0.569 0.091 6.242 0.000 0.668 0.551 ## .jconnect ~~ ## .j1swls 0.452 0.070 6.470 0.000 0.605 0.571 ## .kconnect ~~ ## .k1swls 0.378 0.063 6.020 0.000 0.587 0.558 ## .mconnect ~~ ## .m1swls 0.203 0.041 5.001 0.000 0.406 0.463 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .a1bfi01 3.594 0.063 57.181 0.000 3.594 2.891 ## .a1bfi06r 2.762 0.062 44.674 0.000 2.762 2.259 ## .a1bfi11 3.944 0.047 84.305 0.000 3.944 4.263 ## .a1bfi16 3.706 0.046 81.133 0.000 3.706 4.103 ## .a1bfi21r 3.016 0.062 48.523 0.000 3.016 2.453 ## .a1bfi26 3.604 0.057 63.320 0.000 3.604 3.202 ## .a1bfi31r 2.594 0.061 42.551 0.000 2.594 2.152 ## .a1bfi36 3.663 0.056 65.581 0.000 3.663 3.316 ## .h1clrel 3.756 0.344 10.908 0.000 3.756 2.542 ## .h1satfr 3.575 0.383 9.342 0.000 3.575 2.065 ## .h1sosat 2.697 0.372 7.243 0.000 2.697 1.844 ## .h1ced05 2.987 0.204 14.615 0.000 2.987 3.403 ## .j1clrel 4.785 0.267 17.946 0.000 4.785 3.609 ## .j1satfr 4.346 0.330 13.187 0.000 4.346 2.609 ## .j1sosat 3.799 0.300 12.661 0.000 3.799 2.855 ## .j1ced05 2.587 0.153 16.899 0.000 2.587 3.108 ## .k1clrel 4.744 0.280 16.970 0.000 4.744 3.631 ## .k1satfr 4.190 0.342 12.258 0.000 4.190 2.524 ## .k1sosat 3.367 0.311 10.835 0.000 3.367 2.241 ## .k1ced05 2.733 0.178 15.350 0.000 2.733 3.086 ## .m1clrel 5.734 0.247 23.230 0.000 5.734 5.023 ## .m1satfr 5.387 0.291 18.491 0.000 5.387 3.786 ## .m1sosat 4.568 0.314 14.554 0.000 4.568 3.323 ## .m1ced05 2.252 0.165 13.670 0.000 2.252 2.719 ## .h1swls 2.189 0.371 5.895 0.000 2.189 1.576 ## .j1swls 3.088 0.264 11.692 0.000 3.088 2.541 ## .k1swls 2.369 0.326 7.269 0.000 2.369 1.838 ## .m1swls 2.952 0.272 10.840 0.000 2.952 2.448 ## a1swls 5.341 0.058 91.684 0.000 5.341 4.635 ## bfie 0.000 0.000 0.000 ## .hconnect 0.000 0.000 0.000 ## .jconnect 0.000 0.000 0.000 ## .kconnect 0.000 0.000 0.000 ## .mconnect 0.000 0.000 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .a1bfi01 0.727 0.063 11.517 0.000 0.727 0.470 ## .a1bfi06r 0.955 0.075 12.655 0.000 0.955 0.638 ## .a1bfi11 0.556 0.043 12.809 0.000 0.556 0.650 ## .a1bfi16 0.519 0.041 12.766 0.000 0.519 0.636 ## .a1bfi21r 0.771 0.061 12.625 0.000 0.771 0.510 ## .a1bfi26 0.735 0.059 12.378 0.000 0.735 0.580 ## .a1bfi31r 0.899 0.071 12.650 0.000 0.899 0.619 ## .a1bfi36 0.295 0.040 7.450 0.000 0.295 0.242 ## .h1clrel 1.170 0.138 8.506 0.000 1.170 0.536 ## .h1satfr 1.955 0.203 9.647 0.000 1.955 0.653 ## .h1sosat 0.946 0.119 7.956 0.000 0.946 0.442 ## .h1ced05 0.451 0.047 9.522 0.000 0.451 0.585 ## .j1clrel 0.990 0.102 9.736 0.000 0.990 0.563 ## .j1satfr 1.621 0.164 9.870 0.000 1.621 0.584 ## .j1sosat 0.765 0.094 8.152 0.000 0.765 0.432 ## .j1ced05 0.446 0.042 10.670 0.000 0.446 0.644 ## .k1clrel 1.018 0.108 9.423 0.000 1.018 0.596 ## .k1satfr 1.727 0.174 9.912 0.000 1.727 0.627 ## .k1sosat 1.426 0.148 9.668 0.000 1.426 0.632 ## .k1ced05 0.526 0.052 10.109 0.000 0.526 0.671 ## .m1clrel 0.733 0.068 10.788 0.000 0.733 0.562 ## .m1satfr 1.241 0.109 11.352 0.000 1.241 0.613 ## .m1sosat 0.983 0.095 10.399 0.000 0.983 0.520 ## .m1ced05 0.440 0.037 11.974 0.000 0.440 0.642 ## .h1swls 1.471 0.128 11.501 0.000 1.471 0.763 ## .j1swls 1.123 0.095 11.824 0.000 1.123 0.760 ## .k1swls 1.109 0.095 11.633 0.000 1.109 0.667 ## .m1swls 0.771 0.068 11.279 0.000 0.771 0.530 ## a1swls 1.328 0.095 13.990 0.000 1.328 1.000 ## bfie 0.818 0.104 7.882 0.000 1.000 1.000 ## .hconnect 0.724 0.136 5.331 0.000 0.715 0.715 ## .jconnect 0.556 0.101 5.518 0.000 0.725 0.725 ## .kconnect 0.414 0.085 4.865 0.000 0.600 0.600 ## .mconnect 0.249 0.047 5.346 0.000 0.437 0.437 ## ## Defined Parameters: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## ind 0.131 0.046 2.864 0.004 0.119 0.098 ## total 0.247 0.071 3.479 0.001 0.223 0.185 # use se = &quot;bootstrap&quot; in the fit function to get bootstrapped se 7.7.5 Summary of panel SEM models. These models are well suited to address between subjects questions, but does not get at a within subjects questions at all. To do so you need to turn to… 7.8 SEM Growth models The implimentation of growth models in an SEM framework is very similar to the HLM framework. The major differences is how time is treated. Here, time variables must be the same for everyone in that each assessment point must have a particular variable name associated with it. That is, time is considered categorical in SEM, whereas in MLM it could be treated continuously. This requirment also makes a differences in how our data need to be structured. Whereas previously we had a time variable, now we indirectly include time into our model by specifying when variables were assessed. This has the consequence of necessitating a wide format, as opposed to the long format of MLM. Other than time, the idea behind the growth model is exactly the same. 7.8.1 Coding time One key these models is how you code time. Beause we are working with qualitative time rather than continuous everyone has to have the same time structure. In terms of definiting a latent intercept and latent slope the intercept is defined as when the slope loading is zero. This idea can be thought of as the intercept is the mean of the DV when the predictor is 0, where we have time as the predictor. More later. model.1 &lt;- &#39; i =~ 1*t1 + 1*t2 + 1*t3 + 1*t4 s =~ 0*t1 + 1*t2 + 2*t3 + 3*t4&#39; fit.1 &lt;- growth(model.1, data=Demo.growth) summary(fit.1) ## lavaan (0.5-23.1097) converged normally after 29 iterations ## ## Number of observations 400 ## ## Estimator ML ## Minimum Function Test Statistic 8.069 ## Degrees of freedom 5 ## P-value (Chi-square) 0.152 ## ## Parameter Estimates: ## ## Information Expected ## Standard Errors Standard ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) ## i =~ ## t1 1.000 ## t2 1.000 ## t3 1.000 ## t4 1.000 ## s =~ ## t1 0.000 ## t2 1.000 ## t3 2.000 ## t4 3.000 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## i ~~ ## s 0.618 0.071 8.686 0.000 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .t1 0.000 ## .t2 0.000 ## .t3 0.000 ## .t4 0.000 ## i 0.615 0.077 8.007 0.000 ## s 1.006 0.042 24.076 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .t1 0.595 0.086 6.944 0.000 ## .t2 0.676 0.061 11.061 0.000 ## .t3 0.635 0.072 8.761 0.000 ## .t4 0.508 0.124 4.090 0.000 ## i 1.932 0.173 11.194 0.000 ## s 0.587 0.052 11.336 0.000 semPaths(fit.1) semPaths(fit.1, &#39;est&#39;) 7.8.2 latent basis model model.2 &lt;- &#39; i =~ 1*t1 + 1*t2 + 1*t3 + 1*t4 s =~ 0*t1 + t2 + t3 + 3*t4&#39; fit.2 &lt;- growth(model.2, data=Demo.growth) summary(fit.2) ## lavaan (0.5-23.1097) converged normally after 28 iterations ## ## Number of observations 400 ## ## Estimator ML ## Minimum Function Test Statistic 6.447 ## Degrees of freedom 3 ## P-value (Chi-square) 0.092 ## ## Parameter Estimates: ## ## Information Expected ## Standard Errors Standard ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) ## i =~ ## t1 1.000 ## t2 1.000 ## t3 1.000 ## t4 1.000 ## s =~ ## t1 0.000 ## t2 1.048 0.041 25.835 0.000 ## t3 1.995 0.041 48.478 0.000 ## t4 3.000 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## i ~~ ## s 0.610 0.072 8.483 0.000 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .t1 0.000 ## .t2 0.000 ## .t3 0.000 ## .t4 0.000 ## i 0.597 0.078 7.625 0.000 ## s 1.011 0.042 23.978 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .t1 0.585 0.087 6.707 0.000 ## .t2 0.675 0.061 11.072 0.000 ## .t3 0.635 0.074 8.585 0.000 ## .t4 0.514 0.131 3.941 0.000 ## i 1.915 0.173 11.072 0.000 ## s 0.593 0.053 11.210 0.000 Does not change the fit of the model nor the implied means, but it can change your parameters by changing the time scaling. 7.8.3 constraining slope to be fixed only model.3 &lt;- &#39; i =~ 1*t1 + 1*t2 + 1*t3 + 1*t4 s =~ 0*t1 + t2 + t3 + 3*t4 s ~~0*s&#39; fit.3 &lt;- growth(model.3, data=Demo.growth) ## Warning in lav_object_post_check(object): lavaan WARNING: covariance matrix of latent variables ## is not positive definite; ## use inspect(fit,&quot;cov.lv&quot;) to investigate. summary(fit.3) ## lavaan (0.5-23.1097) converged normally after 31 iterations ## ## Number of observations 400 ## ## Estimator ML ## Minimum Function Test Statistic 303.366 ## Degrees of freedom 4 ## P-value (Chi-square) 0.000 ## ## Parameter Estimates: ## ## Information Expected ## Standard Errors Standard ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) ## i =~ ## t1 1.000 ## t2 1.000 ## t3 1.000 ## t4 1.000 ## s =~ ## t1 0.000 ## t2 1.176 0.072 16.325 0.000 ## t3 2.000 0.053 37.429 0.000 ## t4 3.000 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## i ~~ ## s 0.949 0.070 13.511 0.000 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .t1 0.000 ## .t2 0.000 ## .t3 0.000 ## .t4 0.000 ## i 0.528 0.088 5.986 0.000 ## s 1.030 0.034 29.982 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## s 0.000 ## .t1 2.618 0.177 14.770 0.000 ## .t2 1.378 0.108 12.738 0.000 ## .t3 0.439 0.079 5.567 0.000 ## .t4 1.761 0.139 12.672 0.000 ## i 0.662 0.200 3.302 0.001 7.8.4 introducing covariates/predictors # a linear growth model with a time invariatnt covariate model.4 &lt;- &#39; # intercept and slope with fixed coefficients i =~ 1*t1 + 1*t2 + 1*t3 + 1*t4 s =~ 0*t1 + 1*t2 + 2*t3 + 3*t4 # regressions i ~ x1 + x2 s ~ x1 + x2 &#39; fit.4 &lt;- growth(model.4, data = Demo.growth) summary(fit.4) ## lavaan (0.5-23.1097) converged normally after 31 iterations ## ## Number of observations 400 ## ## Estimator ML ## Minimum Function Test Statistic 10.873 ## Degrees of freedom 9 ## P-value (Chi-square) 0.285 ## ## Parameter Estimates: ## ## Information Expected ## Standard Errors Standard ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) ## i =~ ## t1 1.000 ## t2 1.000 ## t3 1.000 ## t4 1.000 ## s =~ ## t1 0.000 ## t2 1.000 ## t3 2.000 ## t4 3.000 ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## i ~ ## x1 0.609 0.060 10.079 0.000 ## x2 0.613 0.065 9.488 0.000 ## s ~ ## x1 0.263 0.029 9.157 0.000 ## x2 0.517 0.031 16.868 0.000 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## .i ~~ ## .s 0.088 0.042 2.116 0.034 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .t1 0.000 ## .t2 0.000 ## .t3 0.000 ## .t4 0.000 ## .i 0.586 0.062 9.400 0.000 ## .s 0.958 0.030 32.382 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .t1 0.597 0.085 7.067 0.000 ## .t2 0.671 0.060 11.088 0.000 ## .t3 0.599 0.065 9.254 0.000 ## .t4 0.593 0.109 5.437 0.000 ## .i 1.076 0.115 9.335 0.000 ## .s 0.219 0.027 7.975 0.000 # centered predictor Demo.growth$x1.c &lt;- scale(Demo.growth$x1, center=TRUE, scale = FALSE) Demo.growth$x2.c &lt;- scale(Demo.growth$x2, center=TRUE, scale = FALSE) model.5 &lt;- &#39; # intercept and slope with fixed coefficients i =~ 1*t1 + 1*t2 + 1*t3 + 1*t4 s =~ 0*t1 + 1*t2 + 2*t3 + 3*t4 # regressions i ~ x1.c + x2.c s ~ x1.c + x2.c &#39; fit.5 &lt;- growth(model.5, data = Demo.growth) summary(fit.5) ## lavaan (0.5-23.1097) converged normally after 27 iterations ## ## Number of observations 400 ## ## Estimator ML ## Minimum Function Test Statistic 10.873 ## Degrees of freedom 9 ## P-value (Chi-square) 0.285 ## ## Parameter Estimates: ## ## Information Expected ## Standard Errors Standard ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) ## i =~ ## t1 1.000 ## t2 1.000 ## t3 1.000 ## t4 1.000 ## s =~ ## t1 0.000 ## t2 1.000 ## t3 2.000 ## t4 3.000 ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## i ~ ## x1.c 0.609 0.060 10.079 0.000 ## x2.c 0.613 0.065 9.488 0.000 ## s ~ ## x1.c 0.263 0.029 9.157 0.000 ## x2.c 0.517 0.031 16.868 0.000 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## .i ~~ ## .s 0.088 0.042 2.116 0.034 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .t1 0.000 ## .t2 0.000 ## .t3 0.000 ## .t4 0.000 ## .i 0.615 0.061 10.024 0.000 ## .s 1.006 0.029 34.547 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .t1 0.597 0.085 7.067 0.000 ## .t2 0.671 0.060 11.088 0.000 ## .t3 0.599 0.065 9.254 0.000 ## .t4 0.593 0.109 5.437 0.000 ## .i 1.076 0.115 9.335 0.000 ## .s 0.219 0.027 7.975 0.000 what is different what is the same? 7.8.5 introducing time varying covariates # a linear growth model with a time-varying covariate model.6 &lt;- &#39; # intercept and slope with fixed coefficients i =~ 1*t1 + 1*t2 + 1*t3 + 1*t4 s =~ 0*t1 + 1*t2 + 2*t3 + 3*t4 # regressions i ~ x1 + x2 s ~ x1 + x2 # time-varying covariates t1 ~ c1 t2 ~ c2 t3 ~ c3 t4 ~ c4 &#39; fit.6 &lt;- growth(model.6, data = Demo.growth) summary(fit.6) ## lavaan (0.5-23.1097) converged normally after 31 iterations ## ## Number of observations 400 ## ## Estimator ML ## Minimum Function Test Statistic 26.059 ## Degrees of freedom 21 ## P-value (Chi-square) 0.204 ## ## Parameter Estimates: ## ## Information Expected ## Standard Errors Standard ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) ## i =~ ## t1 1.000 ## t2 1.000 ## t3 1.000 ## t4 1.000 ## s =~ ## t1 0.000 ## t2 1.000 ## t3 2.000 ## t4 3.000 ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## i ~ ## x1 0.608 0.060 10.134 0.000 ## x2 0.604 0.064 9.412 0.000 ## s ~ ## x1 0.262 0.029 9.198 0.000 ## x2 0.522 0.031 17.083 0.000 ## t1 ~ ## c1 0.143 0.050 2.883 0.004 ## t2 ~ ## c2 0.289 0.046 6.295 0.000 ## t3 ~ ## c3 0.328 0.044 7.361 0.000 ## t4 ~ ## c4 0.330 0.058 5.655 0.000 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## .i ~~ ## .s 0.075 0.040 1.855 0.064 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .t1 0.000 ## .t2 0.000 ## .t3 0.000 ## .t4 0.000 ## .i 0.580 0.062 9.368 0.000 ## .s 0.958 0.029 32.552 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .t1 0.580 0.080 7.230 0.000 ## .t2 0.596 0.054 10.969 0.000 ## .t3 0.481 0.055 8.745 0.000 ## .t4 0.535 0.098 5.466 0.000 ## .i 1.079 0.112 9.609 0.000 ## .s 0.224 0.027 8.429 0.000 7.8.6 multivariate growth curves model.bi &lt;- &#39; #create positive affect growth model i.p =~ 1*PosAFF11 + 1*PosAFF12 + 1*PosAFF13 s.p =~ 0*PosAFF11 + 1*PosAFF12 + 2*PosAFF13 # create negative affect growth model i.n =~ 1*NegAFF11 + 1*NegAFF12 + 1*NegAFF13 s.n =~ 0*NegAFF11 + 1*NegAFF12 + 2*NegAFF13 &#39; fit.bi &lt;- growth(model.bi, data = long) ## Warning in lav_object_post_check(object): lavaan WARNING: covariance matrix of latent variables ## is not positive definite; ## use inspect(fit,&quot;cov.lv&quot;) to investigate. summary(fit.bi) ## lavaan (0.5-23.1097) converged normally after 63 iterations ## ## Number of observations 368 ## ## Estimator ML ## Minimum Function Test Statistic 56.908 ## Degrees of freedom 7 ## P-value (Chi-square) 0.000 ## ## Parameter Estimates: ## ## Information Expected ## Standard Errors Standard ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) ## i.p =~ ## PosAFF11 1.000 ## PosAFF12 1.000 ## PosAFF13 1.000 ## s.p =~ ## PosAFF11 0.000 ## PosAFF12 1.000 ## PosAFF13 2.000 ## i.n =~ ## NegAFF11 1.000 ## NegAFF12 1.000 ## NegAFF13 1.000 ## s.n =~ ## NegAFF11 0.000 ## NegAFF12 1.000 ## NegAFF13 2.000 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## i.p ~~ ## s.p -0.033 0.025 -1.303 0.193 ## i.n -0.127 0.021 -5.958 0.000 ## s.n 0.047 0.012 3.793 0.000 ## s.p ~~ ## i.n 0.056 0.012 4.758 0.000 ## s.n -0.036 0.007 -5.012 0.000 ## i.n ~~ ## s.n -0.032 0.018 -1.800 0.072 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .PosAFF11 0.000 ## .PosAFF12 0.000 ## .PosAFF13 0.000 ## .NegAFF11 0.000 ## .NegAFF12 0.000 ## .NegAFF13 0.000 ## i.p 3.210 0.035 91.056 0.000 ## s.p 0.045 0.020 2.269 0.023 ## i.n 1.478 0.030 49.244 0.000 ## s.n -0.036 0.018 -2.001 0.045 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .PosAFF11 0.334 0.047 7.070 0.000 ## .PosAFF12 0.235 0.023 10.407 0.000 ## .PosAFF13 0.200 0.037 5.422 0.000 ## .NegAFF11 0.289 0.034 8.562 0.000 ## .NegAFF12 0.101 0.011 8.908 0.000 ## .NegAFF13 0.157 0.023 6.735 0.000 ## i.p 0.199 0.045 4.464 0.000 ## s.p 0.016 0.020 0.791 0.429 ## i.n 0.141 0.029 4.788 0.000 ## s.n 0.012 0.014 0.861 0.389 semPaths(fit.bi) inspect(fit.bi,&quot;cor.lv&quot;) ## i.p s.p i.n s.n ## i.p 1.000 ## s.p -0.577 1.000 ## i.n -0.760 1.185 1.000 ## s.n 0.947 -2.530 -0.760 1.000 EEEEeeeee that is not good. What happened? 7.9 Measurement Invariance (MI) To meaningfully look at means, we need to have the means mean the same thing. In other words, without using the word mean, we need to make sure that the measurment of the construct is consistent across time. If it isn’t, then what we may see as change actually reflect people responding to the indicators differently. For example, a common item on an extraversion scale is “Do you like to go to parties?” This is likely interpretted differently by a 20 year old compared to a 70 year old. This is due to what is normative, what parties look like that a typical 20 and 70 year old go to, etcetera. Another way to look at this is the item “2 x 3 = X, solve for X”. The reasons that a 8 year old and a 18 year old get the item incorrect is likely for different reasons (ie knowledge vs not being careful). Maturation is the easiest way to see differences, but it also happens when you want to compare groups ie some anova design. This assumption is typically never critically examined. 7.9.1 types of MI Configural (pattern). Typically always true with a decent measure of your construct. Can be tested through test statistics and eye-balling. Serves as default. Weak (metric/loading). Can be easily met. Not meeting this shows big problems, unless you are working with a really large dataset (where there is large power to find differences). Strong (Scalar/intercept). Need to meet this designation to run longitudinal models and look at means across time. Strict (residual/error variance). Not necessarily better than Strong, and does not need to be satisfied to use longitudinal models. Why might this not hold even if you are assessing the same construct? Hint: think of what residual variance is made up of. 7.9.2 Testing MI configural (baseline) config &lt;- &#39; ## define latent variables Pos1 =~ PosAFF11 + PosAFF21 + PosAFF31 Pos2 =~ PosAFF12 + PosAFF22 + PosAFF32 Pos3 =~ PosAFF13 + PosAFF23 + PosAFF33 ## correlated residuals across time PosAFF11 ~~ PosAFF12 + PosAFF13 PosAFF12 ~~ PosAFF13 PosAFF21 ~~ PosAFF22 + PosAFF23 PosAFF22 ~~ PosAFF23 PosAFF31 ~~ PosAFF32 + PosAFF33 PosAFF32 ~~ PosAFF33 &#39; config &lt;- cfa(config, data=long, meanstructure=TRUE, std.lv=TRUE) summary(config, standardized=TRUE, fit.measures=TRUE) ## lavaan (0.5-23.1097) converged normally after 72 iterations ## ## Number of observations 368 ## ## Estimator ML ## Minimum Function Test Statistic 9.266 ## Degrees of freedom 15 ## P-value (Chi-square) 0.863 ## ## Model test baseline model: ## ## Minimum Function Test Statistic 2688.088 ## Degrees of freedom 36 ## P-value 0.000 ## ## User model versus baseline model: ## ## Comparative Fit Index (CFI) 1.000 ## Tucker-Lewis Index (TLI) 1.005 ## ## Loglikelihood and Information Criteria: ## ## Loglikelihood user model (H0) -2040.957 ## Loglikelihood unrestricted model (H1) -2036.324 ## ## Number of free parameters 39 ## Akaike (AIC) 4159.914 ## Bayesian (BIC) 4312.329 ## Sample-size adjusted Bayesian (BIC) 4188.596 ## ## Root Mean Square Error of Approximation: ## ## RMSEA 0.000 ## 90 Percent Confidence Interval 0.000 0.026 ## P-value RMSEA &lt;= 0.05 0.997 ## ## Standardized Root Mean Square Residual: ## ## SRMR 0.011 ## ## Parameter Estimates: ## ## Information Expected ## Standard Errors Standard ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## Pos1 =~ ## PosAFF11 0.656 0.030 22.030 0.000 0.656 0.906 ## PosAFF21 0.652 0.031 20.908 0.000 0.652 0.877 ## PosAFF31 0.682 0.031 22.157 0.000 0.682 0.908 ## Pos2 =~ ## PosAFF12 0.555 0.026 21.138 0.000 0.555 0.881 ## PosAFF22 0.643 0.030 21.651 0.000 0.643 0.894 ## PosAFF32 0.642 0.027 23.348 0.000 0.642 0.936 ## Pos3 =~ ## PosAFF13 0.509 0.024 21.036 0.000 0.509 0.888 ## PosAFF23 0.545 0.027 20.347 0.000 0.545 0.867 ## PosAFF33 0.537 0.026 20.763 0.000 0.537 0.878 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .PosAFF11 ~~ ## .PosAFF12 0.002 0.007 0.325 0.745 0.002 0.024 ## .PosAFF13 0.001 0.007 0.207 0.836 0.001 0.017 ## .PosAFF12 ~~ ## .PosAFF13 0.003 0.006 0.517 0.605 0.003 0.039 ## .PosAFF21 ~~ ## .PosAFF22 0.006 0.008 0.784 0.433 0.006 0.056 ## .PosAFF23 0.006 0.008 0.773 0.439 0.006 0.055 ## .PosAFF22 ~~ ## .PosAFF23 0.011 0.007 1.525 0.127 0.011 0.111 ## .PosAFF31 ~~ ## .PosAFF32 0.008 0.007 1.097 0.273 0.008 0.100 ## .PosAFF33 0.016 0.007 2.215 0.027 0.016 0.177 ## .PosAFF32 ~~ ## .PosAFF33 0.005 0.006 0.773 0.440 0.005 0.068 ## Pos1 ~~ ## Pos2 0.471 0.044 10.609 0.000 0.471 0.471 ## Pos3 0.399 0.048 8.226 0.000 0.399 0.399 ## Pos2 ~~ ## Pos3 0.450 0.046 9.806 0.000 0.450 0.450 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .PosAFF11 3.212 0.038 85.122 0.000 3.212 4.437 ## .PosAFF21 3.105 0.039 80.035 0.000 3.105 4.172 ## .PosAFF31 3.248 0.039 82.962 0.000 3.248 4.325 ## .PosAFF12 3.253 0.033 99.116 0.000 3.253 5.167 ## .PosAFF22 3.126 0.037 83.356 0.000 3.126 4.345 ## .PosAFF32 3.274 0.036 91.602 0.000 3.274 4.775 ## .PosAFF13 3.302 0.030 110.504 0.000 3.302 5.760 ## .PosAFF23 3.094 0.033 94.403 0.000 3.094 4.921 ## .PosAFF33 3.280 0.032 102.942 0.000 3.280 5.366 ## Pos1 0.000 0.000 0.000 ## Pos2 0.000 0.000 0.000 ## Pos3 0.000 0.000 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .PosAFF11 0.093 0.011 8.155 0.000 0.093 0.178 ## .PosAFF21 0.128 0.013 9.770 0.000 0.128 0.231 ## .PosAFF31 0.099 0.012 8.092 0.000 0.099 0.176 ## .PosAFF12 0.089 0.009 9.942 0.000 0.089 0.224 ## .PosAFF22 0.104 0.011 9.363 0.000 0.104 0.202 ## .PosAFF32 0.058 0.009 6.467 0.000 0.058 0.124 ## .PosAFF13 0.070 0.008 8.211 0.000 0.070 0.212 ## .PosAFF23 0.098 0.011 9.234 0.000 0.098 0.248 ## .PosAFF33 0.086 0.010 8.719 0.000 0.086 0.229 ## Pos1 1.000 1.000 1.000 ## Pos2 1.000 1.000 1.000 ## Pos3 1.000 1.000 1.000 weak (constrain loadings) weak &lt;- &#39; ## define latent variables Pos1 =~ L1*PosAFF11 + L2*PosAFF21 + L3*PosAFF31 Pos2 =~ L1*PosAFF12 + L2*PosAFF22 + L3*PosAFF32 Pos3 =~ L1*PosAFF13 + L2*PosAFF23 + L3*PosAFF33 ## free latent variances at later times (only set the scale once) Pos2 ~~ NA*Pos2 Pos3 ~~ NA*Pos3 ## correlated residuals across time PosAFF11 ~~ PosAFF12 + PosAFF13 PosAFF12 ~~ PosAFF13 PosAFF21 ~~ PosAFF22 + PosAFF23 PosAFF22 ~~ PosAFF23 PosAFF31 ~~ PosAFF32 + PosAFF33 PosAFF32 ~~ PosAFF33 &#39; weak &lt;- cfa(weak, data=long, meanstructure=TRUE, std.lv=TRUE) summary(weak, standardized=TRUE, fit.measures=TRUE) ## lavaan (0.5-23.1097) converged normally after 81 iterations ## ## Number of observations 368 ## ## Estimator ML ## Minimum Function Test Statistic 17.684 ## Degrees of freedom 19 ## P-value (Chi-square) 0.544 ## ## Model test baseline model: ## ## Minimum Function Test Statistic 2688.088 ## Degrees of freedom 36 ## P-value 0.000 ## ## User model versus baseline model: ## ## Comparative Fit Index (CFI) 1.000 ## Tucker-Lewis Index (TLI) 1.001 ## ## Loglikelihood and Information Criteria: ## ## Loglikelihood user model (H0) -2045.166 ## Loglikelihood unrestricted model (H1) -2036.324 ## ## Number of free parameters 35 ## Akaike (AIC) 4160.332 ## Bayesian (BIC) 4297.114 ## Sample-size adjusted Bayesian (BIC) 4186.072 ## ## Root Mean Square Error of Approximation: ## ## RMSEA 0.000 ## 90 Percent Confidence Interval 0.000 0.042 ## P-value RMSEA &lt;= 0.05 0.983 ## ## Standardized Root Mean Square Residual: ## ## SRMR 0.021 ## ## Parameter Estimates: ## ## Information Expected ## Standard Errors Standard ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## Pos1 =~ ## PosAFF11 (L1) 0.631 0.027 23.651 0.000 0.631 0.894 ## PosAFF21 (L2) 0.677 0.029 23.460 0.000 0.677 0.887 ## PosAFF31 (L3) 0.686 0.029 23.837 0.000 0.686 0.910 ## Pos2 =~ ## PosAFF12 (L1) 0.631 0.027 23.651 0.000 0.582 0.894 ## PosAFF22 (L2) 0.677 0.029 23.460 0.000 0.625 0.886 ## PosAFF32 (L3) 0.686 0.029 23.837 0.000 0.633 0.931 ## Pos3 =~ ## PosAFF13 (L1) 0.631 0.027 23.651 0.000 0.503 0.883 ## PosAFF23 (L2) 0.677 0.029 23.460 0.000 0.540 0.864 ## PosAFF33 (L3) 0.686 0.029 23.837 0.000 0.547 0.885 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .PosAFF11 ~~ ## .PosAFF12 0.003 0.007 0.395 0.693 0.003 0.029 ## .PosAFF13 0.002 0.007 0.231 0.817 0.002 0.018 ## .PosAFF12 ~~ ## .PosAFF13 0.002 0.006 0.404 0.686 0.002 0.031 ## .PosAFF21 ~~ ## .PosAFF22 0.006 0.008 0.676 0.499 0.006 0.049 ## .PosAFF23 0.005 0.008 0.646 0.518 0.005 0.047 ## .PosAFF22 ~~ ## .PosAFF23 0.012 0.007 1.598 0.110 0.012 0.114 ## .PosAFF31 ~~ ## .PosAFF32 0.008 0.007 1.185 0.236 0.008 0.107 ## .PosAFF33 0.016 0.007 2.214 0.027 0.016 0.182 ## .PosAFF32 ~~ ## .PosAFF33 0.005 0.006 0.766 0.444 0.005 0.067 ## Pos1 ~~ ## Pos2 0.437 0.046 9.404 0.000 0.474 0.474 ## Pos3 0.319 0.042 7.578 0.000 0.400 0.400 ## Pos2 ~~ ## Pos3 0.332 0.047 7.030 0.000 0.450 0.450 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .PosAFF11 3.212 0.037 87.342 0.000 3.212 4.553 ## .PosAFF21 3.105 0.040 78.061 0.000 3.105 4.069 ## .PosAFF31 3.248 0.039 82.691 0.000 3.248 4.311 ## .PosAFF12 3.253 0.034 95.798 0.000 3.253 4.994 ## .PosAFF22 3.126 0.037 85.004 0.000 3.126 4.431 ## .PosAFF32 3.274 0.035 92.400 0.000 3.274 4.817 ## .PosAFF13 3.302 0.030 111.238 0.000 3.302 5.799 ## .PosAFF23 3.094 0.033 94.971 0.000 3.094 4.951 ## .PosAFF33 3.280 0.032 101.745 0.000 3.280 5.304 ## Pos1 0.000 0.000 0.000 ## Pos2 0.000 0.000 0.000 ## Pos3 0.000 0.000 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## Pos2 0.853 0.086 9.942 0.000 1.000 1.000 ## Pos3 0.636 0.067 9.479 0.000 1.000 1.000 ## .PosAFF11 0.100 0.011 9.159 0.000 0.100 0.201 ## .PosAFF21 0.124 0.013 9.501 0.000 0.124 0.213 ## .PosAFF31 0.098 0.012 8.261 0.000 0.098 0.172 ## .PosAFF12 0.085 0.009 9.548 0.000 0.085 0.201 ## .PosAFF22 0.107 0.011 9.929 0.000 0.107 0.215 ## .PosAFF32 0.061 0.009 7.123 0.000 0.061 0.132 ## .PosAFF13 0.071 0.008 8.812 0.000 0.071 0.219 ## .PosAFF23 0.099 0.010 9.680 0.000 0.099 0.254 ## .PosAFF33 0.083 0.009 8.776 0.000 0.083 0.218 ## Pos1 1.000 1.000 1.000 Strong (constrain loadings and intercepts) strong &lt;- &#39; ## define latent variables Pos1 =~ L1*PosAFF11 + L2*PosAFF21 + L3*PosAFF31 Pos2 =~ L1*PosAFF12 + L2*PosAFF22 + L3*PosAFF32 Pos3 =~ L1*PosAFF13 + L2*PosAFF23 + L3*PosAFF33 ## free latent variances at later times (only set the scale once) Pos2 ~~ NA*Pos2 Pos3 ~~ NA*Pos3 ## correlated residuals across time PosAFF11 ~~ PosAFF12 + PosAFF13 PosAFF12 ~~ PosAFF13 PosAFF21 ~~ PosAFF22 + PosAFF23 PosAFF22 ~~ PosAFF23 PosAFF31 ~~ PosAFF32 + PosAFF33 PosAFF32 ~~ PosAFF33 ## constrain intercepts across time PosAFF11 ~ t1*1 PosAFF21 ~ t2*1 PosAFF31 ~ t3*1 PosAFF12 ~ t1*1 PosAFF22 ~ t2*1 PosAFF32 ~ t3*1 PosAFF13 ~ t1*1 PosAFF23 ~ t2*1 PosAFF33 ~ t3*1 ## free latent means at later times (only set the scale once) Pos2 ~ NA*1 Pos3 ~ NA*1&#39; strong &lt;- cfa(strong, data=long, meanstructure=TRUE, std.lv=TRUE) summary(strong, standardized=TRUE, fit.measures=TRUE) ## lavaan (0.5-23.1097) converged normally after 81 iterations ## ## Number of observations 368 ## ## Estimator ML ## Minimum Function Test Statistic 30.144 ## Degrees of freedom 23 ## P-value (Chi-square) 0.145 ## ## Model test baseline model: ## ## Minimum Function Test Statistic 2688.088 ## Degrees of freedom 36 ## P-value 0.000 ## ## User model versus baseline model: ## ## Comparative Fit Index (CFI) 0.997 ## Tucker-Lewis Index (TLI) 0.996 ## ## Loglikelihood and Information Criteria: ## ## Loglikelihood user model (H0) -2051.396 ## Loglikelihood unrestricted model (H1) -2036.324 ## ## Number of free parameters 31 ## Akaike (AIC) 4164.792 ## Bayesian (BIC) 4285.943 ## Sample-size adjusted Bayesian (BIC) 4187.591 ## ## Root Mean Square Error of Approximation: ## ## RMSEA 0.029 ## 90 Percent Confidence Interval 0.000 0.055 ## P-value RMSEA &lt;= 0.05 0.901 ## ## Standardized Root Mean Square Residual: ## ## SRMR 0.024 ## ## Parameter Estimates: ## ## Information Expected ## Standard Errors Standard ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## Pos1 =~ ## PosAFF11 (L1) 0.631 0.027 23.635 0.000 0.631 0.893 ## PosAFF21 (L2) 0.676 0.029 23.441 0.000 0.676 0.886 ## PosAFF31 (L3) 0.686 0.029 23.838 0.000 0.686 0.910 ## Pos2 =~ ## PosAFF12 (L1) 0.631 0.027 23.635 0.000 0.582 0.894 ## PosAFF22 (L2) 0.676 0.029 23.441 0.000 0.624 0.886 ## PosAFF32 (L3) 0.686 0.029 23.838 0.000 0.633 0.932 ## Pos3 =~ ## PosAFF13 (L1) 0.631 0.027 23.635 0.000 0.503 0.882 ## PosAFF23 (L2) 0.676 0.029 23.441 0.000 0.539 0.862 ## PosAFF33 (L3) 0.686 0.029 23.838 0.000 0.547 0.885 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .PosAFF11 ~~ ## .PosAFF12 0.003 0.007 0.471 0.638 0.003 0.035 ## .PosAFF13 0.000 0.007 0.030 0.976 0.000 0.002 ## .PosAFF12 ~~ ## .PosAFF13 0.002 0.006 0.299 0.765 0.002 0.023 ## .PosAFF21 ~~ ## .PosAFF22 0.006 0.008 0.718 0.473 0.006 0.051 ## .PosAFF23 0.004 0.008 0.521 0.602 0.004 0.038 ## .PosAFF22 ~~ ## .PosAFF23 0.011 0.007 1.530 0.126 0.011 0.109 ## .PosAFF31 ~~ ## .PosAFF32 0.008 0.007 1.160 0.246 0.008 0.105 ## .PosAFF33 0.017 0.007 2.261 0.024 0.017 0.187 ## .PosAFF32 ~~ ## .PosAFF33 0.005 0.006 0.795 0.427 0.005 0.070 ## Pos1 ~~ ## Pos2 0.438 0.047 9.409 0.000 0.474 0.474 ## Pos3 0.320 0.042 7.590 0.000 0.401 0.401 ## Pos2 ~~ ## Pos3 0.332 0.047 7.027 0.000 0.450 0.450 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .PosAFF11 (t1) 3.237 0.035 92.743 0.000 3.237 4.583 ## .PosAFF21 (t2) 3.084 0.038 81.945 0.000 3.084 4.043 ## .PosAFF31 (t3) 3.244 0.038 85.408 0.000 3.244 4.304 ## .PosAFF12 (t1) 3.237 0.035 92.743 0.000 3.237 4.967 ## .PosAFF22 (t2) 3.084 0.038 81.945 0.000 3.084 4.375 ## .PosAFF32 (t3) 3.244 0.038 85.408 0.000 3.244 4.771 ## .PosAFF13 (t1) 3.237 0.035 92.743 0.000 3.237 5.674 ## .PosAFF23 (t2) 3.084 0.038 81.945 0.000 3.084 4.931 ## .PosAFF33 (t3) 3.244 0.038 85.408 0.000 3.244 5.249 ## Pos2 0.044 0.055 0.798 0.425 0.047 0.047 ## Pos3 0.058 0.055 1.043 0.297 0.072 0.072 ## Pos1 0.000 0.000 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## Pos2 0.853 0.086 9.942 0.000 1.000 1.000 ## Pos3 0.636 0.067 9.475 0.000 1.000 1.000 ## .PosAFF11 0.101 0.011 9.188 0.000 0.101 0.203 ## .PosAFF21 0.125 0.013 9.527 0.000 0.125 0.215 ## .PosAFF31 0.097 0.012 8.216 0.000 0.097 0.172 ## .PosAFF12 0.086 0.009 9.551 0.000 0.086 0.201 ## .PosAFF22 0.107 0.011 9.947 0.000 0.107 0.216 ## .PosAFF32 0.061 0.009 7.094 0.000 0.061 0.132 ## .PosAFF13 0.073 0.008 8.865 0.000 0.073 0.223 ## .PosAFF23 0.101 0.010 9.725 0.000 0.101 0.257 ## .PosAFF33 0.083 0.009 8.706 0.000 0.083 0.216 ## Pos1 1.000 1.000 1.000 Strict (loadings, intercept, residual variances) strict &lt;- &#39; ## define latent variables Pos1 =~ L1*PosAFF11 + L2*PosAFF21 + L3*PosAFF31 Pos2 =~ L1*PosAFF12 + L2*PosAFF22 + L3*PosAFF32 Pos3 =~ L1*PosAFF13 + L2*PosAFF23 + L3*PosAFF33 ## free latent variances at later times (only set the scale once) Pos2 ~~ NA*Pos2 Pos3 ~~ NA*Pos3 ## correlated residuals across time PosAFF11 ~~ PosAFF12 + PosAFF13 PosAFF12 ~~ PosAFF13 PosAFF21 ~~ PosAFF22 + PosAFF23 PosAFF22 ~~ PosAFF23 PosAFF31 ~~ PosAFF32 + PosAFF33 PosAFF32 ~~ PosAFF33 ## equality of residuals PosAFF11 ~~ r*PosAFF11 PosAFF12 ~~ r*PosAFF12 PosAFF13 ~~ r*PosAFF13 PosAFF21 ~~ r*PosAFF21 PosAFF22 ~~ r*PosAFF22 PosAFF23 ~~ r*PosAFF23 PosAFF31 ~~ r*PosAFF31 PosAFF32 ~~ r*PosAFF32 PosAFF33 ~~ r*PosAFF33 ## constrain intercepts across time PosAFF11 ~ t1*1 PosAFF21 ~ t2*1 PosAFF31 ~ t3*1 PosAFF12 ~ t1*1 PosAFF22 ~ t2*1 PosAFF32 ~ t3*1 PosAFF13 ~ t1*1 PosAFF23 ~ t2*1 PosAFF33 ~ t3*1 ## free latent means at later times (only set the scale once) Pos2 ~ NA*1 Pos3 ~ NA*1&#39; strict &lt;- cfa(strict, data=long, meanstructure=TRUE, std.lv=TRUE) summary(strict, standardized=TRUE, fit.measures=TRUE) ## lavaan (0.5-23.1097) converged normally after 85 iterations ## ## Number of observations 368 ## ## Estimator ML ## Minimum Function Test Statistic 60.491 ## Degrees of freedom 31 ## P-value (Chi-square) 0.001 ## ## Model test baseline model: ## ## Minimum Function Test Statistic 2688.088 ## Degrees of freedom 36 ## P-value 0.000 ## ## User model versus baseline model: ## ## Comparative Fit Index (CFI) 0.989 ## Tucker-Lewis Index (TLI) 0.987 ## ## Loglikelihood and Information Criteria: ## ## Loglikelihood user model (H0) -2066.569 ## Loglikelihood unrestricted model (H1) -2036.324 ## ## Number of free parameters 23 ## Akaike (AIC) 4179.139 ## Bayesian (BIC) 4269.025 ## Sample-size adjusted Bayesian (BIC) 4196.054 ## ## Root Mean Square Error of Approximation: ## ## RMSEA 0.051 ## 90 Percent Confidence Interval 0.031 0.070 ## P-value RMSEA &lt;= 0.05 0.445 ## ## Standardized Root Mean Square Residual: ## ## SRMR 0.026 ## ## Parameter Estimates: ## ## Information Expected ## Standard Errors Standard ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## Pos1 =~ ## PosAFF11 (L1) 0.631 0.026 23.891 0.000 0.631 0.901 ## PosAFF21 (L2) 0.689 0.028 24.210 0.000 0.689 0.915 ## PosAFF31 (L3) 0.680 0.028 24.061 0.000 0.680 0.913 ## Pos2 =~ ## PosAFF12 (L1) 0.631 0.026 23.891 0.000 0.579 0.885 ## PosAFF22 (L2) 0.689 0.028 24.210 0.000 0.632 0.901 ## PosAFF32 (L3) 0.680 0.028 24.061 0.000 0.623 0.899 ## Pos3 =~ ## PosAFF13 (L1) 0.631 0.026 23.891 0.000 0.500 0.854 ## PosAFF23 (L2) 0.689 0.028 24.210 0.000 0.545 0.873 ## PosAFF33 (L3) 0.680 0.028 24.061 0.000 0.538 0.871 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .PosAFF11 ~~ ## .PosAFF12 0.004 0.007 0.617 0.537 0.004 0.045 ## .PosAFF13 0.002 0.007 0.280 0.780 0.002 0.020 ## .PosAFF12 ~~ ## .PosAFF13 0.003 0.007 0.394 0.693 0.003 0.029 ## .PosAFF21 ~~ ## .PosAFF22 0.003 0.007 0.346 0.730 0.003 0.027 ## .PosAFF23 0.002 0.007 0.228 0.820 0.002 0.018 ## .PosAFF22 ~~ ## .PosAFF23 0.009 0.007 1.259 0.208 0.009 0.098 ## .PosAFF31 ~~ ## .PosAFF32 0.011 0.007 1.508 0.132 0.011 0.117 ## .PosAFF33 0.016 0.007 2.310 0.021 0.016 0.177 ## .PosAFF32 ~~ ## .PosAFF33 0.008 0.007 1.186 0.236 0.008 0.091 ## Pos1 ~~ ## Pos2 0.433 0.046 9.372 0.000 0.472 0.472 ## Pos3 0.318 0.042 7.613 0.000 0.402 0.402 ## Pos2 ~~ ## Pos3 0.330 0.047 7.031 0.000 0.454 0.454 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .PosAFF11 (t1) 3.236 0.035 92.686 0.000 3.236 4.617 ## .PosAFF21 (t2) 3.087 0.038 81.529 0.000 3.087 4.100 ## .PosAFF31 (t3) 3.245 0.038 86.233 0.000 3.245 4.359 ## .PosAFF12 (t1) 3.236 0.035 92.686 0.000 3.236 4.947 ## .PosAFF22 (t2) 3.087 0.038 81.529 0.000 3.087 4.402 ## .PosAFF32 (t3) 3.245 0.038 86.233 0.000 3.245 4.679 ## .PosAFF13 (t1) 3.236 0.035 92.686 0.000 3.236 5.530 ## .PosAFF23 (t2) 3.087 0.038 81.529 0.000 3.087 4.944 ## .PosAFF33 (t3) 3.245 0.038 86.233 0.000 3.245 5.251 ## Pos2 0.044 0.055 0.799 0.424 0.048 0.048 ## Pos3 0.052 0.055 0.945 0.345 0.066 0.066 ## Pos1 0.000 0.000 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## Pos2 0.841 0.085 9.950 0.000 1.000 1.000 ## Pos3 0.627 0.066 9.494 0.000 1.000 1.000 ## .PosAFF11 (r) 0.093 0.003 33.038 0.000 0.093 0.188 ## .PosAFF12 (r) 0.093 0.003 33.038 0.000 0.093 0.216 ## .PosAFF13 (r) 0.093 0.003 33.038 0.000 0.093 0.270 ## .PosAFF21 (r) 0.093 0.003 33.038 0.000 0.093 0.163 ## .PosAFF22 (r) 0.093 0.003 33.038 0.000 0.093 0.188 ## .PosAFF23 (r) 0.093 0.003 33.038 0.000 0.093 0.237 ## .PosAFF31 (r) 0.093 0.003 33.038 0.000 0.093 0.167 ## .PosAFF32 (r) 0.093 0.003 33.038 0.000 0.093 0.192 ## .PosAFF33 (r) 0.093 0.003 33.038 0.000 0.093 0.242 ## Pos1 1.000 1.000 1.000 Note that there are other types of MI that we could investigate, depending on what we are interested in. We could look at equality of latent means and variances, as well as regressions, if they were in the model. 7.9.3 Comparing the models Usually done through chi-square difference test. But this is a very sensitive test, especially with larger samples. Better to look at changes in CFI. If delta is .01 or greater than maybe it shows misfit. ##Compare configural and weak model anova(config, weak) ## Chi Square Difference Test ## ## Df AIC BIC Chisq Chisq diff Df diff Pr(&gt;Chisq) ## config 15 4159.9 4312.3 9.2658 ## weak 19 4160.3 4297.1 17.6836 8.4179 4 0.07742 . ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ##Compare weak and strong model anova(weak, strong) ## Chi Square Difference Test ## ## Df AIC BIC Chisq Chisq diff Df diff Pr(&gt;Chisq) ## weak 19 4160.3 4297.1 17.684 ## strong 23 4164.8 4285.9 30.144 12.461 4 0.01424 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 fitmeasures(weak)[&#39;cfi&#39;] ## cfi ## 1 fitmeasures(strong)[&#39;cfi&#39;] ## cfi ## 0.9973062 fitmeasures(strict)[&#39;cfi&#39;] ## cfi ## 0.9888801 7.10 second order growth model Repeated measures are latent. Why would we want to do this? sec.order &lt;- &#39; ## define latent variables Pos1 =~ NA*PosAFF11 + L1*PosAFF11 + L2*PosAFF21 + L3*PosAFF31 Pos2 =~ NA*PosAFF12 + L1*PosAFF12 + L2*PosAFF22 + L3*PosAFF32 Pos3 =~ NA*PosAFF13 + L1*PosAFF13 + L2*PosAFF23 + L3*PosAFF33 ## intercepts PosAFF11 ~ t1*1 PosAFF21 ~ t2*1 PosAFF31 ~ t3*1 PosAFF12 ~ t1*1 PosAFF22 ~ t2*1 PosAFF32 ~ t3*1 PosAFF13 ~ t1*1 PosAFF23 ~ t2*1 PosAFF33 ~ t3*1 ## correlated residuals across time PosAFF11 ~~ PosAFF12 + PosAFF13 PosAFF12 ~~ PosAFF13 PosAFF21 ~~ PosAFF22 + PosAFF23 PosAFF22 ~~ PosAFF23 PosAFF31 ~~ PosAFF32 + PosAFF33 PosAFF32 ~~ PosAFF33 ## latent variable intercepts Pos1 ~ 0*1 Pos2 ~ 0*1 Pos3 ~ 0*1 #model constraints for effect coding ## loadings must average to 1 L1 == 3 - L2 - L3 ## means must average to 0 t1 == 0 - t2 - t3 i =~ 1*Pos1 + 1*Pos2 + 1*Pos3 s =~ 0*Pos1 + 1*Pos2 + 2*Pos3 &#39; fit.sec.order &lt;- growth(sec.order, data=long, missing = &quot;ML&quot;) summary(fit.sec.order, fit.measures=TRUE) ## lavaan (0.5-23.1097) converged normally after 99 iterations ## ## Number of observations 368 ## ## Number of missing patterns 1 ## ## Estimator ML ## Minimum Function Test Statistic 30.254 ## Degrees of freedom 24 ## P-value (Chi-square) 0.176 ## ## Model test baseline model: ## ## Minimum Function Test Statistic 2688.088 ## Degrees of freedom 36 ## P-value 0.000 ## ## User model versus baseline model: ## ## Comparative Fit Index (CFI) 0.998 ## Tucker-Lewis Index (TLI) 0.996 ## ## Loglikelihood and Information Criteria: ## ## Loglikelihood user model (H0) -2051.451 ## Loglikelihood unrestricted model (H1) -2036.324 ## ## Number of free parameters 30 ## Akaike (AIC) 4162.902 ## Bayesian (BIC) 4280.145 ## Sample-size adjusted Bayesian (BIC) 4184.966 ## ## Root Mean Square Error of Approximation: ## ## RMSEA 0.027 ## 90 Percent Confidence Interval 0.000 0.053 ## P-value RMSEA &lt;= 0.05 0.926 ## ## Standardized Root Mean Square Residual: ## ## SRMR 0.025 ## ## Parameter Estimates: ## ## Information Observed ## Standard Errors Standard ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) ## Pos1 =~ ## PosAFF11 (L1) 0.950 0.014 68.551 0.000 ## PosAFF21 (L2) 1.018 0.015 69.038 0.000 ## PosAFF31 (L3) 1.033 0.014 73.342 0.000 ## Pos2 =~ ## PosAFF12 (L1) 0.950 0.014 68.551 0.000 ## PosAFF22 (L2) 1.018 0.015 69.038 0.000 ## PosAFF32 (L3) 1.033 0.014 73.342 0.000 ## Pos3 =~ ## PosAFF13 (L1) 0.950 0.014 68.551 0.000 ## PosAFF23 (L2) 1.018 0.015 69.038 0.000 ## PosAFF33 (L3) 1.033 0.014 73.342 0.000 ## i =~ ## Pos1 1.000 ## Pos2 1.000 ## Pos3 1.000 ## s =~ ## Pos1 0.000 ## Pos2 1.000 ## Pos3 2.000 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## .PosAFF11 ~~ ## .PosAFF12 0.003 0.007 0.465 0.642 ## .PosAFF13 0.000 0.007 0.029 0.977 ## .PosAFF12 ~~ ## .PosAFF13 0.002 0.006 0.306 0.759 ## .PosAFF21 ~~ ## .PosAFF22 0.006 0.008 0.716 0.474 ## .PosAFF23 0.004 0.008 0.520 0.603 ## .PosAFF22 ~~ ## .PosAFF23 0.011 0.007 1.518 0.129 ## .PosAFF31 ~~ ## .PosAFF32 0.008 0.007 1.159 0.247 ## .PosAFF33 0.017 0.007 2.253 0.024 ## .PosAFF32 ~~ ## .PosAFF33 0.005 0.006 0.791 0.429 ## i ~~ ## s -0.052 0.023 -2.216 0.027 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .PosAFF11 (t1) 0.210 0.045 4.645 0.000 ## .PosAFF21 (t2) -0.161 0.048 -3.344 0.001 ## .PosAFF31 (t3) -0.049 0.046 -1.067 0.286 ## .PosAFF12 (t1) 0.210 0.045 4.645 0.000 ## .PosAFF22 (t2) -0.161 0.048 -3.344 0.001 ## .PosAFF32 (t3) -0.049 0.046 -1.067 0.286 ## .PosAFF13 (t1) 0.210 0.045 4.645 0.000 ## .PosAFF23 (t2) -0.161 0.048 -3.344 0.001 ## .PosAFF33 (t3) -0.049 0.046 -1.067 0.286 ## Pos1 0.000 ## Pos2 0.000 ## Pos3 0.000 ## i 3.192 0.034 92.584 0.000 ## s 0.019 0.018 1.016 0.310 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .PosAFF11 0.101 0.011 9.101 0.000 ## .PosAFF21 0.125 0.013 9.479 0.000 ## .PosAFF31 0.097 0.012 8.170 0.000 ## .PosAFF12 0.086 0.009 9.536 0.000 ## .PosAFF22 0.107 0.011 9.917 0.000 ## .PosAFF32 0.061 0.009 7.052 0.000 ## .PosAFF13 0.072 0.008 8.770 0.000 ## .PosAFF23 0.101 0.010 9.655 0.000 ## .PosAFF33 0.083 0.009 8.716 0.000 ## Pos1 0.196 0.043 4.553 0.000 ## Pos2 0.207 0.023 9.132 0.000 ## Pos3 0.129 0.034 3.767 0.000 ## i 0.245 0.044 5.627 0.000 ## s 0.029 0.019 1.542 0.123 ## ## Constraints: ## |Slack| ## L1 - (3-L2-L3) 0.000 ## t1 - (0-t2-t3) 0.000 7.11 Multple groups 7.11.1 Cohort sequential designs 7.12 Missing data 7.12.1 Planned missing data 7.13 Power 7.14 Now you try Fit a measurement model to your constructs at one time point. Try out the different types of scaling discussed in class. What changes what stays the same? What do the fit statistics say about your latent variable? Good/bad? Is your latent variable Just identified/saturdated, under identified or over identified? Fit a longitudinal CFA model where you a) first correlate your latent factors across time and then b) a second model that predicts later times by a prevous time (ie auto regressive; t1 -&gt; t2 -&gt; t3). What are your conclusions? How does one differ from the other? Fit a longitdinal growth model in SEM and in HLM. Compare and contrast the differences. Constrain the residual variances to be equal. Does this change the fit of your model? Contrain your slope to be fixed, not random. How does this change your model? Change the time metric in your SEM growth model. How does that change your estimates? Does it change your fit statistics? Try a different type of estimation (see lavaan tutorial for details). How does that change your model? Provide semplots for each of the models "]
]
